[
["index.html", "Cognitive Technologies: From Theory and Data to Application Preface", " Cognitive Technologies: From Theory and Data to Application Preface This is a collection of chapters exploring the theme of cognitive technologies. Each chapter was written by a student enrolled in the course PSYC 80103, Cognitive Technologies: From Theory and Data to Application, offered as a doctoral course, through the Department of Psychology at the Graduate Center of the City University of New York, taught by Matthew Crump, Spring 2018. "],
["reflections-on-our-tour-of-cognitive-technologies.html", "Chapter 1 Reflections on our tour of Cognitive Technologies 1.1 Snake oil: An old technology 1.2 Tech that works 1.3 Connection to Instance Theory 1.4 Exciting Directions 1.5 That’s all", " Chapter 1 Reflections on our tour of Cognitive Technologies Matthew Crump, Brooklyn College and Graduate Center of The City University of New York In Spring 2018 a small group of doctoral and master’s students and I took a tour on the theme of Cognitive Technologies. We were interested in two sub themes that would connect cognition with technology: 1) examples where basic research and theory in cognition has led to applied technologies, and 2) examples where new tech has the potential to augment human cognition. Each week we covered varied topics from speed reading, computational models of semantics, machine learning for classification, computational models of object recognition, decoding brain states, brain training, apps for education, lie detection technology, augmented reality and smart spaces, cognition on drugs, and the use of big data for informing theories of cognition. 1.1 Snake oil: An old technology We found some “cognitive” technologies did not live to their hype. For example, speed-reading techniques do little more than train people how to skim text quickly. Too bad any gains in speed are accompanied with losses in comprehension (Rayner et al. 2016). There appears to be no strong evidence that brain training games do anything beyond training people on the games themselves (Simons et al. 2016). No far transfer here. Similarly, the evidence for cognition enhancing drugs (that do anything beyond enhancing alertness) is just as dissapointing (Battleday and Brem 2015; Marraccini et al. 2016; Mehlman 2004). 1.2 Tech that works We found several promising technologies and endeavored to connect their successes to formative ideas in Cognitive Psychology. We focused a great deal on insights from instance-based view of cognition, and their connection to the many recent successes of machine learning applied to various classification problems. For example, problems that used to be identified as easy for for people and hard for machines, like face and object recognition, word and document similarity analysis, gesture, posture, and emotion recognition, voice transcription, and language translation, all have working computational solutions. In general, many of these problems were solved by the same kind of solution: gather a large database of examples, represent each example as a collection of digital features, then train a machine learning algorithm on the examples and measure whether the classifier can generalize to accurately classify new examples that were not from the training set. This big-data approach often works quite well. Why does it work? My view is that success was anticipated by instance theories. 1.3 Connection to Instance Theory Instance theories of cognition have been developed to account for a range of cognitive abilities, from learning (Jamieson, Crump, and Hannah 2012) and memory (D. L. Hintzman 1988; D. L. Hintzman 1984; D. Hintzman 1986), skill-acquisition (Logan 1988), categorization and concept formation (Jacoby and Brooks 1984), to judgment and decision-making (Dougherty, Gettys, and Ogden 1999). A common assumption among instance theories is that single experiences are a foundational unit of knowledge representation: People retain the details of their specific experiences. In some computational models, such as MINERVA (D. Hintzman 1986), this idea is expressed in terms of a multiple-trace architecture. Every experience is represented as a feature vector coding the “gory detail” of the elemental features of that experience. These experiences are laid down in an instance-based memory, that has an ever expanding body of unique traces for each successive new experience. The notion that people have instance-based memory representation has been met with some skepticism, perhaps due to the incredulous idea that brains could have enough storage space to hold such a large repository of experiences: Instance theory must be wrong because you would receive a “hard-drive is too full message”. Regardless of the limits of brain-space, the more interesting implication from instance-theory is what can be done with a large pool of examples. In Jacoby &amp; Brooks’ Jacoby and Brooks (1984) view, a large pool of exmamples can provide a non-analytic basis for cognition. When people have a large number of examples, they can perform classification tasks on the basis of analogy by similarity. When presented with a face, rather than pulling up a feature-list for faces and inspecting each element in the stimulus to determine whether the rules say whether it can be called a face, people can look at face, find that they can spontaneiously recall many similar prior examples of this stimulus, then call it a face because it looks globally similar to other faces they have seen. The essential ingredients for instance theory are 1) a large pool examples, and 2) sensitivity to similarity. In computational models of instance theory, like most global matching memory models (Eich 1982; D. L. Hintzman 1984; Humphreys et al. 1989; Murdock 1993), both of these ingredients are present. The models store items, experiences, or examples, as high-dimensional feature vectors in a memory. The models also assume that retrieval from memory is done by cue-driven similarity. Specifically, the cues or features present in the current environment are represented as a high-dimensional feature vector, and this cue-of-the-present-moment (probe) is used to retrieve similar traces from memory. This can be achieved mathematically by computing the correlation or cosine between the features of the probe, and the features of each trace in memory. Then, the model assumes that people might respond to the probe in the same way that they responded to the traces retrieved by memory. Finally, instance theories work well when there is structure in the data. Structure refers to the fact that the features of our experiences are not random. They are correlated with themselves over time and space. If our experiences were random, our world would look and sound like the white noise from old TVs not capable of receiving a station. The insight from instance theory is that sensitivity to the structure of the world around us can be obtained by a reconstructive memory process capable of preserving the details of of our experiences. The experiences contain the structure, and we use similairity between the experiences to become sensitive to that structure. Reasoning by analogy, we see this idea being validated by the many successes of machine learning techniques applied to previously hard classification problems. Those solutions were obtained by harvesting enough examples to support accurate classifier generalization to new exemplars. 1.3.1 Procedures of Mind Our review of instance theories also anticipated some of the lack-luster findings for cognitive enhancing technologies, like brain-training. The work of Kolers was particularly insightful (Kolers and Roediger 1984). Among other things Kolers spilled a great deal of ink on the topic of learning to read upside down (and other geometric rotations of text). Unsurprisingly, he found that people are of course worse at reading weird rotated text compared to normal upright text, and that people can learn to get better at reading these unfamiliar rotations. More important, were his findings about what it was that people had learned: the details. For example, people learned about the very specific thing they were practicing. A subject learning to read upside-down text would not get better in general for reading just any upside down text, instead they get better at reading the specific letters, words, and sentences contained in the examples they were learning. In other words, there wasn’t much far transfer to be had. In Koler’s view, people were learning “procedures of mind” for solving the specific pattern-analyzing problems they were confronted in the training examples. Here, specificity is the rule and generalization can the exception. Generalization can occur when the specific procedures applied to one problem happen to be useful for another. Taking a broader view, it appears that the specificity and lack of far transfer associated with learning new skills is a kind of hegemonic principle. For example, brain-training games train the game in specific, not the brain in general (Simons et al. 2016). Luminosity should have read Kolers. 1.4 Exciting Directions Every week we read a few papers and everyone was assigned to find neat papers that we should all be aware of. We found some cool stuff. Here’s a few highlights in no particular order. 1.4.1 Conversational AI Really hard problems like making computers capable being an engaging conversational partner are being tackled with some success. Amazon created the Alexa prize, which would be awarded to a research group who could produce a chatbot (installed in Amazon’s talking speaker Alexa) that could engage a person in chat for 20 minutes, without the person getting tired and cancelling the conversation. The challenge is still standing after the 2017 competition, but they are running it again in 2018, presumably with more training examples to improve the algorithms. It’s around the corner. 1.4.2 Decoding Brain states Multi-voxel pattern classification analysis for classifying cognitive states based off of neural data has been applied to many problems. It often works. So, now we can get some idea of what dreams you were dreaming while you were lying in the scanner (Horikawa et al. 2013). There are too many other examples to list. 1.4.3 Detecting Deception Lie detection has moved beyond the polygraph. People might be bad at detecting some of the signals of lying vs. telling the truth (Vrij, Granhag, and Porter 2010), but machine learning techniques are being thrown at the problem with some success. How about lie detection using fmri (Langleben et al. 2005), videos of your face (Meservy et al. 2005), records of language production (Matsumoto and Hwang 2015), or typing (Derrick et al. 2013)? It seems to work better than chance, often much better. 1.4.4 Inner Voice decoding with a chinstrap! It’s still in development, but this chinstrap tech called alterego can be used to decode what your inner voice is saying. Umm what? 1.4.5 Image Memorability What if there was machine that could tell you how intrinsically memorable something is? Ad agencies would be into this, they might want to know what pictures would stick most strongly in people’s memories. Some big data initiatives are now sorting this out by having loads of people do memory tasks for loads of pictures (Isola et al. 2011). The result is a massive database of pictures normed for their memorability (Khosla et al. 2015). This can be used to predict memorability of pictures. Baby steps, but moving forward. 1.5 That’s all There’s alot going in the broad area of cognitive technologies. Researchers in cognition have growing opportunities to make use of computational models and big data to make theoretical and applied progress. It’ll be fun to see what happens. References "],
["computational-classification-techniques-for-biomedical-and-clinical-big-data.html", "Chapter 2 Computational Classification Techniques for Biomedical and Clinical Big Data 2.1 Abstract 2.2 Introduction 2.3 Previous Work 2.4 Medical and Clinical Applications 2.5 Clerical Applications 2.6 Real World Applications and Future Work 2.7 Conclusion 2.8 References", " Chapter 2 Computational Classification Techniques for Biomedical and Clinical Big Data Kelsey Bourque, Cognitive Technologies, Spring 2018 2.1 Abstract In this paper, we review popular computational classification methods and their application to biomedical and clinical data. These techniques are necessary to make sense of biomedical “big data”, as more and more of it is available every day. There is a definite lack of knowledge, as no person could possibly keep up on all this information. Therefore, computational classification is needed to create and sustain systems that will ultimately benefit the medical community. 2.2 Introduction “Big data” is a popular buzzword thrown into seemingly every conversation about data mining technology. Simply put, “big data” is just massive, sometimes unstructured, data sources collected from many odds and ends but most typically from the internet. Much time and effort go into finding effective and efficient ways to make sense of this data, specifically ways to accurately classify it at minimal computational expense. Computational classification techniques have been around long before big data was a buzzword—and some existed even before the age of the internet. These classification techniques can be supervised or unsupervised, meaning that they learn from human-annotated data, or they learn on their own without annotation. While supervised learning tends to yield superior results, the amount of human time and effort put into annotating is extremely expensive and not always practical. Especially when considering the popularity of big data, few researchers have the time to put into annotating and therefore unsupervised learning has become more popular in recent years. Slowly but surely, unsupervised learning is evolving and becoming more and more accurate. One field that would benefit greatly from computational classification techniques is the biomedical domain. Medical resources are rich in information and many of them are available publicly, such as medical journals published on PubMed and Medline, two online databases for medical and clinical scholarly texts. However, clinical data is much more difficult to come by given issues with privacy and consent. Despite this, there are publicly available datasets which are large enough to construct more complicated systems, such as neural networks. There is a true need for research in biomedical and clinical texts not only as a practical task for computational classification, but a life saving one too. Artificial intelligence systems such as IBM Watson use classification in tasks to help physicians provide top care for their patients. It would be humanly impossible to read and retain everything published in any medical subfield, but Watson can analyze thousands of documents daily. Not only can Watson maintain and update a database, but it can also help provide patients with better care by keeping doctors updated on relevant findings that may help that person. Computational classification is also useful on the clerical side of the medical field, including bettering the medical billing and coding system. Currently, medical billers and coders work with specialized vocabularies to properly annotate clinical charts to bill insurance companies. While this system is necessary, medical billers and coders are only human and can make mistakes. Automated systems for medical billing and coding has been experimented with and continues to be a difficult task to execute as well as trained professionals can. In this paper, the argument that the medical field would most definitely benefit from more computational classification applications will be made, including reviewing relevant previous general work in these algorithms, as well as their application to the medical field to date. 2.3 Previous Work Computational classification techniques have been around for decades and their application is nothing short of diverse. In this section, we will review more text-specific classification techniques, such as those that fall under machine learning and are associated with natural language processing, and have been widely tested with text. Much medical and clinical data is written text, ranging from clinical notes and patient charts to papers written in medical journals. Machine learning applications, such as classification, have a wide range of practical applications that help to make sense out of all this data. Popular classification techniques include topic modeling, neural networks, and clustering, but these algorithms often need the support of word sense disambiguation. 2.3.1 Topic Modeling Topic modeling (also formerly referred to as Latent Semantic Analysis/Indexing, LSA/LSI) is a statistical model that works at the word or sentence level to classify documents into similar categories, or by “topics”. Landauer et al wrote their 1997 paper “Introduction to Latent Semantic Analysis” as a broad introduction to Latent Semantic Analysis and its potential. Landauer et al described the method as an application for extracting and representing the semantic meaning of words by statistical computations applied to a large corpus of text. Landauer et al argue that in a way, LSA mimics human sorting and categorization of words. For example, LSA has been found to be capable of simulating human cognition by developing vocabulary to word recognition, sentence-word semantic priming, discourse comprehension, and judgement of essay quality. The knowledge derived from LSA can be described as sufficient but lacking in experience. While humans often understand their world though experience, human knowledge is not limited to experience-only learning. LSA’s uniqueness is not just limited to its comparability to human learning, but also because it is unlike other traditional natural language processing or artificial intelligence applications of its time. LSA takes raw text as input and does not utilize dictionaries, knowledge bases, semantic networks, grammars, syntactic parsers, or morphology. Instead, the raw text is parsed into words represented as unique character strings and are then organized into a matrix where each row is a unique word and each column is text passage (most typically documents), and singular value decomposition is applied to the matrix. Landauer et al tested their LSA on multiple judgment tasks and reported good performance but concluded that LSA lacks the necessity of raw experience that makes it somewhat incomparable to human cognition. However, as an overall computational classification technique, LSA did lead the way for more sophisticated topic modeling. Even just two years after the publication of “An Introduction to Latent Semantic Analysis”, the paper “Latent Semantic Indexing: A Probabilistic Analysis” by Papadimitriou et al sought to improve LSA by introducing the technique of random projection. Random Projection is a mathematical application used to reduce dimensionality, which Papadimitriou et al believed would increase speed while maintaining accuracy. The application of random projection to the initial corpus by Papadimitriou et al was intended to reduce the bottleneck that often comes with LSI, which they achieved with some success. While the model performed faster, Papadimitriou et al were somewhat dissatisfied with the LSI performance. Both Papadimitriou et al and Landauer et al agreed that LSA is somewhat lacking in polysemy and synonymy. The bag of words model employed by LSA could be to blame, given that bag of words considers the context in which words appears independent from the word itself. Despite the effort that LSA puts forward in classifying documents and retrieving relevant information, LSA is indeed limited in disambiguating word senses. More recent versions of LSA, now called topic models, have attempted to address these issues with polysemy and synonymy. Wallach attempted to bridge this gap in her 2006 paper “Topic Modeling: Beyond Bag-of- Words” by employing both bag of words and n-gram statistics. She extended Latent Dirichlet allocation (Blei et al., 2003), which represents documents as random mixtures over latent topics, where each topic is characterized by a distribution over words, by introducing a bigram model that takes word order into account. Her results showed that the predictive accuracy of her model is significantly better than that of either latent Dirichlet allocation or the hierarchical Dirichlet language model. Also, her model automatically infers a separate topic for function words, meaning that the other topics are less dominated by these words. This contribution is especially important because Wallach’s model uses a larger number of topics than either Dirichlet model and has a greater information rate reduction as more topics are added, again while being able to maintain accuracy. 2.3.2 Neural Networks Another popular application for text analysis and classification is neural networks. Neural networks are currently very popular for their speed and accuracy across many applications. Partially responsible for the rise of neural network applications in natural language processing of late is the popular Word2Vec model from Mikolov et al of Google. Mikolov el al published their paper “Efficient Estimation of Word Representation in Vector Space” and made the Word2Vec algorithm publicly available in 2013. Part of Word2Vec’s attractiveness is the speed in which the word vectors are developed. This is due to the structure in which the word vectors are derived, which are shallow neural networks. The Word2Vec model creates a two-layer network, in which one layer is hidden. This structure is supported by the log linear architectures proposed by Mikolov et al that learns distributed representations of words while minimizing computational complexity. This includes a continuous bag of words model (CBOW) and a continuous skip- gram model. The CBOW architecture is like that of a feedforward neural net language model where the non-linear hidden layer is removed, and the projection layer is shared for all words. Therefore, all words get projected in the same position their vectors are averaged. The continuous skip-gram model is like the CBOW model, but instead tries to maximize classification of a word based on another word in the same sentence. Each current word is used as input to a log-linear classifier with a continuous projection layer. The word vectors returned are capable of various tasks, such as generating similar words and deciding which word does not belong to the set. Perhaps the most interesting contribution of the Word2Vec model is the ability to conceptualize words. This is explained best through the famous king and queen example. Simply, v(king) - v(man) + v(woman) = v(queen), where the vector man is taken from the vector king while adding the vector woman, which results in the vector queen. While Word2Vec’s application to natural language is more general and flexible, there exists other neural network systems that are more targeted towards specific natural language processing applications. For example, Chen et al proposed a standard neural network dependency parser that utilizes part of speech tag and arc label embeddings to yield 1,000 parses per second with a 92.2% accuracy. Since Word2Vec was released, many other algorithms have been published piggybacking off the model. For example, Sense2Vec was published two years after Word2Vec, which uses part of speech tagging to help disambiguate word sense. Trask et al argue that Word2Vec does not do enough linguistic preprocessing to accurately disambiguate words such as “duck”, which depending on the context, can either be a noun of a verb. Sense2Vec maintains Word2Vec’s general architecture but adds more linguistic features to better enhance word embeddings. Another popular natural language processing topic is morphology, which Luong et al addressed in their paper “Better Word Representations with Recursive Neural Networks for Morphology”. Luong et al argue that while vector space representations have had success over the past few years, morphological relation has been lacking. Their solution was to create a recursive neural network capable of finding word similarity and distinguishing rare words. Luong et al used both supervised and unsupervised approaches to their experiment and were able to yield comparable results between the two approaches. Neural networks continue to prove to be a practical and useful application in natural language processing and in many areas of machine classification. 2.3.3 Clustering The final computational classification technique discussed here will be clustering. Clustering is an unsupervised learning task of mapping data to find where it “clusters”, or where data situates itself to other similar data. Clustering is a popular classification technique especially since it can be performed unsupervised. Unsupervised learning techniques have become more popular in the age of the internet where researchers have a constant stream of raw, accessible data to analyze. One especially popular source is the micro blogging site Twitter, with its easy to access APIs and rich textual content. In the paper “Social Network Data Mining Using Natural Language Processing and Density Based Clustering” Khanaferov et al proposed a system to mine Twitter data for information relevant to obesity and health. Their goal of demonstrating a practical approach to solving a healthcare issue through a computational method focused on mining useful patterns out of public data. First, they used a data warehouse to complete online mining operations. The data warehouse had three distinct layers and served as step for mining processing. After the collected data was cleaned and standardized, a density-based clustering algorithm was implemented to find relevant patterns. The output resulted in sets of transactions, and each transaction included a set of search terms associated with it. To better visualize the cluster data, it was plotted onto a map using Google Maps API, which helped show that tweets coming out of the United States and Europe had a negative sentiment, while those coming out of South Asia, Canada, and Central Africa had a positive sentiment. Overall, they were able to cluster tweets in a somewhat meaningful way, although the loose relationship between healthcare and social media is a tricky one to extract meaningful results from. Cardie et al experimented with noun phrase clustering in their paper “Noun Phrase Coreference as Clustering”. They introduced a new, unsupervised algorithm for this task by approaching each group of coreferential noun phrases as an equivalent class. They identified various features in each noun phrase such as individual words, head noun, position, pronoun type, and more, then defined the distance between two nouns. The clustering algorithm applied worked backwards in the document, since noun phrases tend to reference the noun phrase preceding it. This approach was somewhat accurate in its results, ranging from 41.3%-64.9%, leaving room for improvement. 2.3.4 Word Sense Disambiguation An important distinction in computational classification of text is that of word sense disambiguation. This applies to choosing the correct sense of a polysemous word, given the context in which is occurs. Word sense disambiguation within the medical field, called biomedical text normalization, is especially relevant given the specialized nature of the data at hand. Applications of biomedical text normalization that work within a medical and clinical context may not be successfully applied to outside subjects, and vice versa. For example, the abbreviation “CA” can mean two things within the medical field: “cancer” or “carbohydrate antigen”. However, outside of the medical field, “CA” could very likely stand for “California”, or other words that have nothing to do with “cancer” or “carbohydrate antigen”. For this reason, research within biomedical text normalization is an important task that will hopefully lead to achieving higher accuracy in classification applications. Given how much medical data exists, techniques range from supervised to semi-supervised and unsupervised learning, although in recent years unsupervised learning is favored by many researchers. Tulkens et al managed to create a successful biomedical text normalization program in their paper “Using Distributed Representations to Disambiguate Biomedical and Clinical Concepts”. Their approach was an unsupervised learning method that classified concepts by clustering. To achieve this, they utilized the Word2Vec continuous skip-gram model to create their word representations. Those representations were then transformed via compositional functions to become concept vectors, essentially an entire concept representation in one vector. Every ambiguous concept tested in their experiment was defined by having more than one concept unique identifier (CUI) from the Unified Medical Language System (UMLS). Much like the “cancer” or “carbohydrate antigen” example above, the test concepts had multiple, but distinct, meanings. Tulkens et al managed to obtain between 69%-89% accuracy by transforming both the training and test data into concept vectors and measuring the cosine distance between them. In a semi-supervised approach, Siu et al experimented with semantic type classification of complex noun phrases. Often in medical text, complex noun phrases consist of specific names (diseases, drugs, etc.) and common words such as “condition”, “degree”, or “process”. The common words can have different semantic types depending on their context in the noun phrase, and in their experiment Siu et al attempted to classify these common words into fine-grained semantic types. Siu et al argue that it is crucial to consider these common nouns in information extraction because while they can carry biomedical meaning, but they can also be used in a general, uninformative sense. Their semi- supervised method labeled target words within a noun phrase with its suitable semantic type or tagging it as uninformative. Experiments with this method yielded a 91.34% micro-average and an 83.57% macro-average over 50 frequently appearing target words. Another unsupervised approach to biomedical word sense disambiguation is that of Henry et al in their paper “Evaluation Feature Extraction Methods for Knowledge-Based Biomedical Word Sense Disambiguation”. They compared vector representations in the 2-MRD WSD algorithm and evaluated four dimensionality reduction methods: continuous bag of words and skip-gram, singular value decomposition, and principal component analysis. Like Tulkens et al, Henry et al also measured their accuracy with cosine similarity. Singular value decomposition performed well in their experiments, however it may not do as well with larger data sets. Regarding dimensionality, low vector dimensionality was sufficient for the continuous bag of words and skip-gram models, but higher dimensionality achieved better results for singular value decomposition. Although principle component analysis is commonly used for dimensionality reduction, in this case it did not improve results for word sense disambiguation. Regardless of the method, normalization of biomedical and clinical text remains a nuanced and necessary step in processing for information retrieval and document classification. Part of the urgency to make advancements in this task is the fact that computational methods are being applied to medical and clinical data every day. Their effectiveness relies on the ability to properly disambiguate terms and classify accurately, as a human would, otherwise they could be rendered useless. 2.4 Medical and Clinical Applications Computational classification techniques have been applied to medical data for years in hope of contributing to new methods for helping patients by identifying and diagnosing diseases, as well as preventing illnesses from occurring in the first place. This work is predictive and requires copious amounts of data to be proven effective. Just like with any other computational classification technique, there are both supervised and unsupervised approaches to the task. Since there is an ever-growing amount of medical data available, many researchers are turning to semi- supervised and unsupervised techniques to wrangle more data in a more efficient amount of time. While supervised learning is extremely practical and yields highly accurate results, there is always the cost of annotating data. Annotation must be conducted by people and given the size of the data set or task, can be very time consuming. In this section, we will review various contributions researchers are making to the biomedical natural language processing community and the techniques they use. The ability for a computer or artificial intelligence to aid health care providers in diagnosing patients sounds like something out of a science fiction novel. However, experimental applications for machine diagnosis have become popular in recent years by taking medical data from patients that have specific ailments and using their history to learn models that can predict this occurrence in future patients. Apostolova et al sought to create a system to detect sepsis and septic shock in patients early when treatment is effective. They report that sepsis has an approximate 50% mortality rate worldwide, and often the infection can be detected through clues in nurses’ notes. Using the MIMIC-III corpus, a publicly available data set from ICU patients, alone was unsuccessful. However, once they noticed that when a patient has and infection or is suspected of having one, nurses tend to mention that they are on an antibiotic. Using this heuristic along with a list of commonly prescribed antibiotics, they were able to extract the language used to describe the patient’s state when they had an infection. These notes with infection-hinting and infection-confirmed language were used in combination with notes where infection was not present as training data to train Support Vector Machines (SVM), a type of unsupervised clustering machine learning algorithm, in binary classification of these free-form notes. Using this technique, they were able to achieve an F1-score ranging between 79%-96%. These results are a good start to their end goal of creating an automated system for detecting early sepsis in at risk patients. SVMs have also been experimented with for cancer diagnosis with mixed reviews. In one paper from 2002, “Gene Selection for Cancer Classification Using Support Vector Machines”, Guyon et al proposed a method to make sense out of the massive amount of data DNA microarrays generate. Briefly, DNA microarrays are microscopic collections of DNA attached to a surface. The task researchers use them for is to classify and predict the diagnostic category of a sample based on its gene expression profile; in this case, the expression is cancer. Guyon et al used samples from both cancer patients and patients without cancer to train their model, an SVM based on Recursive Feature Elimination, which uses weight magnitude as ranking criterion. Their technique was able to extract biologically relevant genes from patients with colon cancer or leukemia and yielded a high classification accuracy of 98% accuracy in colon cancer compared to the 86% of the baseline system. Guyon el al argued that SVMs lend themselves well to this type of gene classification because of their ability to easily handle large feature sets (here, thousands of genes) and a small number of patterns (dozens of patients). However, Koo et al argued in their 2006 paper “Structured polychotomous machine diagnosis of multiple cancer types using gene expression” that even though SVMs are a popular and accurate classification technique, their results are implicit and therefore difficult to interpret. In attempts to change this drawback, Koo et all proposed an extension of import vector machines by using an analysis of variance decomposition and structured kernels, called the structured polychotomous machine. Import vector machines are like SVMs, but they are typically computationally cheaper than SVMs and can provide estimates for posterior probabilities. The DNA microarray data Koo et al used came from a few sources, including the small round blue cell tumor data set and a leukemia data set. They wanted to create a system that not only improved upon import vector machines, but they also wanted to provide a method for finding genes that accurately discriminate cancer subtypes. Overall, Koo et al were able to achieve 0% error rates and their method was able to select a smaller set of genes and successfully classify among samples. Their model also outperformed the SVM baseline in several tests, as they expected. As seen in these two comparative studies, robust machine learning systems are necessary for biomedical classification applications. DNA microarrays are one example of an expensive data set commonly used in biomedical classification techniques, however one other commonly used data source is that of Twitter. Mentioned earlier in this paper, Twitter is a frequently used source for text data. In a study from Nadeem et al, “Identifying Depression on Twitter”, data was crowdsourced from Twitter users who have been diagnosed with Major Depressive Disorder in efforts to measure and predict depression in users. From these users, along with a general demographic, tweets from up to a year prior were extracted and a bag of words model was applied to quantify each tweet. Finally, statistical classifiers were applied to the tweets to analyze the risk of depression. Linguistic features were extracted from the tweets of those with depression as an attempt to see what language people with depression use that varies from the language of those who don’t. From this analysis, Nadeem et al found approximately 20 words (and one sad-face emoticon) that were used at a much higher rate in depressed users. Nadeem et al employed the use of Decision Tree, Support Vector Machine, Logistic Regression, Ridge Classifier, and two Naïve Bayes classifiers. Of the six, the Logistic Regression classifier had the highest precision and F1-score, while the SVM had the highest recall and the Naïve Bayes with 1-gram had the highest overall accuracy of 86%. The statistical classifiers here were trained with supervised learning, resulting in accuracies comparable to the unsupervised experiments of Koo et al and Guyon et al. Both methods proved to be useful and accurate in their classification tasks of diagnosing disease. Like the goal of Nadeem et al, Gorrell et al attempted to identify first episodes of psychosis in psychiatric patient records in their experiment. They filtered thousands of records and obtained 9,109 individual clinical records. Of those, 560 screened positive for psychosis, 5,234 screened negative (but remained at risk) and 3,315 were excluded for various reasons. Gorrell et al chose to use SVM, Random Forests, and JRip algorithms to classify their data for speed and accuracy reasons. They used two- and three-fold validation to define their features. Three-fold features included missing demographic information, such as borough, ethnicity, gender, postcode, first primary diagnosis, and age. However, where available, first primary diagnosis was included (bipolar hypomanic/unspecified and severe depressive with psychotic symptoms). Text features included in three-fold validation consisted of “olanzapine”, “risperidone”, “auditory hallucinations”, “voices”, “paranoid”, “psychotic” and “psychosis”. Two-fold validated features were somewhat less specific, including first primary diagnosis (bipolar, organic delusional schizophrenia-like disorder, organic mood disorder), and text features such as “aripiprazole”, “quetiapine”, “persecutory”, and “schizophrenia”. The three algorithms chosen along with varying feature set size obtained decent results, ranging from 66.46%-82.2%. Surprisingly, the Random Forests classifier had both the weakest and strongest accuracy, scoring 66.46% accuracy with the full feature set size plus unigrams, and an 82.2% accuracy with a reduced feature set size. While text classification is a useful tool in diagnosing depression and other mental illnesses, researchers have also experimented with multimodal tools to identify and classify these illnesses. Morales et al explored this technique in “OpenMM: An Open-source Multimodal Feature Extraction Tool” where they used text, speech, and face mapping features to identify depression in individuals. Morales et al argue that to usefully model situational awareness, machines must have access to the same visual and verbal cues that humans have. To do this, Morales et al built a pipeline to extract visual and acoustic features that performed automatic speech recognition and use that data to transcribe and extract relevant linguistic features. OpenMM was tested on deception, depression, and sentiment classification showing promising results. Depression detection had a baseline of 55.36% accuracy, and OpenMM’s acoustic feature set was able to produce an accuracy of 76.79%. OpenMM is publicly available for other researchers to experiment with and build upon, which is necessary for making use of all these classification techniques. Like the ability of machines to diagnose disease, machine learning can also be leveraged to help prevent disease by developing predictive models. This goal can be successfully obtained through text mining techniques on clinical and medical data. Jacobson et al experimented with detecting healthcare-associated infections in patients by applying deep learning techniques to Swedish medical records. The Swedish Health Record Research Bank data obtained contained two million patient records from over 800 clinical units between 2006 and 2014. They also used the special subset Stockholm EPR Detect-HAI Corpus which contains 213 patient records and classified by two domain experts and gold annotated. After the necessary preprocessing of the data, the records were transformed into numerical vectors, one of which being bag of words and tf-idf representations, the other Word2Vec word vectors. Artificial neural networks were then built from these models, including stacked sparse auto encoders and stacked restricted Boltzmann machines. The results were somewhat diverse, ranging from 66% to 91%, but most of the scores hovered between 70%-80%. Jacobson et al admitted that deep learning techniques are often expensive to train and usually researchers sacrifice some agility for increased accuracy, which was unfortunately not seen in this experiment. Despite the shortcomings, this research is still incredibly useful and future work is promising. Having a broad range of potential diseases to identify and classify is attractive, but narrow topics are also necessary. To this point, Abdinurova et al sought to create a model that could classify epilepsy, namely, the various stages of it. The stages of epilepsy include absence of seizure, pre-seizure, seizure, and seizure-free and are all used in clinical data. Their system utilized artificial neural networks and SVMs combined with supervised learning algorithms, and k-means clustering combined with unsupervised techniques. The result from these various techniques experimented with showed favorable results, all with high accuracies. As expected, the supervised methods performed better than their unsupervised counterparts, however the unsupervised results were not drastically worse. This experiment is an excellent comparison of state of the art supervised and unsupervised learning tasks and proves that both methods can yield comparable results. In addition to being excellent classification systems, the models also performed well on information retrieval tasks, an important function of machine classification. 2.5 Clerical Applications Computational classification can also be applied to clerical work in the medical field. Currently, medical billers and coders are used to review doctor’s notes and patient charts, annotate them for relevant information, and send that information to insurance companies for the proper billing. Medical billers and coders are skilled people who are trained in vocabularies of the Unified Medical Language System (UMLS), which includes the International Classification of Diseases (ICD) and Current Procedure Terminology (CPT), among others. These vocabularies are used to unambiguously identify various medical concepts for insurance companies to know exactly what their customer visited the doctor for, so they can be billed accordingly. While medical billers and coders are necessary to the modern healthcare system, they can make mistakes in their annotations, and efficiency and always be improved. Researchers have been applying computational classification methods to medical billing and coding problems to create systems to automate these tasks. Karimi et al have experimented with such tasks in their paper “Automatic Diagnosis Coding of Radiology Reports: A Comparison of Deep Learning and Conventional Classification Methods”. Their system seeks to apply deep learning to auto-coding of radiology reports using the ICD vocabulary and to see how deep learning fares with a smaller data set. Interestingly, they chose to use both domain-specific and out-of-domain data for their training sets. The in-domain set was ICD9, a data set of radiology reports, and the out-of-domain set was IMDB, a movie review data set for sentiment analysis. Their best deep learning neural network classification result was comparable to that of the SVM and logistic regression classifiers also used in this experiment. Automatic billing and coding classification systems have been attempted by other researchers, including Pestian et al in their paper “A Shared Task Involving Multi-label Classification of Clinical Free Text”. In this experiment, Pestian et al sought to use ICD codes to annotate clinical data, much like a medical biller and coder would manually, but instead they used classification techniques and text extraction techniques to pull relevant information from the clinical data and label it with an ICD code, then store it in XML schema. This approach was reasonably successful, but still not as accurate as a manual coder overall. Another popular medical vocabulary from the UMLS often used in computational classification are Concept Unique Identifiers, or CUIs. Mentioned earlier in this paper, CUI codes are used to map unique concepts to specific codes describing them. CUIs are meant to eliminate ambiguity amongst terms, especially abbreviations and acronyms. CUI codes are used in medical billing and coding, but they are more widely used in medical journal databases such as PubMed and Medline. Jimeno-Yepes et al created a test data set from medical subject headings (MeSH) of Medline articles to extract 203 ambiguous terms, including abbreviations and acronyms. All 203 terms had at least two CUI codes that they could be associated with and the proper term depended on the context. For example, the ambiguous acronym “AA” had two associated CUI codes, one for “alcoholics anonymous” and another for “amino acid”. Jimeno-Yepes et al then found approximately 200 Medline abstracts for each ambiguous term and tagged them with the proper CUI code. They called their final data set “MSH-WSD”, standing for MeSH word sense disambiguation. The MSH-WSD data set is now a popular test dataset in the biomedical text normalization community. A similar application of classifying ambiguous acronyms in the UMLS was studied by Liu et al in their paper “A Study of Abbreviations in the UMLS”. Liu et al took advantage of the typical format in many papers where an abbreviation was introduced with its expanded form in parentheses next to it. Using this method, they were able to extract 163,666 unique abbreviations and their full forms from the UMLS with a precision of 97.5% and a recall of 96%. About 33% of the abbreviations extracted were ambiguous with six or less characters and multiple possible meanings. This method for extracting abbreviations and full forms of terms has been applied by other researchers, including Jimeno-Yepes et al, where they created the MSH-WSD data set. Clerical tasks are not limited to medical billing and coding in the clinical field; patients often answer various questions regarding their chart and family history at their doctor’s visit. Llanos et al proposed an automatic classification system of doctor-patient questions where they focused on such questions that would need to be looked up in a chart, such as “do you cough every day?” or “are your parents still alive?”. Questions were classified as rule-based, for example, “do you cough every day?” has the semantic annotation of “symptom” and “frequency”. To test question understanding in hopes of being able to eventually give responses, Llanos et al used a linear SVM and two Naïve Bayes classifiers (Multinomial and Gaussian). Their results across all classifiers were comparable, ranging between 65%-87%. Such applications of classifying questions and answers can help for future applications, such as remote question-answering where a patient has a question, but their physician isn’t available. 2.6 Real World Applications and Future Work Arguably the most famous example of artificial intelligence is IBM Watson. Ever since competing in both high-stakes chess and the game show Jeopardy!, Watson has applied its skills to more than just strategy games. Currently Watson has taken to oncology and is helping doctors and researchers diagnose cancer. The motivation behind Watson’s involvement is that oncologists need to stay up to date n the latest cancer research and studies for the maximum benefit of their patients. However, there are thousands of medical journals that publish oncological studies daily, and no one person could possibly keep up with them all. Instead, Watson has been trained to maintain a database of sorts for relevant information regarding cancer research that can be used as a supercomputer for physicians to give their patients the best care possible. Doyle-Lindrud explains in “Watson Will See You Now: A Supercomputer to Help Clinicians Make Informed Treatment Decisions” that Watson has paired with big hospitals and healthcare companies around the country including Memorial Sloan Kettering Cancer Center, the University of Texas MD Anderson Cancer Center, and WellPoint, Inc. In all these locations, Watson has been used as a tool to help customize patient care with the best possible treatment options by analyzing and ranking medical literature to rank potential treatment options based on evidence. Along with oncology, Watson has participated in other experiments meant to benefit patients. Chen et al (2) described various studies that Watson has been a part of, including a drug repurposing study where Watson looked for drugs approved for human use and then cross referenced those drugs with statements suggesting efficacy in treating malaria. After obtaining this final list of cross referenced drugs, Watson then looked at the company’s existing compounds and identified similarities to known malaria treatments in hopes of finding drugs that may not have been intended to treat malaria, but possibly could. Watson also participated in a study at Baylor College of Medicine aimed to enhance insight on cancer kinases. First, Watson read articles discussing known kinases, then with graph and text-based features, Watson found text similarity patterns between kinases. Those models were then applied to Medline abstracts through 2002 to determine whether Watson could identify kinases discovered in 2003 through 2013. Watson was able to identify nine potential kinases successfully, and of these, Baylor validated seven. Watson’s clinical knowledge is a good example of machine classification and information retrieval put to good and accurate use. Watson is a valuable tool for many physicians and its knowledge is expanding daily which will hopefully help save more lives. 2.7 Conclusion The need and application for computational classification techniques in the medical and clinical domain are diverse, however, these systems are only as useful as their computational intelligence. Obtaining accuracies in the 70s and 80s range is a good start, but higher accuracy is needed to be an impactful industry standard. Outside of the clinical application, machine intelligence is being tested by any person with a smart phone. There is a difference between asking Siri what the symptoms of a heart attack are versus asking Siri to call emergency services because you are having a heart attack. It is possible for Siri to call emergency services for you with various commands, such as “call emergency services”, “dial 911”, or “phone 911” among others (OS X Daily), but the distinction is discrete and vital to correctly make. While it may seem small, the need for machines to understand the simple difference between phrases like “Siri, what are the symptoms of a heart attack?” and “Siri, I’m having a heart attack” are just as important as the biomedical classification techniques discussed in this paper. All the techniques and systems reviewed are extremely important for driving efficiency and accuracy in the medical field where mistakes and oversight is rarely forgiven. By providing health care professionals with dependable, robust systems, hopefully more people can be helped, and more institutions can have systems like Watson helping them make diagnostic decisions. Big data will surely remain a buzzword for years to come but embracing the practical use of big data can be difficult. The medical field is often regarded as a groundbreaking one, but professionals in the field can be slow to embrace such advancements. Trusting computers to manage our data and help us make informed decisions lies in ensuring top results and allowing little room for error. For this reason, computational classification of biomedical and clinical concepts is a crucial foundational layer that needs to be standardized. Only when a computational system can classify data correctly, can other important results be produced from that data. Technology is ever-changing and ever- expanding, and hopefully with more advancements in computational classification techniques and achievable replication of results, more computational systems will be developed and trusted to help improve our health and save lives. 2.8 References Blei, D. M., Ng, A. Y., &amp; Jordan, M. I. (2003). Latent Dirichlet allocation. Journal of Machine Learning Research, 3, 993–1022. Abdinurova, Nazgul, et al. “Classification of Epilepsy Using Computational Intelligence Techniques.” 2015 Twelve International Conference on Electronics Computer and Computation (ICECCO), 2015, doi:10.1109/icecco.2015.7416877. Apostolova, Emilia, and Tom Velez. “Toward Automated Early Sepsis Alerting: Identifying Infection Patients from Nursing Notes.” BioNLP 2017, 2017, doi:10.18653/v1/w17-2332. Cardie, Claire, and Kiri Wagstaff. “Noun Phrase Coreference as Clustering .”Association for Computational Linguistics. Chen, Danqi, and Christopher D Manning (1). “A Fast and Accurate Dependency Parser Using Neural Networks.” Association for Computational Linguistics, www.aclweb.org/anthology/D14-1082. Chen, Ying, et al. “IBM Watson: How Cognitive Computing Can Be Applied to Big Data Challenges in Life Sciences Research.” Clinical Therapeutics, vol. 38, no. 4, 2016, pp. 688–701., doi:10.1016/j.clinthera.2015.12.001. Doyle-Lindrud, S. “Watson Will See You Now: a Supercomputer to Help Clinicians Make Informed Treatment Decisions.” Clinical Journal of Oncology Nursing., U.S. National Library of Medicine, Feb. 2015, www.ncbi.nlm.nih.gov/pubmed/25689646. Gorrell, Genevieve, et al. “Identifying First Episodes of Psychosis in Psychiatric Patient Records Using Machine Learning.” Association for Computational Linguistics, www.aclweb.org/anthology/W/W16/W16-2927.pdf. Guyon, I., Weston, J., Barnhill, S. et al. “Gene Selection for Cancer Classification Using Support Vector Machines”. Machine Learning (2002) 46: 389.https://doi.org/10.1023/A:1012487302797 Henry, Sam, et al. “Evaluating Feature Extraction Methods for Knowledge-Based Biomedical Word Sense Disambiguation.” BioNLP 2017, 2017, doi:10.18653/v1/w17-2334. Jacobson, Olof, and Hercules Dalianis. “Applying Deep Learning on Electronic Health Records in Swedish to Predict Healthcare-Associated Infections.” Proceedings of the 15th Workshop on Biomedical Natural Language Processing, 2016, doi:10.18653/v1/w16-2926. Jimeno-Yepes, Antonio J, et al. “Exploiting MeSH Indexing in MEDLINE to Generate a Data Set for Word Sense Disambiguation.” BMC Bioinformatics, vol. 12, no. 1, 2011, p. 223., doi:10.1186/1471-2105-12-223. Karimi, Sarvnaz, et al. “Automatic Diagnosis Coding of Radiology Reports: A Comparison of Deep Learning and Conventional Classification Methods.” BioNLP 2017, 2017, doi:10.18653/v1/w17-2342. Khanaferov, David, et al. “Social Network Data Mining Using Natural Language Processing and Density Based Clustering.” 2014 IEEE International Conference on Semantic Computing, 2014, doi:10.1109/icsc.2014.48. Koo, J.-Y., et al. “Structured Polychotomous Machine Diagnosis of Multiple Cancer Types Using Gene Expression.” Bioinformatics, vol. 22, no. 8, 2006, pp. 950–958., doi:10.1093/bioinformatics/btl029. Landauer, T. K., Foltz, P. W., &amp; Laham, D. (1998). Introduction to Latent Semantic Analysis. Discourse Processes, 25, 259-284. Luong, Minh-Thang, et al. “Better Word Representations with Recursive Neural Networks for Morphology.” Association for Computational Linguistics, www.aclweb.rog/anthology/W13- 3512. Llanos, Leonardo Campillos, et al. “Automatic Classification of Doctor-Patient Questions for a Virtual Patient Record Query Task.” Association for Computational Linguistics, http://www.aclweb.org/anthology/W/W17/W17-2343.pdf. Liu, H., Y. A. Lussier, and C. Friedman. “A Study of Abbreviations in the UMLS.” Proceedings of the AMIA Symposium (2001): 393–397. Print. Mikolov, Tomas et al. “Efficient Estimation of Word Representations in Vector Space.” CoRR abs/1301.3781 (2013): n. pag. Morales, Michelle Renee et al. “OpenMM: An Open-Source Multimodal Feature Extraction Tool.” INTERSPEECH (2017). Nadeem, Moin, et al. “Identifying Depression on Twitter.” ArXiv:1607.07384v1, 25 July 2016, arxiv.org/abs/1607.07384. Papadimitriou, Christos H. et al. “Latent Semantic Indexing: A Probabilistic Analysis.” J. Comput. Syst. Sci. 61 (1998): 217-235. Pestian, John P., et al. “A Shared Task Involving Multi-Label Classification of Clinical Free Text.” Proceedings of the Workshop on BioNLP 2007 Biological, Translational, and Clinical Language Processing - BioNLP ’07, 2007, doi:10.3115/1572392.1572411. “Siri Can Call Emergency Services For You with IPhone If Need Be.” OS X Daily, 20 Mar. 2017, osxdaily.com/2015/07/17/siri-call-emergency-services-iphone/. Trask, Andrew, et al. “sense2vec - A Fast and Accurate Method for Word Sense Disambiguation In Neural Word Embeddings.” 19 Nov. 2015, arxiv.org/abs/1511.06388. Tulkens, Stephan, et al. “Using Distributed Representations to Disambiguate Biomedical and Clinical Concepts.” Proceedings of the 15th Workshop on Biomedical Natural Language Processing, 2016, doi:10.18653/v1/w16-2910. “UMLS - Metathesaurus.” U.S. National Library of Medicine, National Institutes of Health, 12 Apr. 2016, www.nlm.nih.gov/research/umls/knowledge_sources/metathesaurus/. Wallach, Hanna M. “Topic Modeling: beyond Bag-of-Words.” ACM, Conference: Machine Learning, Proceedings of the Twenty-Third International Conference (ICML 2006), 25 June 2006, dl.acm.org/citation.cfm?doid=1143844.1143967. “What Is Medical Billing and Coding?” MedicalBillingAndCoding.org, MedicalBillingAndCoding.org, 2018, www.medicalbillingandcoding.org/medical-billing-coding/. "],
["sonification-and-augmented-cognition-a-brief-overview.html", "Chapter 3 Sonification and augmented cognition: A brief overview 3.1 Types of sonification. 3.2 Why sonify non-sonic information? 3.3 Using sonification to augment cognition 3.4 References", " Chapter 3 Sonification and augmented cognition: A brief overview Nicholaus P. Brosowsky, The Graduate Center of the City University of New York In the most general sense, sonification refers to the transformation of non-sonic data into audible (non-speech) sound to represent or convey information to a listener. Thus, sonification is a rather general, all-encompassing umbrella term that might include everything from fire alarms, stethoscopes and Geiger counters, to Stravinsky’s The Rite of Spring and John Cage’s 4’33”. Though there has been recent attempts to more firmly define sonification as a discipline (e.g., Hermann, Hunt, &amp; Neuhoff, 2011; Nees &amp; Walker, 2009), for better or worse, sonification straddles the boundaries of science, art, design, and application. To better situate this review, I will focus on the ways in which sonification could be used as a tool to enhance or augment cognition. Specifically, I focus on three areas: situational awareness, perception and action in motor skills, and data analysis. But before doing so, I will provide a brief outline of the types of sonification previous work has identified and the general rationale for adopting sonification methods at all. 3.1 Types of sonification. One taxonomy of sonification (for others, see Fitch &amp; Kramer, 1994; Nees &amp; Walker, 2009), distinguishes between five functions of sonification: alerting, status indication, data exploration and, art and entertainment (for more in-depth reviews, see (Hermann et al., 2011; Walker &amp; Kramer, 2004). Alerts refer to sounds that notify the listener that an event has, or is about to occur, and that something in the environment requires their attention. These range from rather simple, low-information alerts like a door-bell, indicating someone is at the door; to more complex alerts that attempt to convey more information, like warning systems in a helicopter cockpit indicating a range of telemetry and avionics data (Edworthy, Hellier, Aldrich, &amp; Loxley, 2004) or forward collision systems in modern cars (P. Bazilinskyy, Petermeijer, Petrovych, Dodou, &amp; De Winter, 2015; Jamson, Lai, &amp; Carsten, 2008). Closely related to the alerting function, is the status or progress indicating function. In this case a listener monitors a constant sound for small changes that indicate a change in status or progress update. For example, using auditory displays to monitor for changes in blood pressure (T. Watson &amp; Lip, 2006), internet network traffic (Debashi &amp; Vickers, 2018; Vickers, Laing, &amp; Fairfax, 2017), or telephone hold time (Garcia, Peres, Ritchey, Kortum, &amp; Stallmann, 2011; Kortum, Peres, Knott, &amp; Bushey, 2005). Data exploration is likely the function most closely associated with the term sonification. Simply put, sound is used to represent data in a way that enables the listener to recognize or search for patterns. This includes auditory graphs, created to summarize and communicate a set of data with known patterns (e.g., Flowers, 2005; Stockman, Nickerson, &amp; Hind, 2005; Walker &amp; Mauney, 2010), or as a way to explore more complex data sets to facilitate interpretation and exploratory analyses (e.g., Grond &amp; Hermann, 2014; Stanton, 2015). Data exploration and pattern recognition will be discussed in greater detail below, however data sonification has been used successfully across a range scientific disciplines from astronomy (Diaz Merced, 2013; W. L. Diaz-Merced et al., 2011) to the social sciences (Dayé &amp; de Campo, 2006). To give just one example, Pereverzev, Loshak, Backhaus, Davis, &amp; Packard (1997) used sonification methods to discover quantum oscillations between two weakly coupled reservoirs of superfluid helium 3, confirming previous theoretical predictions. Finally, sonification can be used for entertainment, art, sports, and leisure. That is, sonification can be used for artistic expression and/or recreation. This final category includes the creation audio-only versions of games (i.e., sonified games) like Tower of Hanoi (Winberg &amp; Hellstrom, 2001) and Tic-Tac-Toe (Targett &amp; Fernstrom, 2003), as well as using sonified feedback to improve performance in sports like rowing (Dubus &amp; Bresin, 2015) and figure-skating (Boyd &amp; Godbout, 2010). Perhaps unsurprisingly, musical composition is another popular use of sonification methods. Here, often large data sets (e.g., weather changes, shark movements, seismic data) are mapped to musical representations to create works of art (e.g., Ballora, 2014; Parkinson &amp; Tanaka, 2013; Quinn, 2001, 2012). In one demonstration, for example, a century of weather data was transformed into compositions for cello and string quartets to describe and communicate climate change (George, Crawford, Reubold, &amp; Giorgi, 2017). In another, DNA sequences were used to compose music in an effort to summarize complex microbial ecology data (“Microbial Bebop”; Larsen, 2016). The line between artistic expression and data display is obviously blurred here. However, in these cases, the primary goal is to create an aesthetically pleasing work of art and communicating an interpretation of the data, if considered at all, is secondary. 3.2 Why sonify non-sonic information? Since visual display has become the dominant form of communicating data, one might wonder why we would consider auditory display and sonification at all. This issues has been discussed fairly extensively in various contexts (e.g., Hermann et al., 2011; Kramer, 2000; Nees &amp; Walker, 2009; Sanderson, 2006). Briefly however, the auditory system excels and perhaps outperforms the visual system, in a number of important ways that are relevant to auditory display and sonification. For one, the auditory system excels at detecting rhythmic and temporal changes. For example, we can perceptually separate two brief sounds like finger snap or metronome tick with as little as five milliseconds separating them; far better than the 35-40 milliseconds required by the visual system (Ashmead, Leroy, &amp; Odom, 1990; Gfeller, Woodworth, Robin, Witt, &amp; Knutson, 1997; Tervaniemi &amp; Brattico, 2004). Therefore, more information can be displayed in audition, compressed at a higher rate, and still maintain discriminability. Similarly, the auditory system is highly sensitive to temporal changes and pattern deviations (Escera, Alho, Winkler, &amp; Näätänen, 1998; Näätänen, Paavilainen, Rinne, &amp; Alho, 2007). As a result, auditory display may be well-suited to data sets that contain complex patterns and temporal changes. More practically speaking, audition is omnidirectional, not requiring the listener to be oriented towards the display. This is especially important given that most of our primary tasks in our work environments are visual, restricting our ability to orient to other displays. Therefore, adding more visual information may be inappropriate because the visual system might already be occupied (Fitch &amp; Kramer, 1994; Wickens &amp; Liu, 1988) or, by adding additional visual displays, we may be overtaxing an already overburdened visual system (M. L. Brown, Newsome, &amp; Glinert, 1989). Additionally, we are able time-share multiple tasks more efficiently when they are presented in different modalities (Driver, 2001; Driver &amp; Spence, 1998; Wickens, 2002; Wickens, Parasuraman, &amp; Davies, 1984). Therefore, sonification presents an opportunity to present additional information and augment task performance without interfering with, or overloading the visual system. 3.3 Using sonification to augment cognition 3.3.1 Perception, attention, and situational awareness One way in which sonification could be used to enhance or augment cognition, is by improving situational awareness. Here I refer to situational awareness broadly, as maintaining conscious knowledge of the immediate environment and all the events happening within it. Our ability to maintain situational awareness, while obviously important for many tasks, is limited not only by what information is available in the environment, but also by our ability to process it (e.g., capacity limitations in working memory, attention, perception, etc.). Work in this area has demonstrated some success in improving situational awareness and task performance by using sonification to facilitate attention and perception processes. Attention is perhaps the most obvious way sonification could be used to improve situational awareness, and the most easily demonstrated. Maintaining situational awareness in complex environments requires that we constantly monitor multiple streams of information. One obvious way to facilitate situational awareness is to offload the monitoring task using auditory alerts or alarms (Hermann et al., 2011; Nees &amp; Walker, 2009). The ubiquity of auditory alarms, from phone alerts to emergency vehicle sirens, makes it easy to over-look. However, they provide an easy way to offload what would be cognitively demanding task (i.e., vigilance or prospective memory), allowing the listener to engage in other tasks. The use of complex auditory alarms has proven useful in a range of settings and tasks including medical or patient monitoring (Cabrera, Ferguson, &amp; Laing, 2005), air-traffic controllers (Cabrera et al., 2005), and piloting aircraft (Edworthy et al., 2004). Situational awareness in complex environments can be difficult because of the overwhelming amount of information and our limitations in dividing attention. Another way that sonification can aid situational awareness is by transforming multiple streams of information into a more useful, easier-to-manage format for real-time monitoring. There are two fields that have demonstrated the usefulness of sonification tools to facilitate situational awareness by overcoming limitations in divided attention: computer-network traffic monitoring and anesthesiology. Computer network administrators must monitor flow of traffic in real-time to identify anomalous events like drops in traffic that may reflect hardware failures, or sudden increases in certain types of traffic that could reflect network intrusions (Axon, Alahmadi, Nurse, Goldsmith, &amp; Creese, 2018). Given the large amount of data the network receives every second, the data needs to be aggregated in a way that allows for real-time monitoring. Sonification tools have been shown to be useful for this purpose, demonstrating that listeners can detect network intrusions and anomalous changes in network activity using different sonification methods (e.g., Ballora, Giacobe, &amp; Hall, 2011; Debashi &amp; Vickers, 2018; Vickers, Laing, Debashi, &amp; Fairfax, 2014; Vickers et al., 2017). For example, Qi, Martin, Kapralos, Green, &amp; García-Ruiz (2007) mapped various network traffic data to piano sounds that allowed listeners to detect different types of network intrusions and Gilfix and Couch (2000) mapped network traffic to naturalistic sounds (e.g., chirping, heartbeats) which allowed listeners to detect anomalies in network traffic. Similarly, anesthesiologists are faced with a similar problem. They need to monitor multiple streams of information about the patient in real-time (e.g., heart rate, central venous pressure, central artery pressure, etc.), often while time-sharing between other tasks. Work in this area tends to show that anesthesiologists and non-anesthesiologists can detect changes using auditory displays as good as when they used visual displays. However, they tend to time-share between tasks better when using an auditory display (Fitch &amp; Kramer, 1994; Loeb &amp; Fitch, 2002; Paterson, Sanderson, Paterson, &amp; Loeb, 2017; Seagull, Wickens, &amp; Loeb, 2001; M. Watson &amp; Sanderson, 2004). Sonification can also improve situational awareness by augmenting perception. That is, sonification methods can be used to enhance the perceptual representation of our environment by providing extrasensory information. Many studies, for example, have focused on supplementing visual information for the blind using sonification. To aid in navigation, there has been success sonifying depth information (Brock &amp; Kristensson, 2013), and the location of objects (Pavlo Bazilinskyy et al., 2016), and even one demonstration of using echolocation (Kish, 2009). Others have shown success sonifying more complex visual information like object identity (Nagarajan, Yaacob, &amp; Sainarayanan, 2003) and line graphs (L. M. Brown &amp; Brewster, 2003). However, there are other examples, where extrasensory information is sonified to enhance perception. Probably, the most well-known, and most-often cited example is the Geiger counter. Developed in the early 1900’s, and still used today, the Geiger counter transforms ionization events into audible clicks allowing us to perceive radiation levels in the environment (Knoll, 2010). Another example, called the “Visor” transposes color into sounds to create artificial synesthesia (Foner, 1999). Given our visual system, different sets of wavelengths can appear as the same color, assuming you adjust the relative amplitudes accordingly. Therefore, two objects could then appear to have the same color although they have different spectra; we can perceive the color, we cannot perceive the shape of the spectrum. The visor was designed to sonify the color spectra to enable the user to discriminate colors based on the shapes of the spectrum. For example, you could hear the difference between a painting and a copy of painting, even if visually they are indistinguishable, hear camouflaged objects, or as the authors suggest, the device could be extended to allow you to hear ultraviolet, infrared, or polarized light. 3.3.2 Perception and action in motor skill learning Another way in which sonification could augment cognition, is by improving perception and action in motor skill learning. That is, sound could be used to provide real-time feedback about performance in a motor task, guiding a learner towards their goal or correct performance. Enhancing motor learning has been explored using auditory alarms, sonified movement feedback, and sonified error feedback (J.F. Dyer, Stapleton, &amp; Rodger, 2017; Sigrist, Rauter, Riener, &amp; Wolf, 2013). Auditory alarms have proven useful for improving motor skill learning. They are simplest form of sonification in that any movement considered an error triggers an alarm. They are easily interpreted by the learner, though they provide little information about how to correct performance. In rehabilitation, for example, auditory alarms have been used to inform patients about errors in movement (e.g., incorrect gait, unphysiological loading), and shown success in helping the learner correct the behavrio (Batavia, Gianutsos, Vaccaro, &amp; Gold, 2001; Eriksson &amp; Bresin, 2010; Petrofsky, 2001; Riskowski, Mikesky, Bahamonde, &amp; Burr, 2009). Similarly, auditory alarms have facilitated motor training in gymnastics (Baudry, Leroy, Thouvarecq, &amp; Chollet, 2006) and improving rifle movements for professional shooters (Underwood, 2009). Sound has also been used to provide constant, real-time feedback about movement. This is considered ‘direct sonification’ because some body movement is directly mapped to sound to provide additional information and guide the learner to correct performance. For example, your location is 3D space could be mapped to amplitude and pitch of a constant sound helping you navigate through space. There is some evidence that continuous sonified feedback is beneficial in simple motor tasks; In simple reaching tasks, for example (Oscari, Secoli, Avanzini, Rosati, &amp; Reinkensmeyer, 2012; Schmitz &amp; Bock, 2014). Unfortunately, however, there is little direct evidence that continuous auditory feedback is beneficial in complex motor tasks. There was some success using sonified movement feedback in swimming tasks (Chollet, Madani, &amp; Micallef, 1992; Chollet, Micallef, &amp; Rabischong, 1988), although these effects might be explained better by increased motivation (Sigrist et al., 2013). Constant sonified movement feedback has also been incorporated in a number of different motor tasks like karate (Yamamoto, Shiraki, Takahata, Sakane, &amp; Takebayashi, 2004), rowing (Schaffert, Mattes, &amp; Effenberg, 2009), and skiing (Kirby, 2009), but there have not been corresponding motor learning studies to validate whether they are in fact beneficial for the learner (Sigrist et al., 2013). There has been more success in using sonified movement error feedback to improve motor-skill learning (Oscari et al., 2012; Schmitz &amp; Bock, 2014). Here, the sound does not directly correspond to your movements, but instead corresponds to your movements in relation to some criterion. For example, instead of directly mapping sound to your location in 3D space, you could map sound parameters to the relationship between your position and some target location (e.g., increase in pitch as you move closer to the target). Using this method has shown some benefits across different complex motor tasks such as speed skating (Boyd &amp; Godbout, 2010) and rowing (Sigrist et al., 2011). Shooting scores during rifle training was also improved with error feedback. Here, the pitch of a pure tone was mapped to the deviation of the gun barrel to the bullseye. 3.3.3 Data analysis and pattern recognition. One of the goals of datamining or data exploration is to detect hidden regularities in high dimensional data. Our ability to detect these hidden regularities is of course dependent on the representation of the data and our ability to recognize the patterns. As mentioned earlier, our auditory system excels at detecting very subtle patterns in sounds (Grond &amp; Hermann, 2014a, 2014b; Hermann et al., 2011). The use of auditory data representations in fact has a long history, well-before there was a term for it (see Frysinger, 2005). The stethoscope, for example, still provides valuable information for a physician, and Pollack and Ficks (1954) mapped multi-dimensional data onto sound parameters to evaluate the information transmission properties of auditory stimuli (i.e., information “bits”). Speeth (1961), provided one of the earliest studies that showed the advantages of using auditory data representations over visual for data pattern recognition. Here they were interested in using seismic measurements to discriminate between earthquakes and underground bomb blasts. The seismometer produces complex wave patterns and using visual displays of the data for categorization proved to be a very difficult task. However, once the seismic data transformed into sound, subjects could accurately classify seismic activity on 90% of the trials. Additionally, because the data was time compressed, an analyst could review up to 24 hours of data in 5 minutes. Other early work has also shown the advantages to using auditory representations when dealing with complex multivariate data. Morrison and Lunney used sound to represent infrared spectral data (Baecker &amp; Buxton, 1987) and Yeung (1980) used sound to represent experimental data from analytical chemistry where subjects achieved 98% classification with little practice. Similarly, Mezrich, Frysinger, &amp; Slivjanovski (1984) used both auditory and visual components to represent multivariate time-series economic data. They found that their dynamic multi-modal display generally outperformed static visual displays. This early work is important in that it demonstrates that some data sets are well-suited for sonification and confers pattern recognition benefits. These are often dense, multivariate data sets that can take advantage of the temporal nature of auditory representations. More recent work has expanded the range of applications of sonification for data exploration with some notable successes. One area that has shown the usefulness of sonification is in the interpretation of brain data. For example, real-time monitoring and analysis of ectroencephalographic (EEG) data has diverse application areas including medical screening, brain computer interfaces, and neurofeedback (Väljamäe et al., 2013). Recent work shows that sonification facilitates the interpretation and categorization of EEG data (Baier, Hermann, &amp; Stephani, 2007; Baier et al., 2007; De Campo, Hoeldrich, Eckel, &amp; Wallisch, 2007). For example, sonified EEG data has been used to detect epilectic seizures. One study transformed EEG data into music (snapping time-frequency data to notes in a musical scale) and found that subjects could identify seizures from the auditory data alone (Loui, Koplin-Green, Frick, &amp; Massone, 2014; Parvizi, Gururangan, Razavi, &amp; Chafe, 2018). Similarly, positron emission topographical (PET) data has been sonified to facilitate the diagnosis of Alzheimer’s disease (Gionfrida &amp; Roginska, 2017). Not limited to brain data, other biomedical signals like electrocardiographic (ECG) data have been sonified facilitating the detection of cardiopathic pathologies and other anomalies (Avbelj, 2012; Kather et al., 2017). The range of fields that have begun to adopt sonification for data exploration, and have shown promising results, is in fact staggeringly diverse. From astronomical data (W. L. Diaz-Merced et al., 2011; W. L. L. Diaz-Merced, 2017; Lunn &amp; Hunt, 2011), meterological data (George et al., 2017), oceanography (Sturm, 2005), physics (Pereverzev et al., 1997), biomedicine (Avbelj, 2012; Larsen, 2016), social sciences (Dayé &amp; de Campo, 2006), to space exploration. During the Voyager 2 mission, the spacecraft was going through the rings of Saturn when it encountered a problem. The operators could not identify the problem through visual analysis of the data. However, once the data was played through a music synthesizer, a “machine-gunning” sound was heard, leading them to conclude that the problem was caused the problems were caused by high-speed collisions with electromagnetically charged micro-meteoroids (Barrass &amp; Kramer, 1999). Sonification can alter our perception of the data allowing insights and pattern recognition that were not possible using visual displays. 3.4 References Ashmead, D. H., Leroy, D., &amp; Odom, R. D. (1990). Perception of the relative distances of nearby sound sources. Perception &amp; Psychophysics, 47(4), 326–331. Avbelj, V. (2012). Auditory display of biomedical signals through a sonic representation: ECG and EEG sonification. In MIPRO, 2012 Proceedings of the 35th International Convention (pp. 474–475). IEEE. Axon, L., Alahmadi, B., Nurse, J. R., Goldsmith, M., &amp; Creese, S. (2018). Sonification in security operations centres: what do security practitioners think? Analyst, 7, 3. Baecker, R. M., &amp; Buxton, W. A. (1987). Human-computer interaction: a multidisciplinary approach. Morgan Kaufmann Publishers Inc. Baier, G., Hermann, T., &amp; Stephani, U. (2007). Event-based sonification of EEG rhythms in real time. Clinical Neurophysiology, 118(6), 1377–1386. Ballora, M. (2014). Sonification, Science and Popular Music: In search of the ‘wow.’ Organised Sound, 19(01), 30–40. https://doi.org/10.1017/S1355771813000381 Ballora, M., Giacobe, N. A., &amp; Hall, D. L. (2011). Songs of cyberspace: an update on sonifications of network traffic to support situational awareness. In Multisensor, Multisource Information Fusion: Architectures, Algorithms, and Applications 2011 (Vol. 8064, p. 80640P). International Society for Optics and Photonics. Barrass, S., &amp; Kramer, G. (1999). Using sonification. Multimedia Systems, 7(1), 23–31. Batavia, M., Gianutsos, J. G., Vaccaro, A., &amp; Gold, J. T. (2001). A do-it-yourself membrane-activated auditory feedback device for weight bearing and gait training: a case report. Archives of Physical Medicine and Rehabilitation, 82(4), 541–545. Baudry, L., Leroy, D., Thouvarecq, R., &amp; Chollet, D. (2006). Auditory concurrent feedback benefits on the circle performed in gymnastics. Journal of Sports Sciences, 24(2), 149–156. Bazilinskyy, P., Petermeijer, S. M., Petrovych, V., Dodou, D., &amp; De Winter, J. C. F. (2015). Take-over requests in highly automated driving: A crowdsourcing survey on auditory, vibrotactile, and visual displays. Unpublished. Bazilinskyy, Pavlo, van Haarlem, W., Quraishi, H., Berssenbrugge, C., Binda, J., &amp; de Winter, J. (2016). Sonifying the location of an object: A comparison of three methods. IFAC-PapersOnLine, 49(19), 531–536. Boyd, J., &amp; Godbout, A. (2010). Corrective Sonic Feedback for Speed Skating: A Case Study. Georgia Institute of Technology. Brock, M., &amp; Kristensson, P. O. (2013). Supporting blind navigation using depth sensing and sonification. In Proceedings of the 2013 ACM conference on Pervasive and ubiquitous computing adjunct publication (pp. 255–258). ACM. Brown, L. M., &amp; Brewster, S. A. (2003). Drawing by ear: Interpreting sonified line graphs. Georgia Institute of Technology. Brown, M. L., Newsome, S. L., &amp; Glinert, E. P. (1989). An experiment into the use of auditory cues to reduce visual workload. In ACM SIGCHI Bulletin (Vol. 20, pp. 339–346). ACM. Cabrera, D., Ferguson, S., &amp; Laing, G. (2005). Development of auditory alerts for air traffic control consoles. In Audio Engineering Society Convention 119. Audio Engineering Society. Chollet, D., Madani, M., &amp; Micallef, J. P. (1992). Effects of two types of biomechanical bio-feedback on crawl performance. Biomechanics and Medicine in Swimming, Swimming Science VI, 48, 53. Chollet, D., Micallef, J. P., &amp; Rabischong, P. (1988). Biomechanical signals for external biofeedback to improve swimming techniques. Swimming Science V. Champaign, IL: Human Kinetics Books, 389–396. Dayé, C., &amp; de Campo, A. (2006). Sounds sequential: sonification in the social sciences. Interdisciplinary Science Reviews, 31(4), 349–364. https://doi.org/10.1179/030801806X143286 De Campo, A., Hoeldrich, R., Eckel, G., &amp; Wallisch, A. (2007). New sonification tools for EEG data screening and monitoring. Georgia Institute of Technology. Debashi, M., &amp; Vickers, P. (2018). Sonification of network traffic flow for monitoring and situational awareness. PLOS ONE, 13(4), e0195948. https://doi.org/10.1371/journal.pone.0195948 Diaz Merced, W. L. (2013). Sound for the exploration of space physics data (PhD). University of Glasgow. Retrieved from http://encore.lib.gla.ac.uk/iii/encore/record/C\\_\\_Rb3090263 Diaz-Merced, W. L., Candey, R. M., Brickhouse, N., Schneps, M., Mannone, J. C., Brewster, S., &amp; Kolenberg, K. (2011). Sonification of Astronomical Data. Proceedings of the International Astronomical Union, 7(S285), 133–136. https://doi.org/10.1017/S1743921312000440 Diaz-Merced, W. L. L. (2017). We too may find new planets. In AASTCS5 Radio Exploration of Planetary Habitability, Proceedings of the conference 7-12 May, 2017 in Palm Springs, CA. Published in Bulletin of the American Astronomical Society, Vol. 49, No. 3, id. 202.01 (Vol. 49). Driver, J. (2001). A selective review of selective attention research from the past century. British Journal of Psychology, 92(1), 53–78. Driver, J., &amp; Spence, C. (1998). Crossmodal attention. Current Opinion in Neurobiology, 8(2), 245–253. https://doi.org/10.1016/S0959-4388(98)80147-5 Dubus, G., &amp; Bresin, R. (2015). Exploration and evaluation of a system for interactive sonification of elite rowing. Sports Engineering, 18(1), 29–41. https://doi.org/10.1007/s12283-014-0164-0 Dyer, J. F., Stapleton, P., &amp; Rodger, M. (2017). Mapping Sonification for Perception and Action in Motor Skill Learning. Frontiers in Neuroscience, 11. https://doi.org/10.3389/fnins.2017.00463 Edworthy, J., Hellier, E., Aldrich, K., &amp; Loxley, S. (2004). Designing trend-monitoring sounds for helicopters: methodological issues and an application. Journal of Experimental Psychology: Applied, 10(4), 203. Eriksson, M., &amp; Bresin, R. (2010). Improving running mechanics by use of interactive sonification. Proceedings of ISon, 95–98. Escera, C., Alho, K., Winkler, I., &amp; Näätänen, R. (1998). Neural mechanisms of involuntary attention to acoustic novelty and change. Journal of Cognitive Neuroscience, 10(5), 590–604. Fitch, W. T., &amp; Kramer, G. (1994). Sonifying the body electric: Superiority of an auditory over a visual display in a complex, multivariate system. In SANTA FE INSTITUTE STUDIES IN THE SCIENCES OF COMPLEXITY-PROCEEDINGS VOLUME- (Vol. 18, pp. 307–307). Addison-Wesley Publishing Co. Flowers, J. H. (2005). Thirteen years of reflection on auditory graphing: Promises, pitfalls, and potential new directions. Georgia Institute of Technology. Foner, L. N. (1999). Artificial synesthesia via sonification: A wearable augmented sensory system. Mobile Networks and Applications, 4(1), 75–81. Frysinger, S. P. (2005). A brief history of auditory data representation to the 1980s. Georgia Institute of Technology. Garcia, A., Peres, S. C., Ritchey, P., Kortum, P., &amp; Stallmann, K. (2011). Auditory Progress Bars: Estimations of Time Remaining. Proceedings of the Human Factors and Ergonomics Society Annual Meeting, 55(1), 1338–1341. https://doi.org/10.1177/1071181311551278 George, S. S., Crawford, D., Reubold, T., &amp; Giorgi, E. (2017). Making Climate Data Sing: Using Music-like Sonifications to Convey a Key Climate Record. Bulletin of the American Meteorological Society, 98(1), 23–27. Gfeller, K., Woodworth, G., Robin, D. A., Witt, S., &amp; Knutson, J. F. (1997). Perception of rhythmic and sequential pitch patterns by normally hearing adults and adult cochlear implant users. Ear and Hearing, 18(3), 252–260. Gilfix, M., &amp; Couch, A. L. (2000). Peep (The Network Auralizer): Monitoring Your Network with Sound. In LISA (pp. 109–117). Gionfrida, L., &amp; Roginska, A. (2017). A Novel Sonification Approach to Support the Diagnosis of Alzheimer’s Dementia. Frontiers in Neurology, 8, 647. https://doi.org/10.3389/fneur.2017.00647 Grond, F., &amp; Hermann, T. (2014a). Interactive Sonification for Data Exploration: How listening modes and display purposes define design guidelines. Organised Sound, 19(1), 41–51. Grond, F., &amp; Hermann, T. (2014b). Interactive Sonification for Data Exploration: How listening modes and display purposes define design guidelines. Organised Sound, 19(01), 41–51. https://doi.org/10.1017/S1355771813000393 Hermann, T., Hunt, A., &amp; Neuhoff, J. G. (2011). The sonification handbook. Logos Verlag Berlin. Jamson, A. H., Lai, F. C., &amp; Carsten, O. M. (2008). Potential benefits of an adaptive forward collision warning system. Transportation Research Part C: Emerging Technologies, 16(4), 471–484. Kather, J. N., Hermann, T., Bukschat, Y., Kramer, T., Schad, L. R., &amp; Zöllner, F. G. (2017). Polyphonic sonification of electrocardiography signals for diagnosis of cardiac pathologies. Scientific Reports, 7, 44549. https://doi.org/10.1038/srep44549 Kirby, R. (2009). Development of a real-time performance measurement and feedback system for alpine skiers. Sports Technology, 2(1–2), 43–52. Kish, D. (2009, April 11). Seeing with sound: What is it like to “see” the world using sonar? Daniel Kish, who lost his sight in infancy, reveals all. New Scientist. Knoll, G. F. (2010). Radiation detection and measurement. John Wiley &amp; Sons. Kortum, P., Peres, S. C., Knott, B. A., &amp; Bushey, R. (2005). The Effect of Auditory Progress Bars on Consumer’s Estimation of Telephone wait Time. Proceedings of the Human Factors and Ergonomics Society Annual Meeting, 49(4), 628–632. https://doi.org/10.1177/154193120504900406 Kramer, G. (2000). Auditory display: sonification, audification and auditory interfaces. Addison-Wesley Longman Publishing Co., Inc. Larsen, P. E. (2016). More of an art than a science: Using microbial DNA sequences to compose music. Journal of Microbiology &amp; Biology Education, 17(1), 129. Loeb, R. G., &amp; Fitch, W. T. (2002). A laboratory evaluation of an auditory display designed to enhance intraoperative monitoring. Anesthesia &amp; Analgesia, 94(2), 362–368. Loui, P., Koplin-Green, M., Frick, M., &amp; Massone, M. (2014). Rapidly Learned Identification of Epileptic Seizures from Sonified EEG. Frontiers in Human Neuroscience, 8. https://doi.org/10.3389/fnhum.2014.00820 Lunn, P., &amp; Hunt, A. (2011). Listening to the invisible: Sonification as a tool for astronomical discovery. Mezrich, J. J., Frysinger, S., &amp; Slivjanovski, R. (1984). Dynamic representation of multivariate time series data. Journal of the American Statistical Association, 79(385), 34–40. Näätänen, R., Paavilainen, P., Rinne, T., &amp; Alho, K. (2007). The mismatch negativity (MMN) in basic research of central auditory processing: A review. Clinical Neurophysiology, 118(12), 2544–2590. https://doi.org/10.1016/j.clinph.2007.04.026 Nagarajan, R., Yaacob, S., &amp; Sainarayanan, G. (2003). Role of object identification in sonification system for visually impaired. In TENCON 2003. Conference on Convergent Technologies for the Asia-Pacific Region (Vol. 2, pp. 735–739). IEEE. Nees, M. A., &amp; Walker, B. N. (2009). Auditory Interfaces and Sonification. Oscari, F., Secoli, R., Avanzini, F., Rosati, G., &amp; Reinkensmeyer, D. J. (2012). Substituting auditory for visual feedback to adapt to altered dynamic and kinematic environments during reaching. Experimental Brain Research, 221(1), 33–41. Parkinson, A., &amp; Tanaka, A. (2013). Making Data Sing: Embodied Approaches to Sonification. In Sound, Music, and Motion (pp. 151–160). Springer, Cham. https://doi.org/10.1007/978-3-319-12976-1\\_9 Parvizi, J., Gururangan, K., Razavi, B., &amp; Chafe, C. (2018). Detecting silent seizures by their sound. Epilepsia, 59(4), 877–884. Paterson, E., Sanderson, P. M., Paterson, N. a. B., &amp; Loeb, R. G. (2017). Effectiveness of enhanced pulse oximetry sonifications for conveying oxygen saturation ranges: a laboratory comparison of five auditory displays. British Journal of Anaesthesia, 119(6), 1224–1230. https://doi.org/10.1093/bja/aex343 Pereverzev, S. V., Loshak, A., Backhaus, S., Davis, J. C., &amp; Packard, R. E. (1997). Quantum oscillations between two weakly coupled reservoirs of superfluid 3 He. Nature, 388(6641), 449. Petrofsky, J. (2001). The use of electromyogram biofeedback to reduce Trendelenburg gait. European Journal of Applied Physiology, 85(5), 491–495. Pollack, I., &amp; Ficks, L. (1954). Information of elementary multidimensional auditory displays. The Journal of the Acoustical Society of America, 26(2), 155–158. Qi, L., Martin, M. V., Kapralos, B., Green, M., &amp; García-Ruiz, M. (2007). Toward sound-assisted intrusion detection systems. In *OTM Confederated International Conferences&quot; On the Move to Meaningful Internet Systems“* (pp. 1634–1645). Springer. Quinn, M. (2001). Research set to music: The climate symphony and other sonifications of ice core, radar, DNA, seismic and solar wind data. Georgia Institute of Technology. Quinn, M. (2012). “Walk on the Sun”: an interactive image sonification exhibit. AI &amp; Society, 27(2), 303–305. Riskowski, J. L., Mikesky, A. E., Bahamonde, R. E., &amp; Burr, D. B. (2009). Design and validation of a knee brace with feedback to reduce the rate of loading. Journal of Biomechanical Engineering, 131(8), 084503. Sanderson, P. (2006). The multimodal world of medical monitoring displays. Applied Ergonomics, 37(4), 501–512. Schaffert, N., Mattes, K., &amp; Effenberg, A. O. (2009). A sound design for the purposes of movement optimisation in elite sport (using the example of rowing). Georgia Institute of Technology. Schmitz, G., &amp; Bock, O. (2014). A Comparison of Sensorimotor Adaptation in the Visual and in the Auditory Modality. PloS One, 9(9), e107834. Seagull, F. J., Wickens, C. D., &amp; Loeb, R. G. (2001). When is less more? Attention and workload in auditory, visual, and redundant patient-monitoring conditions. In Proceedings of the Human Factors and Ergonomics Society Annual Meeting (Vol. 45, pp. 1395–1399). SAGE Publications Sage CA: Los Angeles, CA. Sigrist, R., Rauter, G., Riener, R., &amp; Wolf, P. (2013). Augmented visual, auditory, haptic, and multimodal feedback in motor learning: A review. Psychonomic Bulletin &amp; Review, 20(1), 21–53. https://doi.org/10.3758/s13423-012-0333-8 Sigrist, R., Schellenberg, J., Rauter, G., Broggi, S., Riener, R., &amp; Wolf, P. (2011). Visual and auditory augmented concurrent feedback in a complex motor task. Presence: Teleoperators and Virtual Environments, 20(1), 15–32. Speeth, S. D. (1961). Seismometer sounds. The Journal of the Acoustical Society of America, 33(7), 909–916. Stanton, J. (2015). Sensing big data: Multimodal information interfaces for exploration of large data sets. In Big Data at Work (pp. 172–192). Routledge. Stockman, T., Nickerson, L. V., &amp; Hind, G. (2005). Auditory graphs: A summary of current experience and towards a research agenda. Georgia Institute of Technology. Sturm, B. L. (2005). Pulse of an Ocean: Sonification of Ocean Buoy Data. Leonardo, 38(2), 143–149. Targett, S., &amp; Fernstrom, M. (2003). Audio games: Fun for all? All for fun! Georgia Institute of Technology. Tervaniemi, M., &amp; Brattico, E. (2004). From sounds to music towards understanding the neurocognition of musical sound perception. Journal of Consciousness Studies, 11(3–4), 9–27. Underwood, S. M. (2009). Effects of augmented real-time auditory feedback on top-level precision shooting performance. Väljamäe, A., Steffert, T., Holland, S., Marimon, X., Benitez, R., Mealla, S., … Jordà, S. (2013). A review of real-time EEG sonification research (pp. 85–93). Presented at the International Conference on Auditory Display 2013 (ICAD 2013), Lodz, Poland. Retrieved from http://icad2013.com/index.php Vickers, P., Laing, C., Debashi, M., &amp; Fairfax, T. (2014). Sonification Aesthetics and Listening for Network Situational Awareness. ArXiv:1409.5282 [Cs]. https://doi.org/10.13140/2.1.4225.6648 Vickers, P., Laing, C., &amp; Fairfax, T. (2017). Sonification of a network’s self-organized criticality for real-time situational awareness. Displays, 47, 12–24. https://doi.org/10.1016/j.displa.2016.05.002 Walker, B. N., &amp; Kramer, G. (2004). Ecological psychoacoustics and auditory displays: Hearing, grouping, and meaning making. Ecological Psychoacoustics, 150–175. Walker, B. N., &amp; Mauney, L. M. (2010). Universal design of auditory graphs: A comparison of sonification mappings for visually impaired and sighted listeners. ACM Transactions on Accessible Computing (TACCESS), 2(3), 12. Watson, M., &amp; Sanderson, P. (2004). Sonification supports eyes-free respiratory monitoring and task time-sharing. Human Factors, 46(3), 497–517. Watson, T., &amp; Lip, G. Y. H. (2006). Blood pressure measurement in atrial fibrillation: goodbye mercury? Journal of Human Hypertension, 20(9), 638. Wickens, C. D. (2002). Multiple resources and performance prediction. Theoretical Issues in Ergonomics Science, 3(2), 159–177. Wickens, C. D., &amp; Liu, Y. (1988). Codes and modalities in multiple resources: A success and a qualification. Human Factors, 30(5), 599–616. Wickens, C. D., Parasuraman, R., &amp; Davies, D. R. (1984). Varieties of attention. Winberg, F., &amp; Hellstrom, S. O. (2001). Qualitative aspects of auditory direct manipulation. A case study of the towers of Hanoi. Georgia Institute of Technology. Yamamoto, G., Shiraki, K., Takahata, M., Sakane, Y., &amp; Takebayashi, Y. (2004). Multimodal knowledge for designing new sound environments. In The International Conference on Human Computer Interaction with Mobile Devices and Services. Yeung, E. S. (1980). Pattern recognition by audio representation of multivariate analytical data. Analytical Chemistry, 52(7), 1120–1123. "],
["a-brief-review-of-augmented-reality-display-technologies-and-combination-with-brain-computer-interfaces.html", "Chapter 4 A Brief Review of Augmented Reality Display Technologies and Combination with Brain-Computer Interfaces 4.1 Abstract 4.2 Introduction 4.3 Short overview: Brain Structure 4.4 BCI Technologies and Basic Principles of Brain Data Acquisition 4.5 Common Electroencephalography Methods 4.6 Brain-Computer Interfaces (BCI) 4.7 Augmented Reality (AR) 4.8 Combining AR and BCI 4.9 Limitations and Interpretations 4.10 References", " Chapter 4 A Brief Review of Augmented Reality Display Technologies and Combination with Brain-Computer Interfaces Taylan Safak Ergun, Graduate Center of the City University of New York, May, 2018 4.1 Abstract In this paper, the aim of Brain-Computer Interface (BCI) studies and the technology of Augmented Reality (AR) display systems are briefly summarized. Different types of signal acquisition techniques and BCI strategies are compared by taking into account the target population and the goals that researchers planned. Additionally, some examples of the combination of both AR and BCI systems and the applications are included. The exponential acceleration of BCI and AR studies concerning the promising perspectives, designs, and achievements, as well as, its limitations and shortcomings are tackled based on recent studies. 4.2 Introduction It has been shown through many studies that Brain-Computer Interaction (BMI) systems and Augmented Reality (AR) systems can help users with disabilities. Also, they provide a new level of technologies to create smart environments. In this brief review, Augmented Reality concept restricted to particular display technologies which are mostly used in experimental designs. AR and BCI systems spread to various fields. For example doctors can use the AR system by using Head Mounted Display (HMD) to gather real-time medical data from the patient’s body (Bichlmeier, Wimmer, Heining, &amp; Navab, 2007), on the other hand in our homes we can control electronic devices, lights with hand gestures, gaze movement and voice commands (“Microsoft, HoloLens” n.d ). Additionally, users can create holograms which allow them to visualize and work with their digital contents, users can interact with the virtually display objects or holograms. AR and tracking technologies improve the environment we engage in by using different sensors and various electronic devices, some examples of past and current BCI and AR studies and applications provided in this review. 4.3 Short overview: Brain Structure The human brain is divided into three parts: the Brainstem, the cerebrum, and the cerebellum. The cerebrum is also comprised of right and left hemispheres. Cerebral cortex is the surface of cerebrum and divided into four lobes that some of the functions take place as follows which is the Frontal lobe that provides cognitive functions such as social and moral reasoning and also executive functions (Chayer and Freedman, 2001); the Temporal lobe involved in emotional processing and auditory functions; parietal lobe is responsible for language skills (reading/writing) and attention; occipital lobe is used for visual processing. Since the BCI systems are used to complete different tasks, researchers should consider the related area of the brain while they are obtaining the data acquisitions according to their experimental goals. Some of the data acquisition methods are discussed in the following sections. 4.4 BCI Technologies and Basic Principles of Brain Data Acquisition The BCI system is based on translating neurophysiological signals to commands and control external devices (Sellers &amp; Donchin, 2006). There are two main techniques to implement such processes: Non-invasive BCI and Invasive BCI. Non-invasive BCI does not require any surgical procedures, instead, the brain activity is recorded from the skull with a channel cap. However, invasive BCI requires neurosurgery. A set of electrodes are attached to a specific region of the brain and signals are directly recorded from gray matter of the brain (Lebedev &amp; Nicolelis, 2006). Both techniques have drawbacks and benefits. Non-invasive BCI is the easiest, safest, and most practical method to elicit signals. However, it only provides a basic communication tool because of its low-resolution signals, since the skull and skin prevent it to acquire high-resolution signals (Lebedev &amp; Nicolelis, 2006). Since the usage of non-invasive methods is limited, Lebedev and Nicolelis (2006) suggested using invasive techniques for important goals such as controlling artificial limbs. Invasive BCI provides pretty accurate and more specific signals. Nonetheless, this approach has many problems as well. It requires invasive surgery to implant the microelectrodes. Due to the surgical procedure, infection or scar tissue is likely to occur over time. The scar tissue and/or infection prevents the acquiring of signals or decreases the quality of acquired signals over the course of time (Lebedev &amp; Nicolelis, 2006). However, they emphasized that reaching important goals, such as controlling leg prosthesis, are only possible with an ideal recording device that deals with possible consequences of long-term use of microelectrodes. This is because recording simultaneously from several areas of the brain will provide high-resolution signals. Partially-invasive BCI is another technique to measure and record the electrical activity. In this technique, electrodes are implanted on the surface of the cortex (Levine et al., 1999). Electrocorticography (ECoGs) serves as a partially-invasive recording method. To summarize, neither invasive BCI nor non-invasive BCI techniques for recording brain activity have an edge over one another. The utility of signal acquisition techniques should depend on the aim of the study. If researchers come up with new solutions for the limitations of the BCI system, both disabled and physically capable people will benefit from it accordingly. 4.5 Common Electroencephalography Methods 4.5.1 Electroencephalography (EEG) and Even-Related Potential (ERP) Electroencephalography (EEG) is one of the most common non-invasive BCI’s to measure and record brain activity. An individual is attached to an EEG machine with an electrode cup, the electrodes are placed on the user’s scalp to measure neurophysiological signals. The EEG devise is able to measure severe voltage (10-100 mV) alterations of nerve cells. It only provides information about the general mental state, such as sleep, awareness, and alertness. However, it does not detect minor alteration (1-10 mV) of nerve cells. For this reason, Event-Related Potential (ERP) is used to measure minor fluctuation. ERP is elicited either during a cognitive task that requires an individual to distinguish target stimulus from non-target stimuli (endogenous potential) or after presenting a sensory stimulus (exogenous potential). If an external stimulus is presented, it causes a decrease of electrical potential 100 ms later (N100), while if a participant is asked to distinguish one stimulus from other stimuli, it causes an increase of electrical potential 300 ms later (P300) (Müller-Putz, Scherer, &amp; Pfurtscheller, 2007). 4.5.2 EEG Channel Selection Examples To elicit P300, Piccione et al (2006) used four EEG channels and one EOG channel; Sellers and Donchin (2006) used three EEG channels. In these studies, low communication rates were attributed to the number of few channel selections (Hoffman et. al, 2008). In order to increase communication rates, Hoffman et al. (2008) assessed four different electrode configurations (4,8,16,32 electrodes). For testing classification, they used Bayesian Linear Discriminant Analysis and Fisher’s Linear Discriminant Analysis. For both BLDA and FLDA, there was a significant increase between the four electrode configuration and the eight electrode configuration. However, using more than eight electrodes provides a modicum increase for BLDA. The usage of 16 and 32 electrodes even decreased the performance for FLDA. They concluded the best electrode configuration includes 8 electrodes. It could be considered more user-friendly compared to 16 and 32 electrodes placed and provides better accuracy compared to four electrodes placed (Hoffman et. al, 2008). Takano et al. (2011) and Kansaku (2011) examined eight channels by comparing posterior - anterior channels set and middle - lateral channels set. According to results, the EEG recording from the posterior set and lateral sets gave better accuracy. 4.5.3 Electromyography (EMG) and Electrooculography (EOG) EMG and EOG are considered reliable sources of signal acquisition (Fatourechi, Bashashati, Ward &amp; Birch, 2007). Blum, Stauder, Euler, and Navab (2012) used Neural Impulse Actuator (NIA) to see the potential of the combination of BCI and a gaze tracker. NIA is able to read alpha brain waves, beta brain waves, electromyographic signals elicited by skeletal muscles, and electrooculographic signals triggered by eye movement. With acquired signals from EMG, Blum et al. (2012) achieved to create a user interface (UI) by switching normal vision to X-ray vision on a phantom patient. 4.6 Brain-Computer Interfaces (BCI) 4.6.1 BCI Functions Brain-Computer Interface (BCI), also known as Brain-Machine Interface (BMI) (Lebedev &amp; Nicolelis, 2006; Kansaku, 2011; Takano, Hata &amp; Kansaku, 2011), Mind-Machine Interface (MMI), Synthetic-Telepathy interface (STI) (Bogue, 2010), and Neural Interface System (NIS) (Hatsopoulos &amp; Donoghue, 2009), is a new technology that provides a promising way of communication, especially for neurologically disabled people. This interface does not rely on any physical movement. Instead, electrical signals from the cerebral cortex (Hill, Brunner &amp; Vaughan, 2011) are recorded and translated in order to control external devices. Essentially, users are exposed to a stimulus for making a choice or instructed to actuate a certain task, so that neurophysiological signals are elicited via a signal acquisition technique. In doing so, the connection between the nervous system and a machine is established. This connection provides the opportunity for users to not rely on their muscles or peripheral nerves to operate devices. 4.6.2 Different Types of BCI In order to elicit signals from brain activity, two main techniques can be mentioned, which are self-actuated BCIs and stimulus-driven BCIs. Self-actuated BCI is also known as self-paced BCI (Scherer, Chung, Lyon, Cheung &amp; Rao, 2010). 4.6.2.1 Self-actuated BCI For self-actuated BCI, there are no certain stimuli. In this technique, the users determine the time in which they begin and stop to operate a certain mental task (Hill et al.,2011). Mental imagery, is a phenomenon in which a subject imagines to perform a given action, could be given as an example of self-actuated BCI. Scherer et al. (2010) used mental imagery as a control signal for simple commands. The users operated a Virtual Environment by thinking of moving their left hand, right hand, foot, and tongue. For instance, in order to make a right turn, they thought of their right hand. Elicited signals from the motor and pre-motor cortical areas via EEG enabled it to control the joystick. In doing so, the users achieved to find coins dispersed in the immersive virtual environment. The disadvantage of regulating users’ own brain activity (self-actuated BCI) is long-term training for controlling the system. What is more, Hill et al. (as cited in Hofmann, Vesin, Ebrahimi &amp; Diserens, 2007) showed that completely locked-in patients could not benefit from mental-imagery based BCI system, since the elicited signals were not satisfactory for communication. Treder and Blankertz (2010) developed a two-level typewriter called Hex-O-Spell layout, as an alternative to the classical matrix speller to eliminate crowding effect. Figure 1 Hex-O-Spell layout (taken from Treder &amp; Blankertz, 2010) In the Hex-O-Spell layout, numbers and symbols are arranged into a radial layout. There are six circles placed to create a hexagon. It is the first level of this layout. If one of these circles is selected, 5 symbols in a circle expand into another circle. In the second level, one circle remained empty for the purpose of returning to the first level in case of making a mistake. Users achieved to copy given German words by giving their attention to target symbol located in a circle (Treder &amp; Blankertz, 2010) (figure 1). 4.6.2.2 Stimulus-driven BCI For stimulus-driven BCI, there must be an external sensory stimulus to record signals. Unlike self-actuated BCI, the time for performing a task is determined by experimenters. When a user focused on a prescribed stimulus, BCIs can distinguish it with larger ERPs from given response to another stimulus. P300 based BCI (P300 speller or Donchin matrix speller) is an example of stimulus-driven BCI. The visual stimulus is a matrix consisting of letters and other symbols. The user focuses on one of the flashing icons in a 6 by 6 matrix. Each column and row of the matrix are highlighted in a random order. If the row or the column contains the chosen letter, a positive deflection in ERP is drawn out after roughly 300 milliseconds (Müller-Putz, Scherer, &amp; Pfurtscheller, 2007). In this technique, elicited control signals rely on the oddball paradigm that is a method in which more than one stimulus is presented, with one stimulus appearing less than the other stimuli. Scherer et al. (2010) used the P300 based visual evoked potential to give commands to the humanoid robot, which has the ability to move, grasp, and release objects, to interact with the environment in AR. The user was able to see the humanoid robot’s environment through the robot’s camera. In this way, the user could select an action based on objects in the image. When the user focused on the desired object, images are flickered. After the flicker occurred on the desired objects, the system recognized the given response and considered it as the user’s choice. Kansaku (2011) and Takano et al. (2011) developed a new BCI system by adding Augmented Reality (AR). To make a control panel, see-through Head-Mount Display (HMD) was added to the system as well. A USB camera attached to see-through HMD was used for detecting the AR marker. When an AR marker is detected by the camera, control panels that were a lamp or a TV appeared on either LCD monitor or see-through HMD. On this control panel, icons were used to control the device. Green and blue flickers instead of white and black flickers were preferred because Kansaku (2011) found that it provides a better subjective experience and better accuracy. In addition to this, Perra et al (as cited in Kansaku, 2011) confirmed that blue and green are the safest color combination for people with photosensitive epilepsy. The user focused on an icon with an action on it, such as turning on the lamp. The brain waves that are measured with the electrode cap were recorded and then the icon turned green and the desired action was performed. Piccione et al. (2006) used P300 based-BCI by recruiting disabled and physically capable people. They were instructed to move a blue ball from the starting point to the endpoint on the screen by focusing on one of the presented visual stimuli, which were four arrows. Intensification of an arrow in each trial was 150 milliseconds. Each arrow is randomly flickered every 2.5 seconds (interstimulus interval). Users accomplished to control a two-dimensional cursor. After each trial, researchers expected to elicit P300, if the users were able to focus on the target arrow. Elicited signals were classified by using some signal processing and mathematical procedures such as amplification and a band-pass filter. Sellers and Donchin (2006) used P300 with a four-choice paradigm and showed that ALS patients achieved to control BCI system. However, in this study, the obtained communication rates were low compared to state-of-the-art BCI (Hofmann et al.,2008). The cause of low communication rate was related to a few presented stimuli and relatively long interstimulus interval such as 2.5 seconds. In order to increase classification accuracy and communication rates, Hofmann et al. (2008) used a six-choice paradigm. Also interstimulus interval in their study was 400 ms. The reason for using a six-choice paradigm instead of a four-choice paradigm is that more stimuli decreases the probability for the target stimulus to be recognized easily. According to results of this experiment, all disabled users accomplished 100% classification accuracy as researchers had expected. 4.6.3 Applications for BCI Implemented studies regarding BCI and AR require a highly interdisciplinary approach. Biomedical engineers, rehabilitation engineers, neuroscientists, psychologists, computer scientists, applied mathematicians, and scholars from relevant disciplines contribute to this area. Studies show that the main reason for applying BCI system is to support disabled people’s daily activities. Komatsu et al. (as cited in Takano et al, 2011) found that patients with cervical spinal cord injury benefited from BCI system. Sellers and Donchin (2005) reported that ALS patients successfully controlled a four-choice P300-based BCI system. Kansaku (2011) demonstrated that both physically capable and quadriplegic users accomplished to control a lamp, a television, a hiragana speller, and a primitive robot. Blum et al. (2012) demonstrated that BCI technology can be used for enhancing the quality of surgeries by providing a user interface for medical doctors. Because surgeons need to see both inside the patient with X-ray vision and equipment, a suitable user interface had to meet the requirement of switching readily from regular vision to X-ray vision, and vice versa (Blum et al., 2012). Feedbacks collected from medical doctors showed that the system could be useful for surgeons if the noise due to weak Human-Computer Interaction design is resolved. Lalor et al., (2018) showed that participants successfully completed an immersive 3D game by using EEG-based BCI system. Steady-state visual evoked potential (SSVEP) were used to maintain binary control in the game (figure 2). Figure 2 Players maintain the character’s balance by directly focusing on a checkerboard (taken from Lalor, Kelly, Finuance, Burke, Smith, Riley, &amp; McDarby, 2005) 4.7 Augmented Reality (AR) 4.7.1 AR Technologies Augmented reality (AR) aims at simplifying user life by creating direct or indirect real-time view of a real physical world. To do this computer-generated perceptual information superimposed to real world digitally (“Augmented Reality,”n.d.). Paul Milgram and Fumio Kishino defined the Milgram’s Reality-Virtuality Continuum, which shows the span of a real-to-virtual environment (Azuma, Baillot, Behringer, Feiner, Julier, &amp; Macintyre, 2001). In this demonstration Augmented Reality is one part of the Mixed Reality (MR) (Figure 3). Figure 3 Milgram’s Reality-Virtuality Continuum (taken from Azuma et al., 2001). According to Azuma (1997), augmented reality technology has three main requirements: Combination of real and virtual content, interactive in real time and registered in 3D. Augmented reality devices require to include these three key elements. (Billinghurst, Clark, &amp; Lee, 2015). Regardless of using similar devices such as head mounted displays (HMD) (or head-worn displays HWD), tracking systems, computer interfaces augmented reality differs from Virtual Reality. Different then VR, AR technology removes real objects or manipulates/replaces objects from the real environment (Carmigniani, Furht, Anisetti, Ceravolo, Damiani, &amp; Ivkovic, 2010). Removing objects from the real environment require covering those objects with an artificial computer-generated information. This virtual information matches to environment background to help the user to ignore the real objects (Carmigniani et al., 2010) There are some other main differences between AR and VR in terms of system requirements (figure 4). For example, AR system does not need a wide Field of View (FOV), since AR technology display can be non-immersive. Figure 4 Virtual Reality and Augmented Reality technology requirements (taken from Billinghurst et al., 2015). Augmentation of the real world can apply to all senses such as touch, smell, hearing (Krevelen &amp; Poelman, 2010), haptic and to the somatosensory system (“Augmented Reality,”n.d.; Carmigniani et al., 2010) but the vast majority of research focused on visual enhancements of reality. 4.7.2 AR Devices There are many different devices for AR systems, but some devices such as tracking, computers, displays, and input devices are the most used ones in research (Carmigniani et al., 2010). In this review, I restricted AR definition to specific display technologies. Head mounted displays provide imagery in front of user’s eyes. There are two common types of HMD (figure 5), optical see-through and video see-through. Optical see-through uses the semi-transparent mirror. This mirror combines real-world image and augmented images, with this way users see augmented/enhanced scene through a transparent display. Video see-through systems include cameras, and opaque mirror since visual information from real world pass through camera system, the computer process the information and augmented scene displays on this opaque mirror (Azuma et al., 2001). Since the augmented scene information already processed by the computer, video see-through systems have more control over the combined display (Carmigniani et al., 2010). Figure 5 Two types of HWD’s. Optical see-through display (left), Video see-through display (right) (taken from Azuma et al., 2001). Figure 6 First display is a video-see-through, the middle one is an optical see-through and both of them are binocular HMD from Trivisio. The last one is a monocular HMD from Google Glass (taken from Billinghurst et al., 2015). In addition to HMD, handheld displays are becoming popular. Users can hold the AR employed devices in their hands, which makes the AR applications highly portable and more socially accepted then the HMD. Users can use Smart-phones, Tablet PC, and PDAs to run AR applications (Billinghurst et al., 2015). For example, Google’s ARCore software development kit allows users to build AR applications, by using several technologies such as light estimation, motion tracking, and environmental understanding (“ARCore,” 2018; “Google Developers, ARCore Overview,” 2018” ). Figure 7 Playing a multi-player game with two PDAs (taken from Wagner et al., 2005) Figure 7 shows two people playing The Invisible Train game on PDA’s. Trains do not exist on the wooden miniature railroad track, players only see them through video see-through displays. According to Wagner et al. (2005), handheld AR interface allows untrained users to accomplish collaborative spatial tasks. Another version of AR display is Spatial Augmented Reality (SAR). Common versions are limited in mobility but users can use them without carrying or wearing the display. Usually, SARs installed at a fixed location and projects graphical information onto the physical objects or video see-through displays provides the augmented imagery. For example, mirror-like large screens enable customers to try on clothes without undressing by using Radio-frequency identification (RFID) (“Interactive retail systems,” n.d., “Keonn Technologies”) (figure 8). Figure 8 User try on clothes 3D. Hand gestures allow the user to select and try different clothes. 4.8 Combining AR and BCI With the advent of new technology, researchers attempt to ameliorate the shortages and limitations of the current BCI systems by taking advantage of cutting-edge technology, such as Augmented Reality (AR). In this way, the usage of BCI becomes quite auspicious not only for simple commands but also for high-level commands. By applying a high-technological application, the efficiency of BCI utilization was aimed to increase. To make it possible to use BCI technology in a surrounding area for the users, such as their home, the aim was to decrease errors during the experiments, and to make the studies more enjoyable for users, Augmented Reality (AR) and Virtual Reality (VR) were added to the system. For example, Takano et al. (2011) utilized Augmented Reality in their research to construct an intelligent environment that is an interactive space, in which users can communicate with their surrounding area via technological gadgets. It helps the target users to perform daily activities. Another study shows that an agent robot and electronics in robot’s environment controlled successfully by applying AR technology with the BMI (Kansaku, Hata and Takano, 2010). Research by Kerous and Liarokapis (2017) examined the communication between at least two people by using EEG-based BCI. Unity Game Engine (HTC Vive) was used to display P300 letter grid. Participants sent the messages letter by letter by using ERP-based speller to achieve BrainChat. Combining different technologies may allow us to control electronic devices in the smart spaces especially it will help people with disabilities. 4.9 Limitations and Interpretations Regardless of whether self-actuated BCI or stimulus-driven BCI is used as a BCI strategy, researchers are tackling the limitation of BCI systems stemming from weak Human-Computer Interaction design or noisy signals due to the fact that the skull blocks signals generated in a certain area of the brain (Hill et al.,2011). An example of a weak HCI could be the significant difference between the performance of healthy users and the performance of locked-in state patients (Piccione et. al, 2006: Sellers &amp; Donchin, 2006). In the classical matrix speller, obtaining a high performance relies on precisely fixed eye on the target stimulus. In other words, the classical matrix speller requires overt attention (Treder &amp; Blankertz, 2010). Nonetheless, it is very difficult for locked-in patients to fix their gaze exactly on the target stimulus in densely arranged symbols due to the crowding effect and low-spatial resolution (Hill et al.,2011). Unlike overt attention, covert attention does not rely on eye movement. It is the act to distribute the attention in visual periphery without shifting the gaze to target stimuli (Treder &amp; Blankertz, 2010). On the other hand, since the number of densely packed cone receptors reduce beyond fovea and macula, identifying the target stimulus in visual periphery is more difficult. To find out whether or not eye movement affects the accuracy in ERP-based BCI, Treder, and Blankertz (2010) developed a stimulus in which letters are located on a radial layout that is called Hex-O-Spell self-actuated spelling system. Based on this study, Hex-O-Spell gave better results compared to the matrix speller in terms of accuracy. As researchers had expected, accuracy was better as well for over attention condition rather than covert attention condition. An example of noisy signals is that EMG signals are affected by unexpected muscle tension. Besides, eye blinking and muscle tension have an impact upon EEGs. In order to deal with noise in EEG arising from muscle activities and eye movements, Hofmann et al., (2008) applied a statistical procedure called windsorizing. They extracted the first and the last 10 percentile of the data. To date, the developed BCI systems are not advanced enough for people with disabilities who have trouble with everyday activities. This is because the communication rates are quite low (5-25 bits per second). In order to turn on a lamp or type a symbol in the BCI system, for example, it takes approximately 15 seconds (Takano et al., 2011). It is not time efficient and an able-bodied person would have turned on the lamp by the time the BCI system has turned it on. However, recent studies show that communication rates and accuracy promisingly increased with better research designs. In addition to BCI systems, AR systems and combination of both systems may enable us to control electronic devices in the real world environment (Navarro, 2004). Another study showed that Humanoid Robots can successfully complete particular everyday tasks such as pouring milk over a bowl by using hierarchical EEG-based BCI. Their design allows users to complete both relatively complex and basic tasks by using brain signals (Bryan et al., 2011). ALS patients or person suffering from voluntary muscle control problems may transport himself/herself with an EEG-based BCI adapted wheelchair (Iturrate et al., 2009). Researchers are also examining the combination of VR, AR, and BCI systems to improve rehabilitation and therapy techniques. For example, Mirror Box Therapy (MTB) displays illusory movements which correspond to patient’s brain activity to move healthy or injured limbs (Regenbrecht et al., 2014). With the improvement of the Human-Computer Interaction design in BCI, signal acquisition techniques and BCI strategies, new BCI systems will facilitate both able-bodied and disabled people’s everyday activities. Perhaps, the integration of neurologically disabled people and amputees into society will be possible with proliferated intelligent environments especially in hospitals, nursing homes, and rehabilitation centers. It will help them operate devices without using muscles or experience cultural and natural activities in an intelligent environment. For instance, an ALS patient could experience mountain climbing thanks to the virtual environment. Likewise, an amputee could totally control his artificial limb via an invasive BCI system in the future. 4.10 References ARCore. (2018) In Wikipedia. Retrieved from https://en.wikipedia.org/wiki/ARCore Augmented reality. (n.d.) In Wikipedia. Retrieved from: https://en.wikipedia.org/wiki/Augmented_reality Azuma, R. (1997). A Survey of Augmented Reality. Presence: Teleoperators and Virtual Environments, 6(4), pp.355-385. Azuma, R., Baillot, Y., Behringer, R., Feiner, S., Julier, S. and MacIntyre, B. (2001). Recent advances in augmented reality. IEEE Computer Graphics and Applications, 21(6), pp.34-47. Bichlmeier, C., Wimmer, F., Heining, S. M., &amp; Navab, N. (2007). Contextual Anatomic Mimesis Hybrid In-Situ Visualization Method for Improving Multi-Sensory Depth Perception in Medical Augmented Reality. 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality. doi:10.1109/ismar.2007.4538837 Billinghurst, M., Clark, A., and Lee, G. (2015). A Survey of Augmented Reality. Foundations and Trends® in Human-Computer Interaction, 8(2-3), pp.73-272. Blum, T., Stauder, R., Euler, E., &amp; Navab, N. (2012, November). Superman-like X-ray vision: Towards brain-computer interfaces for medical augmented reality. InMixed and Augmented Reality (ISMAR), 2012 IEEE International Symposium on(pp. 271-272). IEEE. Bogue, R. (2010). Brain-computer interfaces: control by thought. Industrial Robot: An International Journal, 37(2), 126-132. Bryan, M., Green, J., Chung, M., Chang, L., Scherer, R., Smith, J. and Rao, R. (2011). An adaptive brain-computer interface for humanoid robot control. 2011 11th IEEE-RAS International Conference on Humanoid Robots. Chayer, C. and Freedman, M. (2001). Frontal lobe functions. Current Neurology and Neuroscience Reports, 1(6), pp.547-552. Fatourechi, M., Bashashati, A., Ward, R. K., &amp; Birch, G. E. (2007). EMG and EOG artifacts in brain-computer interface systems: A survey. Clinical Neurophysiology, 118(3), 480-494. Google/Google Developers/ ARCore. (2018). Retrieved from: https://developers.google.com/ar/discover/ Hatsopoulos, N. G., &amp; Donoghue, J. P. (2009). The science of neural interface systems. Annual review of neuroscience, 32, 249. Hill, J., Brunner, P., &amp; Vaughan, T. (2011). Interface design challenge for brain-computer interaction. InFoundations of Augmented Cognition. Directing the Future of Adaptive Systems(pp. 500-506). Springer Berlin Heidelberg. Hoffmann, U., Vesin, J. M., Ebrahimi, T., &amp;Diserens, K. (2008). An efficient P300-based brain-computer interface for disabled subjects.Journal of neuroscience methods,167(1), 115- 125. Iturrate, I., Antelis, J., Kubler, A. and Minguez, J. (2009). A Noninvasive Brain-Actuated Wheelchair Based on a P300 Neurophysiological Protocol and Automated Navigation. IEEE Transactions on Robotics, 25(3), pp.614-627. Kansaku, K. (2011). Brain–machine interfaces for persons with disabilities. In Systems Neuroscience and Rehabilitation(pp. 19-33). Springer Japan. Kansaku, K., Hata, N., &amp; Takano, K. (2010). My thoughts through a robots eyes: An augmented reality-brain–machine interface. Neuroscience Research, 66(2), 219-222. doi:10.1016/j.neures.2009.10.006 Keonn Technologies - Interactive retail systems. (n.d.). Retrieved from https://www.keonn.com/systems/view-all-3.html Kerous, B., &amp; Liarokapis, F. (2017). BrainChat - A Collaborative Augmented Reality Brain Interface for Message Communication. 2017 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct). doi:10.1109/ismar-adjunct.2017.91 Krevelen,V, Rick &amp; Poelman, Ronald. (2010). A Survey of Augmented Reality Technologies, Applications and Limitations. International Journal of Virtual Reality (ISSN 1081-1451). 9. 1. Lalor, E., Kelly, S., Finucane, C., Burke, R., Smith, R., Reilly, R. and McDarby, G. (2005). Steady-State VEP-Based Brain-Computer Interface Control in an Immersive 3D Gaming Environment. Lebedev, M. A., &amp;Nicolelis, M. A. (2006). Brain–machine interfaces: past, present and future. TRENDS in Neurosciences, 29(9), 536-546. Levine, S. P., Huggins, J. E., BeMent, S. L., Kushwaha, R. K., Schuh, L. A., Passaro, E. A., … &amp; Ross, D. A. (1999). Identification of electrocorticogram patterns as the basis for a direct brain interface. Journal of clinical neurophysiology, 16(5), 439. Microsoft HoloLens. (2018). Microsoft. Retrieved from https://www.microsoft.com/en-us/hololens/why-hololens Müller-Putz, G., Scherer, R., &amp; Pfurtscheller, G. (2007). Game-like training to learn single s witch operated neuroprosthetic control. In BRAINPLAY 07 Brain-Computer Interfaces and Games Workshop at ACE (Advances in Computer Entertainment) 2007 (p. 41). Navarro, K. F. (2004). Wearable, wireless brain computer interfaces in augmented reality environments. In Proceedings of the IEEE International Conference on Information Technology: Coding and Computing, volume 2, pages 643–647. Piccione, F., Giorgi, F., Tonin, P., Priftis, K., Giove, S., Silvoni, S., …&amp;Beverina, F. (2006). P300-based brain computer interface: reliability and performance in healthy and paralysed users.Clinical neurophysiology,117(3), 531-537. Regenbrecht, H., Hoermann, S., Ott, C., Muller, L. and Franz, E. (2014). Manipulating the Experience of Reality for Rehabilitation Applications. Proceedings of the IEEE, 102(2), pp.170-184. Sellers, E. W., &amp; Donchin, E. (2006). A P300-based brain–computer interface: initial tests by ALS patients.Clinical neurophysiology,117(3), 538-548. Scherer, R., Chung, M., Lyon, J., Cheung, W., &amp; Rao, R. P. (2010, October). Interaction With Virtual And Augmented Reality Environments Using Non-Invasive Brain-Computer Interfacing. In1st International Conference on Applied Bionics and Biomechanics. Takano, K., Hata, N., &amp; Kansaku, K. (2011). Towards intelligent environments: an augmented reality–brain–machine interface operated with a see-through head-mount display. Frontiers in neuroscience, 5. Treder, M. S., &amp;Blankertz, B. (2010). Research (C) overt attention and visual speller design in an ERP-based brain-computer interface.Behav. Brain Funct,6, 1-13. Wagner, D., Pintaric, T., Ledermann, F., &amp; Schmalstieg, D. (2005). Towards Massively Multi-user Augmented Reality on Handheld Devices. Pervasive Computing, 208–219. doi:10.1007/11428572\\_13 "],
["a-methodology-for-microdosing-research-cognitive-behavioral-tasks-as-investigative-tools-for-tracking-low-dose-effects-of-psilocybin.html", "Chapter 5 A Methodology for Microdosing Research: Cognitive behavioral tasks as investigative tools for tracking low-dose effects of psilocybin 5.1 Abstract 5.2 Introduction 5.3 The Third Wave of Psychedelic Science 5.4 Microdosing 5.5 Tasks to Target Psychedelic Drug Effects 5.6 Discussion and Concluding Remarks 5.7 References:", " Chapter 5 A Methodology for Microdosing Research: Cognitive behavioral tasks as investigative tools for tracking low-dose effects of psilocybin Nicole Amada, PhD. Candidate, The Graduate Center, CUNY, May 25 2018 5.1 Abstract Modern day research on psychedelics offers strong evidence for the use of these substances to further our understanding of the brain, as well as to treat mental illness and addiction. While research in clinical science and neuroscience is flourishing, behavioral data, as well as research tracking low-dose effects, known as ‘microdoses,’ is lacking. Cognitive behavioral tasks may provide a unique contribution to psychedelic research through their ability to target specific cognitive functions and measure objective changes. This is particularly relevant to understanding the effects of microdosing, which may not be robust enough to be reliably captured with neuroimaging and may not be conscious enough to be reliably captured with self-reports alone. This paper pairs specific psychedelic effects with validated experimental tasks to systematically track low-dose effects of psilocybin. Cognitive behavioral data may also offer practical information for how these substances can be used and for what purposes. 5.2 Introduction Psychedelic substances are serotonergic hallucinogens (e.g. psilocybin, i.e. ‘magic mushrooms’ and LSD, i.e. lysergic acid diethylamide) that exert widespread effects in the brain through activation of the serotonin 5-HT2A receptor found primarily on the fifth layer of the cortex, (Carhart-Harris et al., 2015) but also found within the limbic system and brain-stem (Kent, 2012; Carter et al., 2005). The excitation of these neurons results in the recruitment of different cell-types, (Martin &amp; Nichols, 2016) and greatly alters the nature of communication between brain regions. Together, these dose-dependent effects make psychedelic substances primary candidates for manipulating cognitive mechanisms. For the purpose of this paper, the research methods proposed here are for investigating the low-dose effects of psilocybin, as opposed to including all serotonergic hallucinogens. The psychedelic state is characterized by altered cognition, sensory perception, and emotionality, resulting in changes in one’s sense of self and perceptions of reality, (Nour, Evans, &amp; Carhart-Harris, 2016; Letheby &amp; Gerrans, 2017; Wittman, et al., 2007) as well as personality characteristics, beliefs, and social attitudes (Carhart-Harris, Erritzoe, Kaelen, &amp; Watts, 2018; Bouso et al., 2015; Lerner &amp; Lyvers, 2006). While clinical and neuroscience research has tracked dose-dependent changes in subjective-reports (Griffiths et al., 2011) and neurophysiology (Nichols et al., 2003), there is far less work looking at dose-dependent changes in cognitive processes. The field of psychedelic research will require a multitude of various methodologies to fully capture the diverse effects of psilocybin. While the efforts of this paper are focused on employing these methods for low-dose research, cognitive psychologists who are interested in psychedelic research should also consider using these methods for higher-dose effects as well. Cognitive behavioral tasks may be especially fitting for microdosing research in their ability to track the onset and nature of changes in specific cognitive processes. The objective of this paper is to pair specific psychedelic drug effects with cognitive-behavioral tasks to elucidate the effects of microdosing. Cognitive data for microdosing research may be able to track changes that cannot be measured by subjective-report or neuroimaging alone. These methods are also important for answering practical questions about the effects of microdosing psilocybin or LSD on everyday functioning to help guide judgment on when and how to use them. Leading research on the effects of these substances from neuroscience and clinical fields are presented and briefly summarized, followed by an introduction and explication of microdosing. Psychedelic drug effects are then further explicated and appropriately paired with cognitive behavioral tasks. Lastly, comments for employing these methods in future research and concluding remarks are presented. 5.3 The Third Wave of Psychedelic Science The present section introduces and summarizes modern clinical and neuroscience research on psychedelic drug effects. While the focus of this paper is not to review previous research, summarizations are kept minimal, with the sole intention of capturing the essence of these two branches. This is important to the efforts of this paper because it establishes the foundation for why these substances should be used in research, which is (unfortunately) still a controversial topic in psychology. 5.3.1 Clinical Science The resurgence of psychedelic research was pioneered by clinical scientists and psychotherapists. In clinical research, psychedelics are paired with psychoanalysis to catalyze change in patients’ perception and perspective of themselves, life events, and their own suffering. Essentially, psychedelic substances generate an altered state whereby the agent is having a meaningfully-heightened experience. Here, he/she can process internal struggles from a unique emotional and cognitive state in order to transform them (with the help of a psychotherapist) into a self-narrative that is agentic and empathetic, rather than disempowering and critical. “…psychedelics engage the self in a humanistic transformative process which is (somewhat) transparent and meaning-respecting, rather than performing sub-personal surgery on the constituent parts of a passive self.” Chris Letheby (2015) comparing the nature of healing with psychedelics to other pharmacological interventions. Illnesses that have been ameliorated by psychedelic therapies include OCD (Moreno et al., 2006), near-death anxiety and depression (Ross et al., 2016; Gasser, Kirchner, &amp; Passie, 2014), and addiction (Vollenweider and Kometer, 2010; Garcia-Romeu, Griffiths, &amp; Johnson 2014; Bogenschultz et al., 2015; Krebs &amp; Johansen, 2012). While all of these disorders may share neurophysiological underpinnings, they are also likely linked by their common and interrelated symptomology. The concept of demoralization may encompass the possible commonalities between these disorders, and is defined here as the inability or lack of will to adaptively cope due to a real or perceived lack of control over his/her situation, as well a loss of life meaning and/or purpose (Vehling, 2017). Results from psychedelic-assisted psychotherapy have shown (generally) that psychedelic experiences tend to result in an enhanced sense of insight, meaning, and agency over ones choices and actions. Evidence also suggests that psychedelic experiences might ‘loosen the grip’ of maladaptive coping, (drug/alcohol dependency, unhealthy patterns of thoughts and behaviors) through an experiential and neurophysiological ‘re-perceiving’ and ‘re-wiring’ process, respectively. Clinical research has proven beyond a doubt that these substances can be used to treat mental illness in a way unlike any other pharmacological intervention. The multidisciplinary framework and holistic approach of this treatment makes it a unique and effective method that empowers individuals and produces lasting effects on cognitive and emotional processing. 5.3.2 Neuroscience The neurophysiological effects of psychedelic molecules are highly complex and widespread, causing direct and indirect effects across functional networks in the brain (Tagliazucchi et al., 2014). As this is not the focus of this paper, I will briefly summarize modern ‘big-picture’ theories of the psychedelic state at the brain level rather than delve into the details of neuropharmacology (for an in-depth review of the neuropharmacology of psychedelics, see Martin &amp; Nichols, 2016; Halberstadt, 2015) “…5-HT2A receptor agonism leads to desynchronization of oscillatory activity, disintegration of intrinsic integrity in the [default mode network] and related brain networks, and an overall brain dynamic characterized by increased between-network global functional connectivity, expanded signal diversity, and a larger repertoire of structured neurophysiological activation patterns.” Swanson (2018) Carhart-Harris and colleagues (2014) proposed the Entropic Brain Theory (EBT), which seeks to explain a given conscious state by its corresponding levels of entropy in the brain. Entropy is a measure of a systems physical order/disorder and informational certainty/uncertainty. EBT proposes that the phenomenological qualities of a conscious state can be mapped onto a scale ranging from low entropy (high order/high certainty) to high entropy (low order/low certainty) (Carhart-Harris et al., 2014). While normal waking consciousness is ‘sub-critical,’ and stable, psychedelic states are characterized by instability and uncertainty. This theory comes out of a series of neuroimaging studies that suggests these substances cause a diversification of functional networks (Tagliazucchi, 2014), as well as desynchronization of networks that would normally ‘suppress’ entropy, sustain a coherent sense of self, and maintain informational certainty about oneself, others, and the world (Muthukumaraswamy et al., 2013; see Carhart-Harris et al., 2014; Carhart-Harris, 2018 for a full description of this theory). Complementary to EBT, Swanson’s (2018) call for a unified theory of psychedelic drug effects expresses promise (as well as highlights some major contradictions), in predictive processing (PP) theories (Muthukamaraswamy et al., 2013; Pink-Haskes et al., 2015; Friston, 2010; Corlett, 2009). PP accounts of psychedelic drug effects extend out from the theory that normal conscious states are a sort of ‘controlled hallucination’ whereby the brain is simulating reality based on accurate predictions of sensory information (Clark, 2015). In PP models, the brain’s higher cortical structures seek to minimize prediction error in the brain by generating top-down signals that ‘match’ and inhibit lower-level processing in order to make sense of and accurately represent sensory information and bodily states (Friston, 2010, Clark 2013). The psychedelic state is therefore a ‘less controlled’ hallucination (Swanson, 2018) as a result of the hyper excitation of the cortex, therefore producing dream-like internal simulations of reality (see Swanson, 2018 for an in-depth review of predictive processing theories of psychedelic drug effects; Friston, 2010; Clark 2015). Exactly why and how psychedelics alter PP is largely unknown. 5.3.3 Summary Clinical and neuroscience fields have provided deep insight into the nature of psychedelic drug effects. Perhaps one of the most significant and consistent findings is the ability for these substances to catalyze immense change, cognitively and neurophysiologically. It is critical to acknowledge that the nature of that change, will be partially dependent on the individual’s unique experiences, prior neural structure, and then subsequent integration processes. While the phenomenological effects of psychedelics are highly complex and likely underpinned by an amalgamation of altered processing, cognitive-behavioral tasks may help to tease out which cognitive processes are being effected across individuals. 5.4 Microdosing Microdoses are 1/10-1/5 of a standard dose of a psychedelic substance (10-30 micrograms for LSD, 0.10-1.0 grams of psilocybin). A microdosing program is continuing to microdose 1-2 times a week for a period of 4-6 weeks (Fadiman, 2011). Due to the void of research on this topic, the effects of microdosing are unknown. Therefore, opportunities for research are plenty but will be largely exploratory. Longitudinal designs will be integral to microdosing research, as it is vital to understand whether or not these effects persist once the program has ceased. Whether or not the researcher is interested in acute effects from a single microdose, cumulative effects of continuous microdosing, or short-, medium-, or long-term effects will determine which methodologies are employed. Microdoses are sub-perceptual, meaning, the amount is not enough to “trip” but has been anecdotally reported to produce meaningful changes in cognition and emotionality (Johnstad, 2018). Anecdotal reports include increased energy, positive mood, less reactivity, enhanced focus, increased creativity, as well as amelioration of brooding, rumination, mild-depressive symptoms, and a significant amount of microdosers also report improving their habits and health-related behaviors (Fadiman, 2011; Gregoire, 2017; Johnstad, 2018; Waldman, 2017; Wong 2017). Despite these substantial anecdotal reports, there is very little work looking at the effects of microdosing, and controlled longitudinal studies are non-existent. 5.5 Tasks to Target Psychedelic Drug Effects This section presents the effects of psychedelics on perception and cognition and then pairs those effects with appropriate tasks. Cognitive behavioral tasks always involve some level of perceptual processing, therefore tasks were selected based on the function that they most prominently target. First, tasks that primarily focus on cognitive functions, such as attention, decision making, and problem solving will be discussed in relation to cognitive psychedelic effects. Second, tasks that focus primarily on perceptual processes, such as the ability to organize and identify sensory information will be discussed in relation to perceptual psychedelic effects. Deciding which tasks may capture low-dose psilocybin-induced changes in perceptual and cognitive processing is difficult at this stage in the research, so initial studies will be largely exploratory. However, insights from medium- and high-dose neuroimaging research will be drawn upon. 5.5.1 Cognitive Effects Psychedelic-induced alterations in brain activity increases cognitive flexibility while decreasing cognitive control and stability (Carhart-Harris, 2014, 2016), resulting in less controlled thought-processes, reduced performance in attentional tasks (Carter et al., 2005; Vollenweider et al., 2007), increased divergent thinking (Kuypers et al., 2016), expanded semantic activation (Family et al., 2016), and a tendency to attribute new meaning to perceptual stimuli (Preller et al., 2017). Long-term improvements in creative problem solving (Sweat et al., 2016), as well as increases in optimism, and trait ‘openness’ have also been reported in the literature (Maclean et al., 2011; Lebedev et al., 2016). Enhanced focus, sustained attention, clarity of mind, and increased cognitive control have been anecdotally reported by microdosers. Perhaps it is the case that microdosing does not result in any impairments of stability or control, rather an enhancement of these processes. If this is the case, it is important to identify whether creativity and flexibility are also enhanced or impaired. If microdosing does produce clarity in thought processes, researchers may find improved performance in processes that are effected by mind-wandering such as attention (Tang et al., 2009) and inhibition (Zeiden &amp; Faust, 2008). The following tasks were chosen to target attention, control, and flexibility. Research on microdosing may be able to discover critical points at which cognitive impairments and cognitive enhancements emerge. Microdosing research should expand the upper limit to 1/10-2/5 of a standard dose in order to identify when cognitive impairments escalate to a point that hinders normal functioning. 5.5.2 Working-Memory and Inhibition Tasks Working memory is a cognitive system or systems generally defined as the ability to hold information “on-line” and manipulating the information in processes of reason, comprehension, and/or learning (Baddeley, 2010). While there are many different theories about this function, what matters here is that it is a real process that allows human beings to hold information in the mind and think about it, and also that this ability has certain limitations. One of the only studies that used cognitive tasks to investigate psychedelic effects on cognitive functioning was done by Bouso and colleagues (2013), who investigated the effects of ayahuasca on working memory in 24 ayahuasca users (11 long-term and 13 occasional users). The researchers used the Stroop task, The Sternberg Task, and Tower of London Task prior and following ayahuasca intake. Their results indicate that, while working memory was impaired (shown by more errors in the Sternberg), stimulus-response interference was decreased (shown by decreased reaction times in the Stroop). They also found impairments of working memory only had negative effects in the less experienced group. The Stroop Color and Word Test (SCWT) was selected because it is a well-established and validated tool for investigating the ability to inhibit inappropriate responses and select appropriate responses (Scarpina &amp; Tagini, 2017). This will also keep consistency in the research to be able to make inferences about effects across studies. The task requires the participant to select the color that a word is presented in when the word itself is a different color. For example, the word “RED” will be presented in green ink and the participant must select “GREEN” to be correct, this is the incongruent condition. The congruent condition is when a word is presented, “RED” for example, and it is presented in red ink. In the congruent condition, the participant clicks “RED” for a correct response. Because reading the word is the more automatic response, the longer reaction times in incongruent trials is known as the Stroop effect (Stroop, 1935). The “n-back task” is widely used in cognitive science as a measure of working memory ability. The task requires participants to attend to a series of objects (typically numbers or words) presented on the computer screen, and to respond when an object is the same as the one that was presented n trials back (usually 2- or 3-back) (Meule, 2017). Here, the participant has to hold the previously presented objects in the mind while paying attention to the object that is currently being presented. In some n-back tasks, the participant is required to press one key when the object presented is not a match with the object n-back and another when it is a match. As to limit the number of cognitive functions required to perform, participants should be required to press a button only when the object presented is a match. Dependent variables that will be compared between groups is accuracy and reaction times. While it may not yield any significant differences, it would be interesting to modify the n-back to see whether or not the valence of a word would affect performance in the n-back task. In this case, a within-subjects variable would be the valence of words, with some trials being low in meaningfulness (chair, cup, hairbrush, toothpick, etc.), some trials with high positive valence (love, trust, beauty, honesty), and some trials being high in negative valence (hate, bully, outcast, violence). Although there’s not any direct evidence from psychedelic research that lends one to believe there would be differences, some exploration in this task could yield interesting results. 5.5.3 Cognitive Flexibility Tasks The ability to appropriately and efficiently adjust cognitive processing in response to a changing condition is perhaps the root of adaptability. Cognitive flexibility is this capacity, whereby an individual is able to switch from one strategy or mindset to another, in response to new or changing conditions, to achieve a desired goal. While tasks in the previous section focused on more automatic cognitive functions, tasks that measure cognitive flexibility must capture changes in more complex cognition or behavior after a person has been performing a task for some time (Cañas, Fajardo, &amp; Salmerón, 2018). Tasks must therefore have several elements such as an acquisition to a task, some environmental changes, and then a required adjustment to those changes in order to successfully perform. An individual’s cognitive flexibility is predictive factor for a range of adaptive outcomes (Zeytinoglu, Calkins, &amp; Leerkes, 2018). Individuals with high cognitive flexibility have shown higher levels of resiliency, (Genet &amp; Siemer, 2011) creativity, (Chen et al., 2014), and quality of life (Davis et al., 2010). The inability to shift strategies or mindsets when a current behavior or psychological state is not helpful can be described as cognitive rigidity (cognitive inflexibility). Cognitive rigidity can manifest mildly in unhealthy habits of mind and body that leave an individual in harmful loops and repetitions. It can also take more severe forms such as obsessive compulsive disorder and depressive rumination, both of which are characterized by rigid cognition (Meiran, Diamond, Toder, &amp; Nemets, 2010). Research on generalized anxiety disorder also reports cognitive rigidity underlies perseverative cognition (i.e. worry or rumination) (Ottaviani et al., 2015, 2016). In addition, research on eating disorders and social anxiety have both shown strong positive correlations with cognitive rigidity (Arlt et al., 2016). Microdosers report access to a greater repertoire of mindsets and perspectives, reflecting a shift from rigidity to flexibility. Bringing validity to these claims is a great challenge for cognitive scientists and deserves great efforts, as enhancing this ability could have positive effects in other aspects of mental life and wellbeing. A good assessment of whether or not microdoses of psychedelic substances can enhance cognitive flexibility would be tasks that require an individual to switch from one strategy or mindset to another to achieve a goal. Two tasks are presented that target different levels of cognitive processing. The first is a test of a more automatic ability to switch from one set of rules to another and respond very quickly. The second requires one to switch between higher-order processing strategies from identifying details of a story to comprehension of the overarching message of a story. The Simon Switch Task (SST) requires individuals to respond differently depending on the type of stimuli presented (adopted from Liu et al., 2016, originally Simon &amp; Barbaum, 1988, 1990). The task starts with a fixation point for about 800 ms, followed by an arrow that is either red or blue. If the arrow is red, participants must hit the arrow key that is the same as the direction of the arrow presented (congruent). If the arrow is blue, participants must hit the arrow key that is the opposite direction of the one presented (incongruent). Some blocks of trials will require a switch from blue to red arrows, while others will not. Switching involves the inhibition of a previously activated rule and the activation of the appropriate rule to employ the appropriate response. This type of switching can be considered a form of attentional flexibility, which is more automatic and requires less complex cognitions compared to the following task. The second task was selected to capture how microdosing psychedelics may alter one’s ability to perform complex cognitive flexibility tasks. Cañas and colleagues (2004) designed a cognitive flexibility task that requires participants to select the optimal strategy for solving a complex problem. The task is designed such that the participant must act quickly to put out a wild fire while considering the instruments and resources available to them, as well as environmental constraints such as wind speed and type of land. The researchers gave the participants several blocks with different task scenarios in which they had to adaptively adjust strategies given resource and environmental constraints. In every scenario, there was an optimal strategy that would successfully cover the most land in the shortest time. In order to capture the level of adjustment to new conditions, participants will get acclimated to responding in a certain scenario, and then switch the resources and constraints to see how quickly and effectively they solve the problem. The fire-fighter task could be an emotionally arousing experience for some individuals, leading to a decrease in performance as a result of physiological arousal. Research has shown decreased right-amygdala reactivity to negative and neutral stimuli after psilocybin administration, which was related to increases in positive mood. It could be that, for this task, the increased performance is partially or fully resulting from less emotional and physiological arousal, rather than an enhancement of cognitive flexibility. It is important that this task is counter-balanced with a task that is equally as cognitively demanding, but lacks any negative valence. While other cognitive functions are employed to perform these tasks, and other factors such as emotional arousal may be influencing the results, performance of task switching is reliably known to capture the varying levels of cognitive flexibility between individuals. 5.5.4 Creativity Task Research looking at the brain activity of schizotypal individuals have found that a greater spread of cortical activation is an important factor for creative thought processes (Park, Roberts, Kirk, and Waldie, 2015). This is also consistent with previously mentioned neuroimaging work that has shown diversification of functional networks after psychedelic administration, anecdotal reports of enhanced creative thinking, and increased activation of indirect semantic associations under psilocybin (Spitzer, 1996). Taken together, these findings lend some indirect support for the hypothesis that microdoses of psychedelics may enhance creative thinking by altering the communication of existing neural circuits to generate novel combinations of information. There are many different conceptualizations of creativity, but they essentially describe the ability for an individual to engage in conceptual and abstract thinking that goes beyond obvious or typical patterns to adopt a novel idea or perspective (Dietrich, 2004). A cognitive neuroscience approach will be used to operationalize this process. Creativity is considered here as a form of cognitive flexibility, constituted by the ability to generate novel and appropriate combinations of information, and is employed in any station where an individual has to adapt to a novel situation, context, or solve a problem (Dietrich, 2004). Kuypers and colleagues (2016) found that the psychedelic substance, Ayahuasca, enhances divergent cognition, a style of thinking whereby an individual is generating new ideas in a context where more than one solution is correct. This study used the Pattern/Line Meaning Task (PLMT) and the Picture Concept Task (PCT) to measure divergent thinking. The ability to think divergently is highly adaptive, as individuals need to generate a multitude of solutions to select the one that is the most appropriate. It is also important to generate alternative solutions when an existing behavior or thought process has become maladaptive or harmful. The task selected to assess whether microdosing a psychedelic substance (psilocybin or LSD) enhances creativity is the Alternative Uses Task (Guilford, 1967). This task is one of the classic measures of divergent thinking and is explorative and easy to employ. Participants must generate as many uses as possible for a given item within 45 seconds. Because these tasks will be online, the participant must type out as many uses as possible. Some examples of items include a shoe, snow, a car tire, a brick, a paperclip, a chair, a coffee mug, or any item that has a function but can be used for other purposes. Assessment techniques are adopted from a previous study and scored based on fluency (number of uses generated), flexibility (number of distinct groups responses could be placed in), appropriateness (1 for appropriate, 0 for inappropriate), originality (comparing each response to the responses of all other participants) (Addis et al., 2014). Because these judgments are done by researchers, it is important to have several raters and run inter-rater reliability checking. Outcomes on these four measures have significant inter-correlations, so it is possible to generate a mean divergent thinking score to compare between groups (Addis et al., 2014). 5.5.5 Perceptual Effects Psychedelic substances alter the way sensory information is processed and represented in the brain, possibly by altering the excitability of neurons in the visual cortex (Moreau et al., 2010). This alteration in visual processing results in distortions of external stimuli, (objects and their motion, shape, space, and distance) as well as the production of a sensory experience in the absence of external stimuli, which has all of the qualities of real perception, known as hallucinations (Kometer et al., 2013). Other perceptual effects include intensifications of textures, colors, lights, and sounds, as well as a higher level of detail perception, (Kometer &amp; Vollenweider, 2016) and synaesthesia (Ward, 2013). While microdoses are by definition ‘sub-perceptual’ and will not produce hallucinations or visual distortions, they may have subtle and/or unconscious effects on perceptual processing. Put another way, while microdoses will not alter the way the brain represents physical characteristics of external stimuli (the object itself), anecdotal reports of enhanced awareness to the environment suggest they may alter the ability to detect a stimuli and/or identify subtle changes in a visual scene. Because it is still unclear the exact nature of the disturbances in functional network connectivity, tasks that have already been linked to specific networks would help researchers identify which perceptual mechanisms are effected by LSD or psilocybin. 5.5.6 Perceptual Processing Tasks Psychedelic users report somewhat paradoxical effects of psychedelics on perceptual processing. In some cases, users report having enhanced detail perception and other reports reflect a more ‘gestalt’ processing of the environment. Therefore, the first task seeks to target these seemingly contradicting reports of changes in perceptual processing. It may be the case that how psychedelics alter processing of a visual scene depends on prior processing style, (Witkin, 1981; Walter &amp; Dassonville, 2011) in which case researchers can investigate the nature of the impact of these substances on processing style with this task as well, or just control for these individual differences. The Embedded Figures Task (EFT) targets the ability to find a particular shape within a more complex figure composed of many intersecting lines by breaking down the figure into its structural components (Manjaly et al., 2007). Neuroimaging research on this task have shown a recruitment of the frontoparietal network of brain regions (superior parietal cortex, precuneus, and middle frontal gyrus). Significant positive correlations between a portion of the right parietal cortex and processing speed were found, as well as strong correlations between processing speed and activation in the frontal gyrus (Walter &amp; Dassonville, 2011). This line of research suggests that healthy individuals rely on the integrity of the frontoparietal network is essential for proper EFT performance. Researchers interested in autism spectrum disorder (ASD) find that healthy individuals rely on working memory to suppress contextual information and search for the target shape, while the underconnectivity of frontoparietal regions in ASD cause individuals to rely more heavily on the parietal-occipital system for feature analysis (Ring et al., 1999; Damarla et al., 2010). Muthukumaraswamy and colleagues (2013) report decreased frontoparietal connectivity after psilocybin administration, which is also consistent with fMRI results (Carhart-Harris et al., 2012). Research on low-dose effects of psychedelics should employ this task in a between samples (grouped by dosage) design in order to identify when these substances begin to exert their effects on this functional network, as well as what processing styles are employed if frontoparietal connectivity is compromised. While the first task requires a shape be held in the mind and searched for in a complex embedded figure, the second task targets the ability to identify change in a scene with many visual elements. The Change Blindness Task (CBT) is more explorative and naturalistic compared to the EFT, and can perhaps capture more nuanced changes in perceptual processing. Change blindness is the inability to spot a change in a visual scene that is easily seen when pointed out (Hocchauser, Aran, &amp; Grynszpan, 2017). Tasks that target this phenomenon have been classified as a measure of explorative processing, or a controlled and innate type of selective attention (Enns &amp; Trick, 2006). The task involves the presentation of a visual scene, followed by a blank screen presented for (at least) 100 ms, and then the same scene with a missing (or changed) element. The participants must notice that a change has occurred and identify which element has changed or is missing, an outcome that varies by the degree of interest or relevance of this element within its context (Hocchauser, Aran, &amp; Grynszpan, 2017; Rensink, 2002). For a CBT on the effects of low-dose psychedelics, it would be important for visual scenes to vary in content. It has been found that psychedelics enhance a sense of connectedness with nature, animals, other people, therefor naturalistic or social scenes may just be of greater interest in general for the psychedelic group compared to the control group. Studies that employ this task should generate a series of visual scenes that vary in content in order to compare the level of change detection across scenes and between groups. As mentioned in the previous section, psychedelics have been subjectively reported to alter the way perceptual information is processed at both local levels (element and detail oriented) and global levels (holistic and meaning oriented). The CBT will be a particularly interesting task to employ because it is flexible, meaning the researcher can be a bit creative in order to investigate and control for many variables that may explain differences between groups. Research employing CBT should investigate changes in perceptual processing by manipulating the content of the visual scene (natural, social, industrial, etc.), level of relevance and meaning amongst elements (high connection/low connection), as well as the meaning saliency of the target element (high importance/low importance), and see how this correlates with detection rates. It will not be enough to say increased detection rates means an enhancement local processing. Increased detection rates could result from an enhanced global processing because of a heightened perception to meaning or relevance between elements. If one of the elements changes or goes missing, it can be detected by its “void of meaning” left behind as a function of its level of connection with other meaningful elements. This can be teased apart by systematically manipulating the level of connection between elements in the visual scenes and the level of importance of the changed/missing elements. Perhaps the type of processing, either local or global, that is employed will depend on the content and narrative of the visual scene itself. It is possible that the influence of psychedelics on perceptual processing may be contingent upon what and how content is presented, guiding the brain to employ the processing style that is most appropriate in a flexible and adaptive way. For example, if a visual scene has a bunch of elements that are not connected by meaning or relevance, perhaps a more local processing is employed to identify change. If a visual scene with high relevance between elements, perhaps a more global processing is employed. 5.6 Discussion and Concluding Remarks As mentioned previously, psychedelics are molecules that exert extremely widespread effects on the brain, cognitive processing, and behavior. Cognitive tasks may be able to identify critical points for the onset of effects on cognitive functioning, as well as capture the degree and nature of these effects. Ideally, cognitive tasks would also be paired with neuroimaging to identify changes in the functional network activity that underpins these tasks. This is important for explaining observed differences in performance. Subjective reports also have their place in supplementing findings from cognitive and neuroscience methods and should be included in any analysis, especially when there could be individual differences in strategies used. Although research that seeks to employ these tasks would ideally take place in a controlled, double-blind research setting, these substances remain federally illegal in the United States and most of Europe. Therefore, preliminary research will most-likely be de-identified and online, with the demand of 200+ participants for psychedelic and non-psychedelic groups. Initial studies can be considered preliminary, with the hopes of generating substantial evidence for why these methods should be funded and carried out in a laboratory. It is crucial that this research evolve into controlled, double-blind research designs. While cognitive tasks are considered objective measures, and sample sizes will be large, the lack of control of the dosage and purity of the psychedelic substance is a large confounding variable. This is important for taking into account placebo effects. Understanding how low-dose use of psychedelics effects cognitive functioning is not just an intriguing research opportunity. Many people across the world report using psychedelics at low-doses fairly often. This research has real-life application for individuals who are going to start microdosing but are unsure as to how it will affect their everyday functioning. It is important that cognitive science takes a leading role in the psychedelic research community, as the documented effects currently take the form of subjective report and neuroimaging data. 5.7 References: Alonso, J. F., Romero, S., Mananas, M. A., Riba, J. (2015). Serotonergic Psychedelics Temporarily Modify Information Transfer in Humans. International Journal of Neuropsychopharmacology: 1-9 Arlt, J., Yui, A., Eneva, K., Dryman, T. M., Heimberg, R. G., Chen, E. Y. (2016). Contributions of cognitive inflexibility to eating disorder and social anxiety symptoms. Eating Behavior: 30-32 Baddeley, A. (2010). Working Memory. Current Biology, 20(4). DOI: https://doi.org/10.1016/j.cub.2009.12.014 Baggott, M. J. (2015). Psychedelics and creativity: a review of the quantitative literature. PeerJ. PrePrints. doi: 10.7287/peerj.preprints.1202v1 Bouso, J. C., Palhano-Fontes, F., Rodríguez-Fornells, A., Ribeiro, S., Sanches, R., Crippa, J. A. S., et al. (2015). Long-term use of psychedelic drugs is associated with differences in brain structure and personality in humans. European Journal of Neuropsychopharmacology, 25: 483–492. doi: 10.1016/j.euroneuro.2015.01.008 Cañas, J.J. Quesada, J. F., Antolí, A., and Fajardo, I. (2003) Cognitive flexibility and adaptability to environmental changes in dynamic complex problem-solving tasks. Ergonomics, 46(482). Carhart-Harris RL, Erritzoe D, Williams T, Stone JM, Reed LJ, Colasanti A, Tyacke RJ, Leech R, Malizia AL, Murphy K, Hobden P, Evans J, Feilding A, Wise RG, Nutt DJ. (2012).Neural correlates of the psychedelic state as determined by fMRI studies with psilocybin. Proceedings in the National Academy of Science, USA. 109: 2138-2143. Carhart-Harris, R. L., Leech, R., Hellyer, P. J., Shanahan, M., Feilding, A., Tagliazucchi, E., Chialvo, D. R., Nutt, D. (2014). The Entropic Brain: a Theory of Conscious States Informed by Neuroimaging Research with Psychedelic Drugs. Frontiers in Human Neuroscience, 8(20). Carhart-Harris, R. L., Kaelen, M., Bolstridge, M., Williams, T. M., Williams, L. T., Underwood, R., et al. (2016b). The paradoxical psychological effects of lysergic acid diethylamide (LSD). Psychological Medicine. 46, 1379–1390. doi: 10.1017/S0033291715002901 Carhart-Harris, R.L., Erritzoe, D., Haijen, E., Kaelen, M., Watts., R. (2018). Psychedelics and connectedness. Psychopharmacology, 235: 547.https://doi.org/10.1007/s00213-017-4701-y Carter, O. L., Burr, D. C., Pettigrew, J. D., Wallis, G. M., Hasler, F., and Vollenweider, F. X. (2005). Using psilocybin to investigate the relationship between attention, working memory, and the serotonin 1A and 2A receptors. Journal of Cognitive Neuroscience, 17, 1497–1508. doi: 10.1162/089892905774 Chen Q., Yang, W., Li, W., Wei, D., Li, H., Lei, Q., Zhang, Q., Qiu, J. (2014). Association of creative achievement with cognitive flexibility by a combined voxel-based morphometry and resting-state functional connectivity study. NeuroImage, 102:474–483 Clark, A. (2013). Whatever next? Predictive brains, situated agents, and the future of cognitive science. Behavioral Brain Science, 36: 181–204. doi: 10.1017/S0140525X12000477 Clark, A. (2015). Surfing Uncertainty: Prediction, Action, and the Embodied Mind. Oxford: Oxford University Press. Damarla, S. R., Keller, T. A., Kana, R. J., Cherkassky, V. L., Williams, D. L., Minshew, N. J., Just, M. A. (2010). Cortical underconnectivity coupled with preserved visuospatial cognition in autism: Evidence from an fMRI study of an embedded figures task. Autism Research, 3(5): 273-279. Davis, J. C., Marra, C. A., Najafzadeh, M., Liu-Ambrose, T. (2010). The independent contribution of executive functions to health related quality of life in older women. BMC Geriatrics, (10)16. Dietrich, A. (2004). The Cognitive Neuroscience of Creativity. Psychonomic Bulletin &amp; Review, 11(6): 1011-1026 Addis, D. R., Ling Pan, R., Schacter, D. L., Schacter, M. (2014): Divergent thinking and constructing episodic simulations. Memory, DOI: 10.1080/09658211.2014.985591 Enns, J. T., &amp; Trick, L. M. (2006). Four modes of selection. In Lifespan cognition: Mechanisms of change (pp. 43–56). Oxford: Oxford University Press Fadiman, J. (2011). The Psychedelic Explorer’s Guide: Safe, Therapeutic, and Sacred Journeys. Inner Traditions/Bear &amp; Company. ISBN-13: 9781594774027 Family, N., Vinson, D., Vigliocco, G., Kaelen, M., Bolstridge, M., Nutt, D. J., et al. (2016). Semantic activation in LSD: evidence from picture naming. Language, Cognition, and Neuroscience. 31, 1320-1327. doi: 10.1080/23273798.2016.1217030 Friston, K. (2010). The free-energy principle: a unified brain theory? National Review Neuroscience. 11, 127–138. doi: 10.1038/nrn2787 Gasser, P., Kirchner, K., Passie, T. (2014). LSD-assisted psychotherapy for anxiety associated with a life-threatening disease: a qualitative study of acute and sustained subjective effects. Journal of Psychopharmacology: 1-12. DOI: 10.1177/0269881114555249 Genet JJ, Siemer M. (2011). Flexible control in processing affective and non-affective material predicts individual differences in trait resilience. Cognition and Emotion, 25:380–388 Gregoire, C. (2017). Everything you Wanted to know about Microdosing (But Were Afraid to Ask): A leading psychedelic researcher explains what’s really behind the trend. Huffington Post, 2017. Griffiths, R. R., Johnson, M. W., Richards, W. A., Richards, B. D., McCann, U., Jesse, R. (2011). Psilocybin occasioned mystical-type experiences: immediate and persisting dose- related effects. Pharmacology, 218(4): 649-65. doi: 10.1007/s00213-011-2358-5 Guilford, J. P. (1967). The nature of human intelligence. New York, NY: McGraw-Hill. Halberstadt, A. D. (2015). Recent Advances in the Neuropsychopharmacology of serotonergic Hallucinogens. Behavioral Brain Research, 277: 99-120 Hocchauser, M., Aran, Adi., Grynszpan, O. (2017). How Adolescents with Autism Spectrum Disorder (ASD) Spontaneously Attend to Real-World Scenes: Use of a Change Blindness Paradigm. Journal of Autism and Developmental Disorders. DOI 10.1007/s10803-017-3343-6 Johnstas, P. G. (2018). Powerful Substances in tiny amounts: An interview study pf psychedelic microdosing. Nordic Studies on Alcohol and Drugs, 35(1), 39-51 Kent, J. L. (2010). Psychedelic information theory: Shamanism in the age of reason. PIT Press/Supermassive. Krebs, T.S., Johansen, P. Lysergic acid diethylamide (LSD) for alcoholism: meta-analysis of randomized control trials. Journal of Psychopharmacology, 26(7): 994-1002 Kuypers, K. P. C., Riba, J., de la Fuente Revenga, M., Barker, S., Theunissen, E. L., and Ramaekers, J. G. (2016). Ayahuasca enhances creative divergent thinking while decreasing conventional convergent thinking. Psychopharmacology 233, 3395–3403. doi: 10.1007/s00213-016-4377-8 Letheby, C. The Philosophy of Psychedelic Transformation. Journal of Consciousness Studies, 22(9-10): 170-193 Letheby, C., Gerrans, P. (2017). Self unbound: ego dissolution in psychedelic experience. Neuroscience of Consciousness, 1(1). Learner, M., Lyvers, M. (2006). Values and Beliefs of Psychedelic Drug Users: A Cross-Cultural Study. Journal of Psychoactive Drugs, 38(2) Lebedev, A. V., Kaelen, M., Lövdén, M., Nilsson, J., Feilding, A., Nutt, D. J., Charhart-Harris, R. L. (2016). LSD-Induced Entropic Brain Activity Predicts Subsequent Personality Change. Human Brain Mapping, 37(9): 3203-3213 Liu, H., Fan, N., Rossi, S., Yao, P., Chen, B. (2016). The effect of cognitive flexibity on task switching and language switching. International Journal of Bilingualism, 20(5): 563-579 MacLean, K. A., Johnson, M. W., and Griffiths, R. R. (2011). Mystical experiences occasioned by the hallucinogen psilocybin lead to increases in the personality domain of openness. Journal of Psychopharmacology, 25, 1453–1461. doi: 10.1177/0269881111420188 Manjaly, Z. M., Bruning, N., Neufang, S., Stephan, K. E., Brieber, S., Marshall, J. C. (2007) Neurophysiological correlates of relatively enhanced local visual search in autistic adolescents. NeuroImage, 35(1):283–291 Martin, D. A., Nichols, C. E. (2016). Psychedelics Recruit Multiple Cellular Types and Produce Complex Transcriptional Responses Within the Brain. Elsevier BioMedicine: 262-277 http://dx.doi.org/10.1016/j.ebiom.2016.08.049 Nour, M. M., Evans, L., Carhart-Harris, R. L. B.Sc. (2017): Psychedelics, Personality and Political Perspectives. Journal of Psychoactive Drugs, DOI: 10.1080/02791072.2017.1312643 Meiran, N., Diamond, G. M., Toder, D., Nemets, B. (2011). Cognitive rigidity in unipolar depression and obsessive compulsive disorder: Examination of task switching, Stroop, working memory updating and post-conflict Adaptation. Psychiatry Research, 185(1-2): 149-156 doi:10.1016/j.psychres.2010.04.044 Meule, A. (2017). Reporting and Interpreting Working Memory Performance in n-back Tasks. Frontiers in Psychology, 8(352). DOI: 10.3389/fpsyg.2017.00352 Muthukumaraswamy, S. D., Carhart-Harris, R. L., Moran, R. J., Brookes, M. J., Williams, T. M., Errtizoe, D., Sessa, B., Papadolpoulos, A., Bolstridge, M., Singh, K. D., Feilding, A., Friston, K. J., Nutt, D. J. (2013). Broadband Cortical Desynchronization Underlies the Human Psychedelic State. Journal of Neuroscience, 33(38): 1517-15183 Nour, M. M., Evans, L., Nutt, D., and Carhart-Harris, R. L. (2016). Ego-dissolution and psychedelics: validation of the Ego-Dissolution Inventory (EDI). Frontiers in Human Neuroscience, 10(269) doi: 10.3389/fnhum.2016.00269 Ottaviani, C., Medea, B., Lonigro, A., Tarvainen, M., Couyoumdjian, A. (2015). Cognitive rigidity is mirrored by autonomic inflexibility in daily life perseverative cognition. Biological Psychology, 107: 24-30 Ottaviani, Christina, Watson, David R, Meeten, Frances, Makovac, Elena, Garfinkel, Sarah N and Critchley, Hugo D. (2016). Neurobiological substrates of cognitive rigidity and autonomic inflexibility in generalized anxiety disorder. Biological Psychology, 119: 31-41. ISSN 0301- 0511 Park H, Roberts R, Kirk I and Waldie K (2015). Neural Correlates of Creativity in Schizotypy: an fMRI study. Frontiers in Human Neuroscience. Conference Abstract: XII International Conference on Cognitive Neuroscience (ICON-XII).doi: 10.3389/conf.fnhum.2015.217.00288 Preller, K. H., Vollenweider, F. X. (2016). Phenomenology, Structure, and Dynamics of Psychedelic States. Current Topics in Behavioral Neurosciences Springer, Berlin, Heidelberg. DOI: https://doi.org/10.1007/7854_2016_459 Preller, K. H., Herdener, M., Pokorny, T., Planzer, A., Kraehenmann, R., Stämpfli, P., et al. (2017). The fabric of meaning and subjective effects in LSD induced states depend on serotonin 2A receptor activation. Current Biology, 27: 451–457. doi:10.1016/j.cub.2016.12.030 Rensink, R. A. (2002). Change detection. Annual Review of Psychology, 53(1), 245–277. Ring, H. A., Baron-Cohen, S., Wheelwright, S., Williams, S. C. R., Brammer, M., Andrew, C. (1999). Cerebral correlates of preserved cognitive skills in autism: A functional MRI study of Embedded Figures Task performance. Brain, 122(7):1305–1315. Ross, S., Bossis, A., Guss, J., Agin-Liebes, G., Malone, T., Cohen, B., Mennenga, S. E., Belser,A., Kalliontzi, K., Babb, J., Su, Z., Corbey, P., Schmidt, B. L. (2016). Rapid andsustained symptom reduction following psilocybin treatment for anxiety and depression in patients with life-threatening cancer: a randomized controlled trial. Journal of Psychopharmacology, 30(12): 1165-1180 Scarpina, F., Tagini, S. (2017). The Stroop Color and Word Test. Frontiers in Psychology, 8(557). DOI: 10.3389/fpsyg.2017.00557 Simon, J. R., Berbaum, K. (1988): Effect of irrelevant information on retrieval time for relevant information. Acta Psychologica, 67(1):33–57. Simon, J. R., Berbaum, K. (1990): Effect of conflicting cues on information-processing — the Stroop effect vs the Simon effect. Acta Psychologica, 73:159 –170. Spitzer, M., Thimm, M., Hermle, L., Holzmann, P., Kovar, K. A., Heirmann, H., Gouzoulis-Mayfrank, E., Kischka, U., Scheider, F. (1996). Increased activation of indirect semantic associations under psilocybin. The Journal of Psychiatric Neuroscience and Therapeutics, 39(12): 1055-1057. DOI: https://doi.org/10.1016/0006-3223(95)00418-1 Stroop, R. J. (1935). Studies of Interference in Serial verbal Reactions. Journal of Experimental Psychology, 18: 643-662 Swanson, L. R. (2018). Unifying Theories of Psychedelic Drug Effects. Frontiers in Pharmacology, 9(172). doi: 10.3389/fphar.2018.00172 Sweat, N. W., Bates, L. W., and Hendricks, P. S. (2016). The associations of naturalistic classic psychedelic use, mystical experience, and creative problem solving. Journal of Psychoactive Drugs, 48, 344–350. doi: 10.1080/02791072.2016.1234090 Tagliazucchi, E., Carhart‐Harris, R., Leech, R., Nutt, D., &amp; Chialvo, D. R. (2014). Enhanced repertoire of brain dynamical states during the psychedelic experience. Human brain mapping, 35(11), 5442-5456. Tang, Y. Y., Ma, Y., Fan, Y., Feng, H., Wang, J., Feng, S., et al (2009). Central and autonomic nervous system interaction is altered by short-term meditation. Proceedings of the National Academy of Sciences, 106(22), 8865–8870. doi:10.1073/pnas.0904031106. Vehling, S., Kissane, D. W., Lo, C., Glaesmer, H., Hartung, T. J., Rodin, G., Mehnert, A. (2017). The association of demoralization with mental disorders and suicidal ideation in patients with cancer. Cancer, American Cancer Society,https://doi.org/10.1002/cncr.30749 Vollenweider, F. X., Csomor, P. A., Knappe, B., Geyer, M. A., and Quednow, B. B. (2007). The effects of the preferential 5-HT2A agonist psilocybin on prepulse inhibition of startle in healthy human volunteers depend on interstimulus interval. Neuropsychopharmacology 32, 1876–1887. doi: 10.1038/ sj.npp.1301324 Waldman, A. (2017). A Really Good Day: How Microdosing Made a Mega Difference in My Mood, My Marriage, and My Life. Alfred A. Knopf, Penguin Random House LLC. Ward, J. (2013). Synesthesia. Annual Review in Psychology, 64: 49–75. doi: 10.1146/annurevpsych-113011-143840 Walter E, Dassonville P (2011) Activation in a Frontoparietal Cortical Network Underlies Individual Differences in the Performance of an Embedded Figures Task. PLoS ONE, 6(7): e20742. https://doi.org/10.1371/journal.pone.0020742 Witkin, H. A., Goodenough, D. R. (1981) Cognitive styles: essence and origins. Field dependence and field independence. Psychological Issues: 1–141 Wittmann, M., Carter, O., Hasler, F., Cahn, B. R., Grimberg, U., Spring, P., Hell, D., Flohr, H., Vollenweider, F. X. (2007). Effects of psilocybin on time perception and temporal control of behaviour in humans. Journal of Psychopharmacology, 21(1): 50-64 Wong, S. (2017). Leading the high life. Journal of Psychopharmacology, 21(1), 50-64 Zeidan, F., &amp; Faust, M. (2008). The effects of brief mindful training on cognitive control. In Southeastern psychological association conference, Charlotte, NC. Zeytinoglu, S., Calkins, S. D., Leerkes, E. M. (2018). Maternal emotional support but not cognitive support during problem-solving predicts increases in cognitive flexibility in early childhood. International Journal of Behavioral Development. "],
["perceiving-the-world-around-us-how-divergent-methods-illustrate-convergent-perspectives.html", "Chapter 6 Perceiving the World Around Us: How Divergent Methods Illustrate Convergent Perspectives 6.1 Introduction 6.2 The Visual System and Present Controversy 6.3 Cognitive and computational approaches 6.4 Conclusion and Implications 6.5 References", " Chapter 6 Perceiving the World Around Us: How Divergent Methods Illustrate Convergent Perspectives Jordan Wylie, The Graduate Center, CUNY, May 25 2018 6.1 Introduction Exogenous, sensory data helps us navigate through our daily lives. Our body’s specialized cells and tissues receive raw sensory information and translate it into signals that the mind and body can understand. The architecture of our brains is well-suited to handle, sort, and filter through the enormous amounts of sensory signals and noise that we encounter every day. One such sensory modality, vision, dominates phenomenological experience and has, in turn, dominated research on both bottom-up (or outside-in) and top-down (or inside-out) approaches to perception. The rich visual system literature spans domains and methodologies within psychology and related disciplines, many of which suggest a shared understanding of how the brain is able to integrate stored information, while continually processing new incoming stimuli. Though it may still be unclear, new computational approaches and computer-informed methodologies have shed light on an age-old debate. Namely, do our motivations and expectations inform conscious perception? Research spanning decades has demonstrated the amazing capacity of the human visual system. Much of the brain’s posterior cortical structure is devoted in some way to processing visual information, with nearly half of the nonhuman primate neocortex being devoted to such processes (DiCarlo, Zoccolan, &amp; Rust, 2012; Felleman &amp; Van Essen, 1991). The dense visual network within the human brain is not contained within the occipital lobe, but recruits assistance from surrounding cortical areas. During visual processing, neural pathways work together to quickly discriminate between stimuli on a vast number of features; patterns, colors, motion, and many other structural features of our visual environments are registered on the retina and then integrated into ongoing neural and cognitive processing. Despite a vast literature, complete mechanistic understanding of visual perception and recognition are still absent. Researchers continue to debate how exactly we interpret the world around us, and which methods are most appropriate for tackling that question. Some theorists have purposed a functionally impenetrable visual perception that is unadulterated by cognitive processes occurring elsewhere in the brain (Pylyshyn, 1999), while others disagree (see Friston, 2010), believing perception to be integrated with cognition similar to nearly all other functions within the brain. The present chapter will attempt to review this issue and relevant research findings guided by the predictive brain lens. Specifically, the focus of the following chapter will be to examine how evidence of predictions inform visual recognition, as supported by neuroscientific and cognitive findings. How might social norms, our motivations and emotions, and informational assumptions influence what we see? Perceptual and recognition accuracy are fundamental to our visual experience, allowing us to interpret and make sense of the world around us. While research on the visual system touches many other important aspects to visual experiences (e.g., attention), those are not within the scope of the present review. Instead, I will focus on how neuroscientific, affective and motivational, and cognitive approaches can reveal important information about visual object recognition. 6.2 The Visual System and Present Controversy It is well documented that human beings have exceptional visual capabilities. While an owl may see with acuity at night, and the lizard may lack a visual blind spot, the human visual system, which has evolved from a shared primate brain, allows for flexibility and an emergent, powerful ability to predict. The combination of our physiology and cognitive abilities enables the integration of vast amounts of visual information to create perceptual experiences that do not deviate much from those around us. Indeed, visual experience requires some uniformity to ground humans in an agreed upon representation of reality. Perception is, therefore, rooted in this understanding and must be tethered to some similarity across people. By counter example, hallucinations demonstrate how perception without reality constraints lacks any observable order (see Clark, 2013). We must agree that a particular pattern of waves that hit the retina yield the color green, this is the first step in semantic development and abstracting away important ideas. But the question remains, how do we (or do we at all) use previous information, memories and states to inform and facilitate visual perception? However, these questions are not novel. Beginning as far back as Descartes (1637), there has been a marked intrigue in how, mechanistically, humans are able to assimilate the extensive visual information present at any given moment to adequately traverse our social environments. This curiosity has not waned. Visual system-centered work has extended beyond m using of Da Vinci and Descartes to more modern-day science like Hubel (Polyak,1957; Schmolesky, 1995). Today, we capitalize on access to neurophysiological components of the visual system and a general template for information processing to inform questions and research concerning vision. Research done with similar primate visual systems, the macaque monkey, illuminated some key neural structures that process visual information (Fitzpatrick, Itoh, &amp; Diamond, 1983; Shipp &amp; Zeki, 1989). By mapping specific connections across brain regions, we have begun to piece together where the visual system is distributed in the brain, which regions are most crucial for processing visual information, and the cascade of processes and networks responsible for the bringing visual information to conscious awareness. However, correlating activity and locating areas within the brain can only answer so many questions. It is necessary to extend these models to other domains to understanding how these areas work. Are they running in parallel or serially? Modular accounts of visual recognition suggest that distinct visual cortical areas (V1-V5) process different types of visual information and together makeup the primary cascade for recognizing objects (Ungerleider &amp; Haxby, 1994). Visual information first hits the retina and is pooled by ganglion cells. It is here that the other important facets of the visual system are most salient. Namely, attending to specific areas allows for information to hit the field of vision, with information situated close to the fovea most effectively represented. After this, information is passed to the LGN for transduction, which finally sparks the cascade of processing to create the final representation (Van Essen, Anderson, &amp; Felleman, 1992; Felleman &amp; Van, 1991). Beginning at the primary visual cortex, or V1, rudimentary object features are calculated from raw visual information (Desimone &amp; Ungerleider, 1989). From there, increasingly specialized areas selectively fill in missing information that builds up to a representation of the object at the conscious level (Kastner &amp; Ungerleider 2000). Moreover, computational evidence suggests that the cascade of processing within the visual system that leads to the conscious categorization and subsequent identification of objects proceeds in a hierarchical fashion. Again, using the macaque monkey’s visual system as a proxy, findings suggest that the specific cortical areas (e.g., V1, V4) process distinct components of the overall sensory input. This processing occurs through a series by which processing low-level features of the two-dimensional space eventually producing a three-dimensional (3-D) object representation (Perrett &amp; Oram, 1993). Other theorists have extended this work to evaluate the applicability given human biological constraints, finding that physiological evidence that implicates the inferior temporal cortex (IT) can be modelled for basic performance (Riesenhuber &amp; Poggio, 1999). Essential to this line of reasoning is the feed-forward building of complexity. Neurophysioloigcal mapping has established specific subdivisions, each of which contribute to the overall functioning. These subdivisions are largely made up of different cellular signal, including the magnocellular (M-pathway) and the parvocellular (P-pathway), research that has been spearheaded by studies of the macaque monkey visual system (Maunsell, Nealey, &amp; DePriest, 1990). The M-pathway and P-pathway have also been linked to specific spatial frequency information, whereby the M-pathway, situated primarily in the dorsal stream, is sensitive to low-spatial frequency information, and the P-pathway, primarily located in the ventral stream, is sensitive to high-spatial frequency information (Burr, Morrone, &amp; Ross, 1994; Goffaux et al., 2005). Whereas the P-pathway primarily facilitates perception of contrast and color, notably higher-order features of visual perception, the M-pathway facilitates perception of motion and coarse greyscale information (Merigan and Maunsell, 1993; Vuilleumier et al., 2003). Interestingly, these pathways are also thought to map onto unconscious (M-pathway) and conscious (P-pathway) visual processing (Tapia &amp; Breitmeyer, 2011). These divergent features of cellular channels within the visual system highlights important characteristics of our primate visual system; namely, the parallel, coordinated nature of visual processing. Whereas these approaches are founded on the bottom-up nature of visual perception and object recognition, recent research has begun to challenge this view. For instance, the subjective value of an object may affect the proximity in which said object is perceived. Subjectively more desired objects (e.g., money) are estimated as closer in proximity than less desirable objects (Balcetis &amp; Dunning, 2010). Further, research on action potential suggests that perception of hill steepness is influenced by metabolic costs (Proffitt, 2006). This line of research has revived the New Look debate, which claims that our beliefs, motivations, affordances, and more directly affect how we interpret incoming visual data (Balcetis, 2016). The updated New Look advocates a penetrability of perception by cognition, while other researchers continue to advocate a cognitively “impenetrable” V1, suggesting methodological limitations have stymied legitimate challenges to conventional conceptions of bottom-up processing (see Firestone &amp; Scholl, 2016). Are the differences in observed behavior a function of response biases or actual perceptual modulation? Does the money actually appear closer? Or is it just a function of the relative desirability? If a judgement is driving the observed differences in responses, early regions of the visual process cascade may be independent of cognitive influence. While evidence is mounting, these questions remain to be answered. In the following sections, I will attempt to answer these questions through the predictive lens. First, I will touch on prominent approaches to studying object recognition in humans. While the lens from which object recognition is studied varies greatly, an overarching goal is to better understand how human brains utilize prior information to inform ongoing processing of visual information. How might stimulus-driven conceptions of vision be limiting? What units or features of visual stimuli make up the foundation for understanding complex objects encountered? The scope of our knowledge about our environments is vast, informed by physiological states, memory, and sensory signals across modalities. How all of this information is integrated represents a critical question within vision research. Beginning with neuropsychological approaches to vision and then moving to cognitive science methods, the following sections will attempt to consider the relative advances and limitations to studying vision through the predictive lens. To answer these questions of general perception and more specific questions of object recognition, methodological approaches began by neural pathway mapping. This was useful in identifying particular neurons that process specific information, but it does not get us closer to understanding how this happens. Computational approaches are currently gaining momentum. These approaches differ slightly from traditional neurobiological study of perception, instead assessing how to maximize information processing model fits. 6.2.1 Neurophysiological Evidence Neural approaches have guided much of the research on the visual system and predictive vision. These approaches capitalize on the physical accessibility of neuroscientific methodology, enabled by the similarity in the visual cortices of other primates (Milner &amp; Goodale 1995). Early work has isolated two major pathways by which our visual system preferentially processes distinct components of what we see (Milner &amp; Goodale, 2008). Specifically, the ventral stream tells us what an object is, while the dorsal tells us where it is (Goodale &amp; Milner, 1992; Goodale &amp; Westwood, 2004). Moreover, the ventral stream is a low-level visual pathway, made up of descending and ascending routes, that are necessary for detailed visual information (Bar, 2000). Much of the research on ventral stream processing has focused on the traditional bottom-up approach, or on the ascending pathways, whereby visual information hits the V1, V2, and V4 cortical areas and then projects onto the high-level regions that are implicated in object perception like the IT (Bar, 2000). Generally, it is through these visual cortices (V1-V4) that the ventral visual stream hierarchically creates the visual representation (Hong, et al., 2016). Contrastingly, the dorsal stream is implicated in movement-based vision, aiding in the calibration of motor functions and detection of movement in the periphery. This pathway is less implicated in the process of object recognition but rather, fine-tuned for perception for action (Goodale &amp; Milner, 1992). However, some research has suggested that our brain may rely on predictions from gross low-level features to supply an initial guess for other parts of the visual system to inform (Bar, 2003; Bar et al., 2006; Kveraga, Boshyan, &amp; Bar, 2007). These findings highlight the potentially important contribution of the dorsal stream to complex visual object recognition and have opened the door to new explorations within the purview of the predictive lens. The dual-system process model posits that ascending neural pathways in the ventral stream hierarchically build the representation of a given object. Though this is undoubtedly a piece of the puzzle, there is much to be gleaned from incorporating feedback loops into the model of visual object recognition. Specifically, research has demonstrated the importance of context in object perception (Bar, 2004; Fenske, Aminoff, Gronau, &amp; Bar, 2006), engagement of higher-order structures in processing degraded or ambiguous stimuli (Wyatte, Curran, &amp; O’Reilly, 2012), and perceptibility of low spatial frequency objects (Kverega, 2007). Recent evidence has corroborated these findings, demonstrating context-dependent oscillation patterns within the prefrontal and parietal cortices (Helfrich, Huang, Wilson, &amp; Knight, 2017). These findings emphasize the role of expectation in guiding and enhancing visual perception. Contextual factors provide cues to associate with similar objects, facilitating and even biasing visual processing. The two-system approach garnered a great deal of support, engendering a flood of scientific research. However, there are fundamental limitations to such approaches. Namely, these approaches rely on isolating pathways in the brain, ostensibly overlooking the complexities and interdependences that exist between these pathways. It is well documented that the brain is an iterative, dynamic organ (Cunningham &amp; Zelazo, 2007). Research in this domain has implicated the PFC and reflective processing to extricate human neural processing from the more automatic associative processing seen in animals, favoring a hierarchical brain architecture that allows for afferent and efferent connections between brain regions (see Zelazo &amp; Cunningham, 2007). This approach has also been situated within the object recognition literature. Work done by Bar (2000) underscores how studying the pathways separately may have neglected important contributions from prefrontal brain areas to ongoing visual processing. To fully understand how neurobiology might suggest a top-down, cognitive penetrability, it is important to reconcile the role of the orbitofrontal cortex (OFC) in the processing of affective information. Specifically, the amygdala has established connectivity to the OFC, which implicates it in encoding emotionally salient information (Pessoa &amp; Adolphs, 2010). Studies have implicated the OFC in representing threat and reward (Kringelbach &amp; Rolls 2004), as well as in processing and representing auditory and visual information (Kringelbach 2005). This research has further linked the OFC to visual processing by demonstrating that the OFC is activated around 80-130ms after stimulus onset (Lamme &amp; Roelfsema 2000). While this is not the earliest component of visual processing (&lt;100ms), utilization of fMRI and MEG imaging has established the temporal activity during the short latency period, a time early enough to modulate ongoing processing (Barrett &amp; Bar, 2009; O’Callaghan, Kveraga, Shine, Adams, &amp; Bar, 2016). Finally, while not the primary focus of the present chapter, attention is an important part of visual perception that often obfuscates the interpretation of visual system penetrability. Attention is an obviously critical facet of the visual system and is important to understanding the ways in which higher-order cognitive processes bias visual processing. We can only process what we attend to, and as such, visual attention operates as a sort of gate keeper in the cascade of conscious object representation. Specific stimulus properties, like emotion, are prioritized, which increases the likelihood that they will be attended to (Öhman, Flykt, &amp; Esteves, 2001). Indeed, like a perceptual bias or expectation, attentional biases increase the probability of recognition. This makes parsing attentional versus perceptual biases difficult to disentangle. However, even at the attentional level, some findings are suggesting an influence of visual expectations (Gantman &amp; Van Bavel, 2014). Attentional control refers to processes that facilitate both suppression of irrelevant stimuli (temporal attention) and broaden the breadth of visual field input (spatial attention), which research has shown are attentional systems differentially biased based on emotional states (Clore &amp; Huntsinger, 2007; Gable &amp; Harmon-Jones, 2008, 2010). Spatial, or broadened attention, increases target detection in peripheral locations, yet increases inaccurate responses due to the costs associated with unfocused processing of visual stimuli. Conversely, temporal or flexible attention requires a focused lens, making irrelevant and peripheral targets difficult to process, but increases the accuracy of target identification. Specifically, previous research has shown that high arousal emotions increase local target detection compared to happiness and sadness (Easterbrook, 1959; Eysenck et al., 2007; Gable &amp; Harmon-Jones, 2008, 2010; Clore &amp; Huntsinger, 2007; Wells &amp; Matthews, 1996). These results highlight the ways in which motivations and emotions may influence attentional processing, subsequently influencing perception. Therefore, even on the attentional level, top-down expectancies can produce influences on visual processing. 6.2.2 Emotions, Motivations, and Perception A critical piece to the present argument is that emotions, often referred to as a part of system-one (Kahneman, 2011), create powerful preferences from which we see the world. Emotions are a crucial component of our capacity to navigate social systems. As mentioned above, emotion saliency provides an interesting intersection between attention and prediction. Emotions guide the way we see our worlds, interact with others, and motivate goal-directed behavior. Research highlights the impact of emotions on our lives, demonstrating that emotions influence our attitudes (DeSteno, Dasgupta, Bartlett, &amp; Cajdric, 2004; Esses, &amp; Dovidio, 2002), our decisions (Lerner &amp; Keltner, 2001; Lerner, Small, &amp; Loewenstein, 2004), and our judgements (Forgas, 2013; Clore &amp; Huntsinger, 2007). As mentioned above, recent studies have illustrated that there is a top-down contribution to object recognition stemming from the dorsal stream (Kveraga et al., 2007). One prominent theory, the Frame and Fill Theory (FnF), posits that object processing within the ventral stream relies on contributions from the dorsal stream (magnocellular connections; M-pathway), which contributes global outlines of visual input and estimates of what the object is via the OFC. The ventral visual stream (parvocellular channels; P-pathway) relies on the global template and ‘fills’ in necessary details for accurate object recognition (Bullier, 2001;Chen et al.,2007). Further, by introducing the dorsal stream as a mechanism through which emotions may bias object recognition, there may also be important implications for the biasing of attention. Research suggests that the dorsal stream governs the shifting of attention (Siegel, Donner, Oostenveld, Fries, &amp; Engel, 2008). Thus, the FnF theory provides a cohesive model of attention and object recognition for studying biases that influence early processing, specifically in relation to biases caused by emotional content. Through this lens, the relationships between emotion and object recognition can be better tested, by biasing processing toward the M-pathway and the dorsal stream object recognition (and flexible attention) may be facilitated. Findings from the lens of affective neuroscience also suggest that the primacy of emotion may guide gating mechanisms of early visual inputs as well as recruit the engagement of the OFC, altering ongoing perceptual and visual processing. (Feldman-Barrett &amp; Bar, 2009; Schmitz et al. 2009). Emotions and affective states are informationally rich, intimately interacting with cognitive processes (see Clore, Gasper, &amp; Garvin, 2001). Together, emotion and perception optimize the visual identification process. Specific evidence has implicated positive and negative affect in the encoding of visual information, suggesting that differences between positive and negative states interact with the encoding of peripheral information by altering the field of vision (Schmitz, De Rosa, Anderson, 2009; Rowe et al., 2007). Moreover, binocular rivalry studies have unlocked interesting insights into what achieves perceptual dominance. Emotional faces (Alpers &amp; Gerdes, 2007), affectively conditioned (Alpers et al., 2005), and motivationally valued (Balcetis, Dunning, &amp; Granot, 2012) stimuli all overtake the perceptual experience compared to neutral and control stimuli. Collectively, these findings hint at important relationships between emotional or motivational value and visual prioritization. If emotions interact with value representations of stimuli, expectations and predictions may be reflected in the processing of visual information. However, within the dominant framing of visual processing, connectivity between emotion “centers” in the brain (e.g., the amygdala) and top-down contributors (e.g., OFC), are not well established. 6.2.3 Zooming in on Fear Fear has emerged as an important emotion to assess different processing during visual perception. A surfeit of research has investigated the link between amygdala functioning and emotions, much of which has focused on amygdala activation in the recognition and response to potential threats through feedback from the visual cortex (Amaral et al., 1992; LeDoux, 1998; Ledoux, 2002; Pessoa et al., 2002; Adolphs &amp; Spezio, 2006). Further, studies have shown automatic detection of threatening stimuli presented outside of conscious awareness (Öhman &amp; Mineka, 2001; Öhman, 2005), enhanced attention in visual searches when in fearful states (Öhman, Flykt, &amp; Esteves, 2001), and biased perceptions when afraid (Stefanucci, Proffitt, Clore, &amp; Parekh, 2008). Such results suggest a unique role emotion, and specifically fear, may have on initial attention and perception and may influence higher-level processes like object-identification. While the role of the amygdala in the processing of emotion is well established, the purported mechanisms that affect cognitive processes in fear states are incompatible, relying on conflicting top-down and bottom-up processing models to explain a variety of phenomena (Pessoa &amp; Adolphs, 2010). Specifically, two routes have been posited for amygdala directed processing. The low route, which has the advantage of speed, suggests a direct subcortical route from the thalamus, and the higher route, from the thalamus to the visual cortex to the amygdala (Rolls, 1999). Indeed, the amygdala provides a critical source of input for affective processing. Yet, evidence of a low route existing in high order species is lacking (Shi &amp; Davis, 2001) and high route processing has yet to reconcile speed issues (Shi &amp; Davis, 2001). This inconsistency diminishes understanding of how the amygdala gets information to the level of consciousness quickly enough to incite action. It is well established that fear is associated with facilitating attention toward and perception of dangerous entities compared to other emotional states. Again, the common framework for explaining these findings are primary cortical visual pathways that send low grade visual information to the amygdala, which then identifies threatening entities. Mixed findings and the lack of a unifying theory have limited understanding of how cognition might influence ongoing processing. Moreover, these approaches rely on the primacy of affect, suggesting that cognition has little to do with initial processing of affective information, a notion that continues to be contended (Lazarus, 1982; Storbeck &amp; Clore, 2007). The emphasis on subcortical processing of information, restricts top-down contributions of processing emotional stimuli such as motivations, perceptions, and attitudes. For instance, the visual system is sensitive to and biased by endogenous (Balcetis &amp; Dunning, 2006; Tiedens, Unzueta, &amp; Young, 2007; Skelly, &amp; Decety, 2012) and exogenous (environmental cues) factors (Proffit, 2006; Cole, Balcetis, &amp; Dunning, 2013), which can change the nature of processing of visual features and perceptions of such objects. Similarly, endogenous and exogenous factors may even bias attention, like fear increasing attentional flexibility, enhancing the ability to detect peripheral objects, which is contrary to the standard assumption that fear only narrows attention (Awh &amp; Pashler, 2010). Current paradigms examining such rapid detection of objects and subsequent object recognition rely on assuming the independence of dorsal and ventral streams, with scarce focus on how they interact with one another and how emotion may modulate such interactions. 6.2.4 Other Emotions The majority of visual perception research examines how fear interacts with processing, though some research has suggested that other emotions (particularly negative valence) evidence biases. One such study investigated how faces are perceived as fundamentally different depending on context in which the face was presented (Aviezer et al., 2008). Although this is notably not a study on object recognition, it nonetheless highlights how the visual system is context dependent. This occurs with something as vital as the accurate recognition and identification of other human faces. Emotion has marked effects on a number of cognitive processes and may have dissociable effects on object recognition during instances in which emotion states are congruent with predicted sensory input compared to when they are not. 6.2.5 Motivated Perception In addition, research within the motivational domain has suggested an influence of motivational drive on perception. The implications of goals in biasing visual system processing is a particularly consequential possibility (Weber, 1996; Inbar, &amp; Pizarro, 2009). For instance, within the social framework, moral goals have been shown to influence our decisions (Haidt, 2007), our attitudes (Helzer &amp; Pizarro, 2011), our emotions (Haidt, 2003), and even the ‘popping out’ of salient words (Gantman &amp; Van Bavel, 2014). Through a motivated perceptual lens, moral goals may facilitate object recognition of salient images. Research has also shown race-based processing may also rely on low-spatial frequency cues (Correll, Hudson, Guillermo, &amp; Earls, 2017), suggesting some integration of social conceptualizations and expectancies into the ongoing visual perceptual process. The effect of motivation on perception is not limited to the moral sphere. Research has also demonstrated goal- and action- driven effects on perception. For example, externally incentivizing a specific construal of ambiguous figures drives differences in reported encounters with the target construal (Balcetis &amp; Dunning, 2006). A number of psychological studies have evidenced top-down effects informed by subjective value, race and stereotypes, and political climate. These types of social knowledge mark a high-level form of context, which has previously been implicated in object perception under isolated laboratory conditions. One study has suggested that outside of frequency, learning and biases in responses, perceptual dominance is explained by subjectively valued influences (Balcetis, Dunning, &amp; Granot, 2012). Further, research done by Levin and Banaji (2006) revealed differences in the perceived lightness of faces matched on luminance. African Americans were seen as darker skinned compared to European-descent faces, a finding that has been attributed to top-down knowledge of facial featural differences between these two races (Levin &amp; Banaji, 2006). Unfortunately, other research has corroborated findings suggesting racial stereotyping modulatory effects on perception. For instance, one study found that race of the target predicted erroneously firing a gun in a computer game, even when the incentive was structured to be accurate and shoot only targets who were holding a gun, not a tool (Correll, Park, Judd, &amp; Wittenbrink, 2002). Another set of findings has demonstrated how a self-identified political group and government stability can alter perception of skin color, favoring lighter skin representations when the target is identified as a member of your political in-group (Caruso, Mead, &amp; Balcetis, 2009) and under instances of in-group instability (Stern et al., 2016). Acquiring accurate social knowledge is important to individual functioning. However, this means that our socially determined biases may permeate into cognition and perception. These findings highlight how such knowledge constrains visual processing and biases in the direction of one’s goals or beliefs. 6.2.6 Conclusion To synthesize the dominant themes so far, the amygdala is crucial for processing of emotional stimuli and is specifically sensitive to fear. Motivational works also provides an informative perspective on how individual internal states or internally valued goals can fundamentally alter perception. Research on the mechanisms that govern how fear impacts attention and object recognition rely on conflicting cortical processing routes, routes which preclude top-down contributions, and omit the early activation on prefrontal cortical areas of the brain. Consequently, more research is needed to establish and extend mechanistic understanding of the influence of fear. Fear imparts biases onto what we see, biases which can produce and reinforce maladaptive behavioral responses (e.g., always seeing a snake instead of a sock increases stress response, a process that is ultimately corrosive for the body). The biases and predictions we bring into our phenomenological experiences constrains what we see, especially in instances in which relevant objects or scenes are obfuscated in some way. On a broader level, this literature pulls at intuition because we know the human brain to be a remarkable predictor (though we are objectively bad lay statisticians). We have adapted the ability to quickly detect threatening objects and to do so in the direction of greater false positives than negatives. Given what is known about the adaptability of the brain, its proclivity to make predictions (in terms of lessening energy costs), and the false positive bias, learned associations may be driving many of these predictions. Such predictions require descending neural processing, and like our conscious navigating of our complex, social environments, they are susceptible to errors and heuristically biased assumptions. 6.2.7 Limits to these approaches While some evidence has converged on the predictive advantage of both emotional and motivational states, there is still an ongoing debate as to where exactly these differences exist. Attention, response biases and demand characteristics are each potentially contributing to findings (for a detailed review see Firestone &amp; Scholl, 2016). Indeed, parsing through whether prior information biases early visual processing (e.g., V1) is a controversial topic. Though scientists would agree on many substantive evaluations of visual processing (e.g., parallel processing), prefrontal cortical access to V1 is one discrepancy that is challenging to resolve using reverse inference (imaging studies) and ineffectually controlled behavioral paradigms. Critics of the descending neural pathway view of object recognition suggest that evidence cited above may be primarily attributed to judgements, and that the scope of our current technologies limits the claims that can be made. For instance, imaging studies using functional magnetic resonance imaging (fMRI) often rely on patterns of activation and lack temporal resolution. Moreover, it is completely uncontroversial to not the interconnected nature of the brain. A large number of studies utilizing neurophysiological or emotion/motivational methods have emphasized specific “centers” in the brain. However, it still remains unclear how selective these neural regions are. For instance, the amygdala was once thought to selectively attend to fear/threat stimuli (Davis, 1997). Recent research has suggested this may not be the case. Instead, the amygdala seems to come online for a number of stimulus features, including emotional saliency (not just fear) and novelty (Sander, Grafman, &amp; Zalla, 2003). What about how we process faces? What makes this different than how we process objects? Additionally, dealing with assessing differences in perception versus judgement findings still marks an important and difficult task. 6.3 Cognitive and computational approaches Again, the primary aim of the present chapter is to synthesize evidence across domains that hint at the penetrability of perception. Instead of being able to draw a hard line between cognition and perception, evidence continues to mount suggesting perceptual experiences are shaped by temporal and spatial predictions (Rohenkohl, Gould, Pessoa, &amp; Nobre, 2014). The location of this influence, then, is the critical component in debate. Indeed, it would be uncontroversial to find that expectations shape judgements. Instead of focusing on the physical regions of the brain that may allow for a particular sequence of neuronal firing, cognitive approaches are rooted in information processing theory. Namely, exogenous stimuli provide particular information that is then transduced and processed through the brain, much like a metaphorical computer. These approaches to object recognition have, like with models of instance theory (Hintzman, 1986), back-propagation (Rumelhart, Hinton, &amp; Williams, 1986) and hierarchical models of associative memory (Fukushima, 1984), illustrated the benefit of representing structures in a way that makes mapping and generalizing patterns feasible. Though it is unlikely that human object recognition and computer vision converge, utilizing these models to combine them with theory of human vision may reveal interesting predictions and advances in the understanding of perception. 6.3.1 Cognitive Approaches Before diving into cognitive theories of object recognition, it is first important to situate visual perception within the cognitive domain. Research within this domain focused on characteristics and patterns of visual perception (Gibson,1950) and dominate processing styles (Navon, 1977). These research enterprises have spurred a great deal of subsequent visual research and continue to inform models today. For instance, Navon (1977) explicated how processing of global features precedes that of local features. This perspective directly maps onto other theories that consider the predictive mind and the quick processing of coarse information through M-pathway channels. Early cognitive theories of object recognition were grounded in information processing perspectives. One such perspective came from Biederman (1987) where he posited that objects are made up of reducible units called ‘geons’. These units provide that foundation for the visual system to build up and recognize more complex objects and scenes. This view, much like early semantic models (see McClelland &amp; Rumerlhart, 1981), relied on basic feature detection as the mechanism that allows for complex combinations and processing of visual information. From this perspective, object attributes like size and location do not appear to be integral to the recognition process. For example, researchers in a priming study found that object representations were not affected by removal of attributes or alteration of left-right orientation, suggesting that identification is occurring on the geon level (Biederman &amp; Cooper, 1991; Hummel &amp; Biederman, 1992). Further, controlled cognitive processes (e.g., semantic) cannot account for differences in priming effects. Instead, matched exemplars do not see a recognition advantage (Biederman &amp; Cooper, 1991). While these approaches have yielded important results, there are still limitations in the organization of these attributes and geons, perspective and field of vision variations, and the concentration on a traditional bottom-up sequence that is triggered by individual stimulus properties. Several other factors contribute to and moderate successful object recognition. Some work has attempted to extend basic units for recognition approaches by including subliminal priming. These approaches allow for the more specific understanding of how object representations reach the conscious level. For example, without inclusion of semantic effects, visual subliminal priming facilitated object recognition, even in instances in which the objects location had changed (Bar &amp; Biederman, 1998). Other work has demonstrated the effects of color on object recognition, which highlight some important features. Namely, color did not facilitate the identification and recognition of objects that were manufactured or that did not naturally occur in the presented color scheme (Humphrey, Goodale, Jakobson, &amp; Servos, 1994). These findings underscore two important concepts; first, the cascade of processing that allows for integration of more complex information (including color) over the series, and second, the importance of expectation in the identification process. Colors that did not match their typical or predicted form did not facilitate the recognition process (Humphrey et al., 1994). Evidence in this direction supports the notion that prior and expectancies are informing ongoing visual perception. Encountering a mismatch of expectation requires more effortful, controlled processing to make sense of the prediction error. 6.3.2 Computational Approaches Computational models of object recognition include a variety of methods and purposes. Many of these recent models primarily focus on error-reduction or variance mapping as a means to achieve a specific outcome, with little care for cognitive or neurophysiological theories. However, even these models still enable interesting, fruitful tests of object perception and cognitive penetration. Attneave (1954) first emphasized that the primary role of visual perception is to process relevant information. From there, he claimed, it becomes clear how repetitive and interdependent the majority of our visual experience is, and how these associations allow for perceptual processes to incorporate higher-order information, as it is purely economical to do so. In spite of this perspective, much of the literature still focused on ascending, feed-forward processing. For example, Marr (1982) developed a prominent theoretical approach to object recognition that emphasized computational methods, the complexity of constructing 3-D representations, and the bottom-up nature of processing stages. Additionally, Marr (1982) emphasized the influence of viewpoint on object perception. Indeed, it seems that viewpoint is an important factor for the object identification and not the object categorization process (for review see Milivojevic, 2012). Again, the bottom-up approach has illuminated a number of facets of the visual perceptual process that are important but is fundamentally excluding how top-down processes interact. To understand how we utilize prior knowledge, how it is integrated, descending neural pathways and the corresponding information must be included. As mentioned above, some computational models have focused less on updating or integrating a cognitive theory of visual perception, instead favoring an outcome-related, engineering approach. Machine learning and computer algorithms have given rise to research devoted to creation of technological advances in the categorization and decoding of objects. One study found that stimulus representation cortical patterns can predict the contents of sleep imagery by correlating patterns of hallucinations during sleep with specific patterns of stimuli representations while awake (Horikawa, Tamaki, Miyawaki, &amp; Kamitani, 2013). Another interesting study reconstructed faces by correlating trained faces with patterns of voxel activity (Cowen, Chun, &amp; Kuhl, 2014). However, unlike objects, faces do not contain much variance in the general structure, which makes conservation of integral information after a primary component analysis much more straightforward. These studies highlight how computer-driven methodology can produce meaningful results, but without a theoretical foundation, how these results can inform ongoing debates on human vision is often obfuscated. How are these patterns of neural activity representing different features of objects or faces? How does viewpoint and an object’s position in space and time affect perception and recognition? These questions are fundamental to the understanding of complex object recognition, and necessary to the question of integration of expectation and prediction. Other computational models have focused more specifically on the combination of theory and empirical evidence. Such models, like predictive coding models (Friston, 2010; Clark 2013), utilize Bayesian theory, and generative models to propose hierarchical perceptual processing that is integrated with descending connections from high-order cortical structures. Instead of purely processing in a feed-forward manner, the human brain is constantly maintaining a representation of the external environment that is informed by past experience, motivations and emotions, memory, and object values. Predictive coding purposes that optimization of perception and action relies on the minimization of prediction errors with recurrent loops (Friston, 2008; Friston, 2010). This idea harkens back to neurophysiological models of the dynamic, iterative brain (Cunningham &amp; Zelazo, 2007). Here, the predictive coding model informs both computational theories by introducing ways in which information is represented (e.g., prediction error) and how those signals are integrated into ongoing processes. Predictive coding reveals how the brain may be economically reducing the processing power required to manage the massive amounts of sensory information. This information is quickly assessed to allow appropriate responding to environment momenta. By understanding that the brain is relying on presuppositions about the organization and probabilities of specific pieces of information, we can begin to make sense of the disparate findings within the psychological study of vision. Whereas bottom-up, hierarchical processes explain how representation units are passed from one area to the next when encountering input, descending pathways hold information about expectations, predictions, and incorporate error (Clark, 2013). This approach parallels models of associative learning whereby bottom-up learning provides necessary cues for encoding, but retrieval is not perfect. Instead, retrieval is related to a number of environmental aspects of the encounter. Research suggests that frequency (Tulving, 1972), emotional value (Carstensen, Fung &amp; Charles, 2003; Teasdale &amp; Russell, 1983), and many other features (for another example, see Storbeck &amp; Clore, 2005) of both internal and external experience overlap and account for variance in accurate retrieval. Still evidence has not adequately delineated to what extent and at what level priors and expectations may influence perception and object recognition. Bayesian priors have oft been utilized as a means for incorporating high-level information into processing. But the question of where the priors interact still remains. Moreover, the distinction between types of top-down influences and cognitive penetration may be an important feature to explore (Hohwy, 2017). What kind of information are they holding? Hohwy (2017) describes the ways in which the minimization of prediction error coupled with Bayesian priors can lead to instances of cognitive penetrability. Indeed, there is a theoretical requirement and a practical one to the inclusion of error minimization processes in cases in which expectations are especially strong to encounter particular stimuli. Otherwise, it is difficult to reconcile how information is learned so that it may be integrated into an expectation. Further, the iterative nature of processing allows for prediction and corroborating (or not) evidence to occur time and time again. Much like associative memory models, the very repetition across contexts can allow for the decoupling of the stimulus in the original environment but holds onto the cooccurrence of an object and the surrounding environment. The goal of perception is to be accurate on a global level, meaning prediction errors that occur in response to visual illusions should be considered functional for the minimization of error over time (Lupyan, 2015; Purves et al., 2011). Although it is indeed true that low-level, sensory signals are necessary input for the process, the synthesizing of visual input is not passive. Instead, perception has been called a “constructive process of turning various forms of energy (mechanical, chemical, electromagnetic) intoinformationuseful for guiding behavior” (Lupyan, 2015). Moreover, recent research in the emotion field has suggested that language is a major contributor to the emotional cascade. This sentiment has been paralleled in other perceptional processes (Nook et al., 2017). Lupyan and Clark (2015) have proposed that language plays a vital role in visual perceptual processes as well. If language is one top-down constraint on perception, a number of mixed findings within cultural psychology can begin to merge. This represents an informative and interesting perspective for the many cognitive processes that require prediction and perception. 6.3.3 Conclusion In sum, cognitive and computational approaches have incorporated findings from neurophysiology to support understanding the process by which visual object recognition occurs. Cognitive approaches have demonstrated specific units that are represented in the cascade, uncovering the increasingly complex series. Two-dimensional surfaces, patterns, colors, edges, and many other aspects of objects all inform the visual system and aid in the overall identification process. Computational approaches allow for modelling of unobserved phenomena that has extended what was previously understood about the hierarchical nature of the brain. These models have demonstrated how prediction and prediction error can make sense of our complex perceptual system. 6.3.4 Limits to these approaches However, these approaches are also subject to limitations. Namely, cognitive studies which reduce objects to basic units suffer much of the same problem that neurophysiological findings do, they are constrained by only studying aspects in isolation. For instance, Biederman (1991) cannot account for a number of naturally occurring visual “environments”. Point of view, field of vision, emotional or motivational state, attentional biases, and more all interact with the most fundamental features of visual object recognition. Computational cognitive approaches run into slightly different issues. Most models require training from set of stimuli, which can lead to biases. Further, this research has given rise to the technologies that have creeped into nearly every facet of our daily lives. Facial recognition is used to unlock smartphones, and while this may be an efficient means for accessing a handheld device, there are still a number of implications. Importantly, the machine learning training sets may be systematically biased, leading to a biased algorithm and subsequent codification systems that rely on this type of data synthesis. 6.4 Conclusion and Implications Both the cognitive and the neuropsychological approaches to studying the visual system and object recognition have revealed unique solutions and more interesting questions. Yet, there is much still to be learned and integrated across these domains. Indeed, computational cognitive models have been exceedingly informative, particularly in regard to application in computer vision. What can be gleaned from integrating these approaches to object recognition? The models and approaches mentioned were by no means exhaustive. Instead, the purpose of the present chapter was to investigate what perceptual and object recognition evidence exists within both neurophysiological and cognitive studies that provides a foundation for conceptualizing the human brain as a predictive machine. Neurophysiology has demonstrated where information is entering, how it proceeds, and demarcated what cells and areas are doing distinct work. However, a number of these models do not incorporate theory on dynamic, integrated processing, instead focusing on isolated units. Cognitive theories diverge on this point. The center around extensive information processing formulations. Though some still consider modular accounts of cognition, the orientation toward process is valuable and something to be incorporated in future research. Informed by neurophysiological findings, we see advances in abnormal mind perception. From schizophrenia (Butler, Silverstein, &amp; Dakin, 2008) to autism spectrum disorder (Dakin &amp; Frith, 2005; Grice et al., 2001), the etiological underpinnings of nonconforming minds may be better understood by defining specializations of specific cortical areas in the brain. Studies that are concerned with representations and information processing have been particularly helpful in the technological domain as computers work like this. For example, major advances in computer vision have been spearheaded by cognitive computational models (Brown, 1985; Ullman et al., 2016). Recently, attempts at computer vision have shifted to convolution networking to better match the complexity and accuracy achieved by the human brain (Simonyan &amp; Zisserman, 2014). Again, there are clear applications of this work and the theories that emerge through trials are potentially informative for a number of other phenomena. Namely, perception is one link to the consciousness. Understanding how prediction and sensory information are integrated in our brain can provide a meaningful step toward solving problems of consciousness. The biases that predictions and expectations produce exist elsewhere (such as visual attention) and have profound effects on downstream cognitive processes like judgments and behavior. For instance, evidence clearly shows that biases influence important social customs like eye-witness reporting (MacLeod, 2002; Storbeck &amp; Clore, 2005). The consequences of these decisions are clear and understanding how emotion regulates and biases affective feelings and associations may contribute to understanding how to recalibrate social systems where a great deal of the ultimate decision depend on individual accounts. 6.5 References Adolphs, R., &amp; Spezio, M. (2006). Role of the amygdala in processing visual social stimuli.Progress in brain research,156, 363-378. Alpers, G. W., &amp; Gerdes, A. (2007). Here is looking at you: emotional faces predominate in binocular rivalry.Emotion,7(3), 495. Alpers, G. W., Ruhleder, M., Walz, N., Mühlberger, A., &amp; Pauli, P. (2005). Binocular rivalry between emotional and neutral stimuli: A validation using fear conditioning and EEG.International Journal of Psychophysiology,57(1), 25-32. Amaral,J.L.Price,A.Pitkänen,S.T.Carmichael (1992). Anatomical organization of the primate amygdaloid complex. J.P.Aggleton(Ed.), The Amygdala:Neurobiological Aspects of Emotion, Memory, and Mental Dysfunction,Wiley-Liss,New York(1992), pp.1-66 Amodio, D. M., Zinner, L. R., &amp; Harmon-Jones, E. (2007). Social psychological methods of emotion elicitation.Handbook of emotion elicitation and assessment, 91. Attneave, F. (1954). Some informational aspects of visual perception.Psychological review,61(3), 183. Aviezer, H., Hassin, R. R., Ryan, J., Grady, C., Susskind, J., Anderson, A., … &amp; Bentin, S. (2008). Angry, disgusted, or afraid? Studies on the malleability of emotion perception. Psychological science, 19(7), 724-732. Awh, E. &amp; Pashler, H. (2000). Evidence for split attentional foci. Journal of Experimental Psychology: Human Perception and Performance, 26, 834-846. Balcetis, E. &amp; Dunning, D. (2006). See what you want to see: Motivational influences on visual perception. Journal of Personality and Social Psychology, 91, 612-625. Balcetis, E., Dunning, D., &amp; Granot, Y. (2012). Subjective value determines initial dominance in binocular rivalry.Journal of Experimental Social Psychology,48(1), 122-129. Balcetis, E. (2016). Approach and avoidance as organizing structures for motivated distance perception.Emotion Review,8(2), 115-128. Balcetis, E., &amp; Dunning, D. (2010). Wishful seeing: More desired objects are seen as closer.Psychological science,21(1), 147-152. Bar, M. (2000). A Cortical Mechanism for Triggering Top-Down, Journal of Cognitive Neuroscience. 15:4, pp. 600–609. Bar, M. (2003). A cortical mechanism for triggering top-down facilitation in visual object recognition. Journal of Cognitive Neuroscience, 15, 600-609. Bar, M., Kassam, K. S., Ghuman, A. S., Boshyan, J., Schmid, A. M., Dale, A. M., Hamalainen, M. S., Marinkovic, K., Schacter, D. L., Rosen, B. R., &amp; Halgren, E. (2006). Top-down facilitation of visual recognition. Proceedings of the National Academy of Sciences, 103, 449-454. Bar, M., &amp; Biederman, I. (1998). Subliminal visual priming.Psychological Science,9(6), 464-468. Barrett, L. F., Bar, M., (2009). See it with feeling: affective predictions during object perception. Philosophical Transactions of The Royal Society. 1325–1334. Bradley, M. M., Sabatinelli, D., Lang, P. J., Fitzsimmons, J. R., King, W., &amp; Desai, P. (2003). Activation of the visual cortex in motivated attention.Behavioral neuroscience,117(2), 369. Brown, S. W. (1985). Time perception and attention: The effects of prospective versus retrospective paradigms and task demands on perceived duration.Perception &amp; Psychophysics,38(2), 115-124. Biederman, I. (1987). Recognition-by-components: a theory of human image understanding.Psychological review,94(2), 115. Biederman, I., &amp; Cooper, E. E. (1991). Priming contour-deleted images: Evidence for intermediate representations in visual object recognition.Cognitive psychology,23(3), 393-419. Britton, J. C., Taylor, S. F., Sudheimer, K. D., &amp; Liberzon, I. (2006). Facial expressions and complex IAPS pictures: Common and differential networks. NeuroImage, 31(2), 906–919. https://doi.org/10.1016/j.neuroimage.2005.12.050 Bullier, J. (2001). Integrated model of visual processing. Brain Research. Brain Research Reviews, 36(2/3), 96–107. Burr, D. C., Morrone, M. C., &amp; Ross, J. (1994). Selective suppression of the magnocellular visual pathway during saccadic eye movements.Nature,371(6497), 511. Butler, P. D., Silverstein, S. M., &amp; Dakin, S. C. (2008). Visual perception and its impairment in schizophrenia.Biological psychiatry,64(1), 40-47. Campbell, J. I., &amp; Thompson, V. A. (2012). MorePower 6.0 for ANOVA with relational confidence intervals and Bayesian analysis.Behavior research methods,44(4), 1255-1265. Carstensen, L. L., Fung, H. H., &amp; Charles, S. T. (2003). Socioemotional selectivity theory and the regulation of emotion in the second half of life.Motivation and emotion,27(2), 103-123. Caruso, E. M., Mead, N. L., &amp; Balcetis, E. (2009). Political partisanship influences perception of biracial candidates’ skin tone.Proceedings of the National Academy of Sciences,106(48), 20168-20173. Chen, C. M., Lakatos, P. S., Shah, A. S., Mehta, A. D., Givre, S. J., Javitt, D. C., &amp; Clark, A. (2013). Whatever next? Predictive brains, situated agents, and the future of cognitive science. Behavioral and brain sciences, 36(3), 181-204. Clore, G. L., &amp; Huntsinger, J. R. (2007). How emotions inform judgment and regulate thought. Trends in Cognitive Sciences, 11(9), 393–399. https://doi.org/10.1016/j.tics.2007.08.00 Clore, G. L., Gasper, K., &amp; Garvin, E. (2001). Affect as information.Handbook of affect and social cognition, 121-144. Cole, S., Balcetis, E., &amp; Dunning, D. (2013). Affective signals of threat increase perceived proximity.Psychological science,24(1), 34-40. Correll, J., Park, B., Judd, C. M., &amp; Wittenbrink, B. (2002). The police officer’s dilemma: Using ethnicity to disambiguate potentially threatening individuals.Journal of personality and social psychology,83(6), 1314. Correll, J., Hudson, S. M., Guillermo, S., &amp; Earls, H. A. (2017). Of kith and kin: Perceptual enrichment, expectancy, and reciprocity in face perception.Personality and Social Psychology Review,21(4), 336-360. Cowen, A. S., Chun, M. M., &amp; Kuhl, B. A. (2014). Neural portraits of perception: reconstructing face images from evoked brain activity. Neuroimage, 94, 12–22. Cunningham, W. A., &amp; Zelazo, P. D. (2007). Attitudes and evaluations: A social cognitive neuroscience perspective.Trends in cognitive sciences,11(3), 97-104. Dakin, S., &amp; Frith, U. (2005). Vagaries of visual perception in autism.Neuron,48(3), 497-507. Davis, M. (1997). Neurobiology of fear responses: the role of the amygdala.The Journal of neuropsychiatry and clinical neurosciences. Descartes, R. (1984).The philosophical writings of Descartes: Volume 3, the correspondence(Vol. 3). Cambridge University Press. DeSteno, D., Dasgupta, N., Bartlett, M. Y., &amp; Cajdric, A. (2004). Prejudice from thin air: The effect of emotion on automatic intergroup attitudes. Psychological Science, 15(5), 319-324. DiCarlo, J. J., Zoccolan, D., &amp; Rust, N. C. (2012). How does the brain solve visual object recognition?.Neuron,73(3), 415-434. Easterbrook, J. A. (1959). The effect of emotion on cue utilization and the organization of behavior. Psychological Review, 66, 183-201. Esses, V. M., &amp; Dovidio, J. F. (2002). The role of emotions in determining willingness to engage in intergroup contact. Personality and Social Psychology Bulletin, 28(9), 1202-1214. Felleman, D. J., &amp; Van, D. E. (1991). Distributed hierarchical processing in the primate cerebral cortex.Cerebral cortex (New York, NY: 1991),1(1), 1-47. Fenske, M. J., Aminoff, E., Gronau, N., &amp; Bar, M. (2006). Top-down facilitation of visual object recognition: object-based and context-based contributions.Progress in brain research,155, 3-21 Firestone, C., &amp; Scholl, B. J. (2016). Cognition does not affect perception: Evaluating the evidence for&quot; top-down&quot; effects.Behavioral and brain sciences,39. Fitzpatrick D, Itoh K, Diamond IT. The laminar organization of the lateral geniculate body and the striate cortex in the squirrel monkey (Saimiri sciureus). J Neurosci. 1983;3:673–702. PubMed PMID: 6187901. Forgas, J. P. (2013). Don’t worry, be sad! On the cognitive, motivational, and interpersonal benefits of negative mood.Current Directions in Psychological Science,22(3), 225-232. Friston, K. (2008). Hierarchical models in the brain. PLoS computational biology, 4(11), e1000211. Friston, K. (2010). The free-energy principle: a unified brain theory?. Nature Reviews Neuroscience, 11(2), 127. Friston and Clark Gable, P. A. &amp; Harmon-Jones, E. (2010). The blues broaden, but the nasty narrows: Attentional consequences of negative affects low and high in motivational intensity. Psychological Science, 21, 211-215. Gantman, A. P., &amp; Van Bavel, J. J. (2014). The moral pop-out effect: Enhanced perceptual awareness of morally relevant stimuli.Cognition,132(1), 22-29. Gibson, J. J. (1950). The perception of the visual world. Goodale, M. A., &amp; Milner, A. D. (1992). Separate visual pathways for perception and action.Trends in neurosciences,15(1), 20-25. Goodale, M. A., &amp; Westwood, D. A. (2004). An evolving view of duplex vision: separate but interacting cortical pathways for perception and action.Current opinion in neurobiology,14(2), 203-211. Grice, S. J., Spratling, M. W., Karmiloff-Smith, A., Halit, H., Csibra, G., de Haan, M., &amp; Johnson, M. H. (2001). Disordered visual processing and oscillatory brain activity in autism and Williams syndrome. Neuroreport, 12(12), 2697-2700. Haidt, J. (2003). The moral emotions.Handbook of affective sciences,11(2003), 852-870. Haidt, J. (2007). The new synthesis in moral psychology.science,316(5827), 998-1002. Harmon-Jones, E., &amp; Gable, P. A. (2008). Incorporating motivational intensity and direction into the study of emotions: Implications for brain mechanisms of emotion and cognition-emotion interactions.Netherlands Journal of Psychology,64(4), 132-142. Harmon-Jones, E., Gable, P. A., &amp; Price, T. F. (2013). Does Negative Affect Always Narrow and Positive Affect Always Broaden the Mind? Considering the Influence of Motivational Intensity on Cognitive Scope. Current Directions in Psychological Science, 22(4), 301–307. https://doi.org/10.1177/0963721413481353 Harmon-Jones, E., &amp; Gable, P. A. (2017). On the role of asymmetric frontal cortical activity in approach and withdrawal motivation: An updated review of the evidence. Psychophysiology, (May 2016). https://doi.org/10.1111/psyp.12879 Haxby, J. V., Hoffman, E. A., &amp; Gobbini, M. I. (2002). Human neural systems for face recognition and social communication. Biological Psychiatry, 51(1), 59–67. Helfrich, R. F., Huang, M., Wilson, G., &amp; Knight, R. T. (2017). Prefrontal cortex modulates posterior alpha oscillations during top-down guided visual perception.Proceedings of the National Academy of Sciences,114(35), 9457-9462. Helzer, E. G., &amp; Pizarro, D. A. (2011). Dirty liberals! Reminders of physical cleanliness influence moral and political attitudes.Psychological science,22(4), 517-522. Hintzman, D. (1986). Schema abstraction in a multiple-trace memory model. Psychological Review, 93, 411–428. Fukushima, K. (1984). A hierarchical neural network model for associative memory.Biological cybernetics,50(2), 105-113. Hummel, J. E., &amp; Biederman, I. (1992). Dynamic binding in a neural network for shape recognition.Psychological review,99(3), 480. Horikawa, T., Tamaki, M., Miyawaki, Y., &amp; Kamitani, Y. (2013). Neural decoding of visual imagery during sleep. Science, 340, 639–642. Hohwy, J. (2017). Priors in perception: Top-down modulation, Bayesian perceptual learning rate, and prediction error minimization.Consciousness and cognition,47, 75-85. Humphrey, G. K., Goodale, M. A., Jakobson, L. S., &amp; Servos, P. (1994). The role of surface information in object recognition: Studies of a visual form agnosic and normal subjects.Perception,23(12), 1457-1481. Inbar, Y., Pizarro, D. A., Knobe, J., &amp; Bloom, P. (2009). Disgust sensitivity predicts intuitive disapproval of gays.Emotion,9(3), 435. Johnson, M. H. (2001). Disordered visual processing and oscillatory brain activity in autism and Williams syndrome.Neuroreport,12(12), 2697-2700. Kahneman, D. (2011).Thinking, fast and slow. Macmillan. Kastner, S., Ungerleider, L. G. (2000). Mechanisms of visual attention in the human cortex.Annual review of neuroscience,23(1), 315-341. Kringelbach, M. L., &amp; Rolls, E. T. (2004). The functional neuroanatomy of the human orbitofrontal cortex: evidence from neuroimaging and neuropsychology.Progress in neurobiology,72(5), 341-372. Kringelbach, M. L. (2005). The human orbitofrontal cortex: linking reward to hedonic experience.Nature Reviews Neuroscience,6(9), 691-702. Kveraga, K., Boshyan, J., &amp; Bar, M. (2007). Magnocellular projections as the trigger of top-down facilitation in recognition. Journal of Neuroscience, 27, 13232-13240 Lamme, V. A. &amp; Roelfsema, P. R. (2000). The distinct modes of vision offered by feedforward and recurrent processing. Trends Neurosci. 23, 571–579. Lang, P., Bradley, M., &amp; Cuthbert, B. (1999). International Affective Picture System (IAPS): Technical manual and affective ratings. Gainesville, FL: The Center for Research in Psychophysiology, University of Florida. Lang, P., &amp; Bradley, M. M. (2007). The International Affective Picture System (IAPS) in the study of emotion and attention.Handbook of emotion elicitation and assessment,29. Lazarus, R. S. (1982). Thoughts on the relations between emotion and cognition.American psychologist,37(9), 1019. LeDoux, J. (1998). Fear and the brain: where have we been, and where are we going?.Biological psychiatry,44(12), 1229-1238. LeDoux, S. F. (2002). Defining natural sciences.Behaviorology Today,5(1), 34-36. Lerner, J. S., &amp; Keltner, D. (2001). Fear, anger, and risk.Journal of personality and social psychology,81(1), 146. Lerner, J. S., Small, D. A., &amp; Loewenstein, G. (2004). Heart strings and purse strings: Carryover effects of emotions on economic decisions.Psychological science,15(5), 337-341. Lupyan, G. (2015). Cognitive penetrability of perception in the age of prediction: Predictive systems are penetrable systems.Review of philosophy and psychology,6(4), 547-569. Lupyan, G., &amp; Clark, A. (2015). Words and the world: Predictive coding and the language-perception-cognition interface.Current Directions in Psychological Science,24(4), 279-284. MacLeod MD. (2002) Retrieval-induced forgetting in eyewitness memory: forgetting as a consequence of remembering.Appl. Cognit. Psychol. 16:135–149. Marr, D. (1982).Vision: A Computational Investigation Into. WH Freeman. Maunsell, J. H., Nealey, T. A., &amp; DePriest, D. D. (1990). Magnocellular and parvocellular contributions to responses in the middle temporal visual area (MT) of the macaque monkey.Journal of Neuroscience,10(10), 3323-3334. McClelland, J. L., &amp; Rumelhart, D. E. (1981). An interactive activation model of context effects in letter perception: I. An account of basic findings.Psychological review,88(5), 375. Merigan, W. H., &amp; Maunsell, J. H. (1993). How parallel are the primate visual pathways?.Annual review of neuroscience,16(1), 369-402. Milivojevic, B. (2012). Object Recognition Can Be Viewpoint Dependent or Invariant–It’s Just a Matter of Time and Task. Frontiers in computational neuroscience, 6, 27. Milner, A. D., &amp; Goodale, M. A. (1995). The visual brain in action. Oxford: Oxford University Press. Milner, A. &amp; Goodale, M. (2008). Two visual systems re-viewed. Neuropsychologia, 46, 774-785. Navon, D. (1977). Forest before trees: The precedence of global features in visual perception.Cognitive psychology,9(3), 353-383. Nook, E. C., Sasse, S. F., Lambert, H. K., McLaughlin, K. A., &amp; Somerville, L. H. (2017). Increasing verbal knowledge mediates development of multidimensional emotion representations.Nature Human Behaviour,1(12), 881. O’Callaghan, C., Kveraga, K., Shine, J. M., Adams, R. B., &amp; Bar, M. (2016). Convergent evidence for top-down effects from the “predictive brain”.Behavioral and Brain Sciences,39. Öhman, A., &amp; Mineka, S. (2001). Fears, phobias, and preparedness: Toward an evolved module of fear and fear learning. Psychological Review, 108, 483-522. Öhman, A., Flykt, A., &amp; Esteves, F. (2001). Emotion drives attention- Snakes in the grass. Journal of Experiemntal Psychology: General, 130(3), 466–478. https://doi.org/10.1037/AXJ96-3445.130.3.466 Öhman, A. (2005). The role of the amygdala in human fear: automatic detection of threat.Psychoneuroendocrinology,30(10), 953-958. Perrett, D. I., &amp; Oram, M. W. (1993). Neurophysiology of shape processing.Image and Vision Computing,11(6), 317-333. Pessoa, L. &amp; Adolphs, R. (2010). Emotion processing and the amygdala: From a ‘low road’ to ‘many roads’ of evaluating biological significance. Nature Neuroscience Reviews, 11, 77 -782. Pessoa, L., McKenna, M., Gutierrez, E., &amp; Ungerleider, L. G. (2002). Neural processing of emotional faces requires attention.Proceedings of the National Academy of Sciences,99(17), 11458-11463. Phelps, E. A., Ling, S., &amp; Carrasco, M. (2006). Emotion facilitates perception and potentiates the perceptual benefits of attention. Psychological Science, 17, 292-299. Polyak S. Chicago: University of Chicago Press;The vertebrate visual system.1957. Proffitt, D. R. (2006). Embodied perception and the economy of action.Perspectives on psychological science,1(2), 110-122. Purves, D., Wojtach, W.T., &amp; Lotto, R.B.. (2011) Understanding vision in wholly empirical terms.Proceedings of the National Academy of Sciences of the United States of America108(Suppl 3): 15588–15595. Pylyshyn, 1999 Riesenhuber, M., &amp; Poggio, T. (1999). Hierarchical models of object recognition in cortex.Nature neuroscience,2(11), 1019. Rohenkohl, G., Gould, I. C., Pessoa, J., &amp; Nobre, A. C. (2014). Combining spatial and temporal expectations to improve visual perception.Journal of vision,14(4), 8-8. Rolls, E.T. (1999). The Brain and Emotion. Oxford, UK: Oxford University Press. Sabatinelli, D., Fortune, E. E., Li, Q., Siddiqui, A., Krafft, C., Oliver, W. T., … &amp; Jeffries, J. (2011). Emotional perception: meta-analyses of face and natural scene processing. Neuroimage, 54(3), 2524-2533. Sander, D., Grafman, J., &amp; Zalla, T. (2003). The human amygdala: an evolved system for relevance detection.Reviews in the Neurosciences,14(4), 303-316. Schmitz, T. W., De Rosa, E., &amp; Anderson, A. K. (2009). Opposing influences of affective state valence on visual cortical encoding.Journal of Neuroscience,29(22), 7199-7207. Schmolesky, M. (1995). The Primary Visual Cortex. Webvision: The Organization of the Retina and Visual System, 1–38. https://doi.org/NBK11524 Schroeder, C. E. (2007). Functional anatomy and interaction of fast and slow visual pathways in macaque monkeys. Cerebral Cortex, 17, 1561-1569. Shi, C. &amp; Davis, M. (2001). Visual pathways involved in fear conditioning measured with fear potentiated startle: behavioral and anatomic studies. Journal of Neuroscience, 21, 9844-55. Shipp S, Zeki S. The organization of connections between areas V5 and V1 in macaque monkey visual cortex. Eur J Neurosci. 1989;1:309–332. PubMed PMID: 12106142. Skelly, L. R., &amp; Decety, J. (2012). Passive and motivated perception of emotional faces: Qualitative and quantitative changes in the face processing network. PLoS One, 7(6), e40371. Siegel, M., Donner, T. H., Oostenveld, R., Fries, P., &amp; Engel, A. K. (2008). Neuronal synchronization along the dorsal visual pathway reflects the focus of spatial attention. Neuron, 60, 709-719. Simonyan &amp; Zisserman, 2014 Somerville, L. H., Wagner, D. D., Wig, G. S., Moran, J. M., Whalen, P. J., &amp; Kelley, W. M. (2013). Interactions between transient and sustained neural signals support the generation and regulation of anxious emotion. Cerebral Cortex, 23(1), 49–60. https://doi.org/10.1093/cercor/bhr373 Stefanucci, J. K., Proffitt, D. R., Clore, G. L., &amp; Parekh, N. (2008). Skating down a steeper slope: Fear influences the perception of geographical slant.Perception,37(2), 321-323. Stern, C., Balcetis, E., Cole, S., West, T. V., &amp; Caruso, E. M. (2016). Government instability shifts skin tone representations of and intentions to vote for political candidates.Journal of personality and social psychology,110(1), 76. Storbeck J, Clore GL. (2005). With sadness comes accuracy, with happiness, false memory: mood and the false memory effect.Psychol. Sci. 16:785–791. Storbeck, J. &amp; Clore, G. L. (2007). On the interdependence of cognition and emotion. Cognition &amp; Emotion, 21, 1212-1237 Storbeck, J. (2012). Performance Costs When Emotion Tunes Inappropriate Cognitive Abilities : Implications for Mental Resources and Behavior, 141(3), 411–416. Storbeck, J., Dayboch, J., &amp; Wylie, J. (2016). Fear broadens attention: Fear and happiness motivate attentional flexibility impairing split attentional foci. Emotion. Submitted. Tapia, E., &amp; Breitmeyer, B. G. (2011). Visual consciousness revisited: magnocellular and parvocellular contributions to conscious and nonconscious vision.Psychological Science,22(7), 934-942. Teasdale, J. D., &amp; Russell, M. L. (1983). Differential effects of induced mood on the recall of positive, negative and neutral words.British Journal of Clinical Psychology,22(3), 163-171. Tiedens, L. Z., Unzueta, M. M., &amp; Young, M. J. (2007). An unconscious desire for hierarchy? The motivated perception of dominance complementarity in task partners. Journal of personality and social psychology, 93(3), 402. Tulving, E. (1972). Episodic and semantic memory.Organization of memory,1, 381-403. Ullman, S., Assif, L., Fetaya, E., &amp; Harari, D. (2016). Atoms of recognition in human and computer vision. Proceedings of the National Academy of Sciences, 113(10), 2744-2749. Ungerleider, L. G., &amp; Haxby, J. V. (1994). ‘What’and ‘where’in the human brain.Current opinion in neurobiology,4(2), 157-165. Van Essen, D. C., Anderson, C. H., &amp; Felleman, D. J. (1992). Information processing in the primate visual system: an integrated systems perspective.Science,255(5043), 419-423. Weber, J. (1996). Influences upon managerial moral decision making: Nature of the harm and magnitude of consequences.Human Relations,49(1), 1-22. Whalen, P. J., Rauch, S. L., Etcoff, N. L., McInerney, S. C., Lee, M. B., &amp; Jenike, M. A. (1998). Masked presentations of emotional facial expressions modulate amygdala activity without explicit knowledge. Journal of Neuroscience, 18(1), 411–418. https://doi.org/9412517 Wiens, S., Peira, N., Golkar, A., &amp; Öhman, A. (2008). Recognizing masked threat: Fear betrays, but disgust you can trust.Emotion,8(6), 810. Wyatte, D., Curran, T., &amp; O’Reilly, R. (2012). The limits of feedforward vision: recurrent processing promotes robust object recognition when objects are degraded.Journal of Cognitive Neuroscience,24(11), 2248-2261. Zelazo, P. D., &amp; Cunningham, W. A. (2007). Executive function: Mechanisms underlying emotion regulation. "],
["brain-training-and-cognition.html", "Chapter 7 Brain Training and Cognition 7.1 Abstract 7.2 Introduction 7.3 Chess and Music 7.4 Cognitive Training 7.5 Cognitive Training Programs: Do They Work? 7.6 Fitness/Physical activities 7.7 Combining Cognitive and Aerobic Training 7.8 Limitations and Future Work 7.9 Conclusion 7.10 References", " Chapter 7 Brain Training and Cognition Alina Korovatskaya, The Graduate Center CUNY, Spring 2018 7.1 Abstract “Brain training” is something most people have heard of, and there are many techniques and methods that claim to improve one’s cognition and enhance one’s brain. These techniques vary from learning how to play chess or music to various cognitive training programs to ordinary exercise activities. But do these techniques work? Can we really do something that will make us smarter or better at tasks? This topic and these techniques are quiet controversial because there are studies that provide evidence for a positive outcome of these training techniques, but their evidence lack in generalization and long-term effects. This paper is a review of various research articles that talk about different brain training techniques, including playing chess or musical instruments, different cognitive trainings, such as brain training games, bilingual brain training, and working memory training, and fitness training and exercises, and provided evidence for these techniques, if any. Limitations of these techniques are discussed as well. 7.2 Introduction “Brain training” is something most people have heard of. It promises that with certain techniques and training people will improve their cognitive abilities, become smarter and better at various tasks by improving working memory, attention, executive functions, reasoning skills and speed information processing (van Heugten at al., 2016). And the amount of these techniques and programs is truly endless. There is a lot to choose from, from mobile apps to cognition enhancing drugs, and each of these programs or techniques promises astonishing results. Seems great, but there’s yet another side to the story because the topic of brain training is controversial. People “often rely on claims that are scientifically unsubstantiated” (Rabipour and Raz, 2012). There are studies that provide evidence for a positive outcome of various training techniques, but their evidence lack in generalization and long-term effects. That is, people who engaged in these training programs showed improvement in trained tasks, but there were no evidence of improving in untrained tasks neither in the same cognitive domain nor in different cognitive domain (Wilson, 1997). There are many techniques and methods offered that claim to improve one’s cognition and enhance one’s brain. These techniques vary from special cognition enhancing drugs to learning how to play chess or music to various cognitive training programs, including brain training games, bilingual training, and working memory training, to ordinary exercise activities. Many people try them, and it might seem like many of these techniques indeed work, or, at least, that is what advertised by developers of those techniques and programs. But do they really work? To what degree? Which techniques and programs are better? Can we really do something that will make us smarter or better at a wide range of cognitive tasks and delay decline in cognitive abilities? Is there enough scientific evidence that can show, “Yes, this program will improve your brain”? How about long-term effect? Or are these training programs can only enhance one’s brains for a certain amount of time? This paper will examine various research studies that were focused on different brain training techniques that claim to improve cognition. These techniques include ability to play chess and music, playing brain training games, improving working memory, speaking two languages, and fitness training. Section 2 will analyze whether playing chess or a musical instrument makes you better at other tasks. Section 3 will discuss different cognitive trainings, including brain training games, bilingual brain training, and working memory training as ways to enhance cognitive functions. Section 4 will look at various examples of cognitive improvement with fitness training and exercises in elderly adults. Section 5 will talk about some limitation of previous research and possible future implications for brain training research. Section 6 would be a brief summary of reviewed studies and a conclusion. 7.3 Chess and Music 7.3.1 Near and Far Transfer It is often claimed that chess players and musicians are smarter and better at various task than those who doesn’t know how to play chess or a music instrument. Giovanni Sala and Fernand Gobet in “Does far transfer exits? Negative evidence from chess, music, and working memory training” talked about evidence, or rather lack of evidence that could support the idea of far transfer in chess masters and musicians. First of all, what is far transfer? What kind of transfers exists? The answer is there are two types of transfer of learning: near transfer and far transfer. Near transfer is “the generalization of a set of skills across two (or more) domains tightly related to each other” (Sala and Gobet, 2017). For example, if you know how to drive an SUV, you will be able to drive a sedan. Far transfer, on the other hand, occurs “when a set of skills generalizes across two (or more) domains that are only loosely related to each other” (Sala and Gobet, 2017). An example of a far transfer would be when studying mathematics helps you learn a foreign language. It is known that near transfer takes place often, while far transfer is not as common (Thorndike and Woodworth, 1901). This theory is supported by the majority of studies, which suggest that cognitive improvement do not transfer to new tasks or transfer only to tasks with the same processing requirements as the trained tasks (Ball et al., 2002; Mahncke et al., 2006; Basak et al., 2008). Nevertheless, some researchers still believe in far transfer from chess and music to other domains because it is assumed that these activities (chess and music) require domain-general cognitive abilities that can be trained by practice in a specific domain. Sala and Gobet (2017) tested this hypothesis by conducting multiple meta-analyses. 7.3.2 A Meta-Analysis Study People who are engaged in intellectual activities show overall better cognitive abilities when compared with general population. For example, more skilled chess players show higher level of cognitive abilities (Sala and Gobet, 2017). Burgoyne et al. (2016) also reported a significant correlation between chess skill and four broad measures of cognitive ability: fluid intelligence, processing speed, short-term memory and working memory, and comprehension knowledge. To be more specific, fluid intelligence is the ability to solve new problems; processing speed is the efficiency of basic mental operations; short-term and working memory is the ability to retain, change, and recall information over a short period of time and comprehension knowledge is the ability to use knowledge gained through experience. Schellenberg (2006) and Lee, Lu, and Ko (2007) also reported positive correlations between music skill, working memory, and IQ. However, positive correlation between chess or music and cognitive ability doesn’t tell anything about far transfer (Sala and Gobet, 2017). But researchers believe in presence of far transfer from chess or music to other domains because these activities enhance general intelligence and have a positive effect on cognitive abilities in other domains (Schellenberg, 2006). Same goes for the theory about far transfer and action-video-game training. However, this theory that action-video-game training can enhance one’s performance in a broad set of visuo-attentional and cognitive tasks was challenged by Oei and Patterson (2015). They used four different action games and showed that participants’ improvements were limited only to those cognitive abilities that were targeted in the game played. Sala and Gobet (2017) tested this hypothesis by running three meta-analyses, focusing on children and young adolescence. The results showed small overall effect sizes in all three meta-analyses, which is not that promising. Simons et al. (2016) also observed no evidence of far transfer benefits from brain-training programs. Although some working memory training programs claimed to improve participants’ performance on various cognitive tasks, studies with a strong experimental design showed no far-transfer effects. 7.3.3 Patterns in Findings There are a few patterns that can be seen in various studies of effects of chess and music skills on cognitive abilities and far transfer. First of all, people who are engaged in cognitive activities like chess or music have better overall cognitive ability than others. Second, training chess, music, or working memory skills doesn’t enhance one’s skills beyond those that they train. Third, there is no far transfer effect to other domains when training music or chess skills (Sala and Gobet, 2017). Due to a lack of good evidence, it can be concluded that playing chess or music doesn’t make people smarter. Rather, smarter people are more likely to engage and excel in these activities because, no doubt, cognitive ability correlates with domain-specific skills. 7.4 Cognitive Training With age, people’s cognitive abilities tend to decline. Our memory, attention, ability to maintain and manipulate information gets worse. There are many different kinds of interventions that have been proposed to help maintain our cognitive abilities. Some recommend rudimentary pencil-and-paper type tasks (crosswords), more advanced computer/video-game type programs (Lumosity), or nutritional supplements (caffeine). Others suggest various drugs (Parsons et al., 2014). All of these interventions suppose to suppress and slow down this decline in cognitive abilities and delay such diseases as dementia or Alzheimer’s disease. But drugs do little to none to maintain cognitive and functional abilities or to slow the progress of the diseases (Kueider et al., 2014). On the other hand, mental exercises seem to do a better job when it comes to improving cognitive abilities. Previous study showed that multiple cognitive training programs could improve cognitive functions like memory (Smith et al., 2009), processing speed (Ball et al., 2007), executive function (Uchida and Kawashima, 2008), and attention (Mozolic et al., 2011) in healthy older adults. Cognitive training is based on the idea that out brain can change for the better, even in old age. In the same way that physical training improves physical abilities, cognitive training improves cognitive abilities. 7.5 Cognitive Training Programs: Do They Work? 7.5.1 Brain Training Games In “Brain training game improves executive functions and processing speed in the elderly: A randomized controlled trial,” Nouchi et al. (2012) examined video game training as one of the types of cognitive training in older adults because some of the previous studies showed that playing video games can lead to improvement in some cognitive functions in older adults. For their study they recruited 32 elderly healthy adults who were divided into two groups: one group played Brain Age game, and another group played Tetris. Brain Age game was published by Nintendo in 2005 and was one of the most popular brain training games. The game was developed based on the previous cognitive training for older adults. Participants in both Brain Age and Tetris groups played for about 15 minutes per day, at least 5 days per week, for 4 weeks (prior to the experiment participants were non-gamers and reported playing video games for less than one hour a week for the past two years). Cognitive functions that were measured were divided into four categories: global cognitive status, executive function, attention, and processing speed. Measures of cognitive functions were conducted before and after training. After the experiment, their result showed that playing Brain Age in short term training could help improve such cognitive functions as executive functions and processing functions in older adults. However, there was no difference between playing Brain Age or Tetris when they measured global cognitive statuses. Also, neither game improved attention. These finding were consistent with some of the previous evidence that playing certain games can help improve cognitive functions in older adults (Basak et al., 2008). But they didn’t study any long-term effects, which is an important part when it comes to determining if a particular game can indeed be used to improve cognitive abilities in older people. And, as authors indicated themselves, a study with a larger number of participants would be necessary to confirm the present results. 7.5.2 Bilingual Brain Training In “Bilingual brain training: A neurobiological framework of how bilingual experience improves executive function,” Stocco et al., (2014) made an interesting point that bilingualism helps “train the brain.” They stated that individuals who are bilingual often outperform monolinguals on tests of executive functions. Executive functions are defined as activities that can be dissociated from one another to a certain extent, like inhibition, shifting, and updating. Bilingual advantage on such tests has been well documented (Bialystok, 2009). This is due to the fact that demands for language selection and switching in bilinguals directly overlaps with the inhibition and shifting components of executive function. Miyake et al. (2000) stated that bilinguals have advantage in executive function because it reflects a superior capacity for inhibitory control, or “the capacity of controlling and halting dominant and automatic responses that are strongly associated to environmental stimuli but are not appropriate for the current task” (Stocco et al., 2014). Bilingual have to deal with interfering responses from the unwanted language (responses that are normally activated in parallel with those of the target language) (Bialystok, 2001). However, more recent studies suggest that improved inhibitory control may not be the best characterizations of bilinguals’ cognitive advantages (Festman et al., 2010). Yet, Miyake et al. (2000) had another explanation for bilinguals’ advantage in executive function. They suggested that it can also be explained by the fact that bilinguals are better at the shifting component of complex tasks, or “the capacity of flexibly switching back and forth between multiple tasks, mental operations, or response sets” (Stocco et al., 2014). This assumption is based on the fact that, in order to be fluent bilinguals, people need to switch effectively between relative grammatical rules and phonological outputs for each of the languages they speak. Therefore bilinguals have a lot of practice with shifting and gain more benefits from it. People who can easily switch between two languages are proven to perform better on all executive function tasks than people who lack the ability to switch between languages effectively (Festman et al., 2010). That can be a proof that the capacity to switch between languages is closely related to having better executive functions. It is evident that bilinguals have advantages over monolinguals. Bilingual practice can be adopted to improve cognitive performance and rehabilitate cognitive decline because extensive training in task switching results in general cognitive benefits. 7.5.3 Working Memory Training Working memory is a capacity limited system that serves as the workplace of our mind and its size can determine or ability to perform various cognitive tasks (Kane et al., 2004). Although it was assumed that working memory capacity has a limit, but more recent studies suggested that working memory capacity can be expanded with targeted training (Klingberg et al., 2005). In “Does working memory training work? The promise and challenges of enhancing cognition by training working memory,” Morrison and Chein (2010) discussed working memory training as a tool for broad cognitive benefits. They identified two approaches to working memory training: strategy training and core training. “Strategy training paradigms involve teaching of effective approaches to encoding, maintenance, and/or retrieval from working memory” (Morrison and Chein, 2010). The main goal of the majority of strategy training studies is to increase performance in tasks that require retention of information over a delay. In strategy training studies, participants are introduced to specific task strategies and then provided with practice sessions encouraging the strategy of interest. Morrison and Chein (2010) found out that training-related increases in working memory capacity have been successfully demonstrated across a wide range of subject populations, but different training techniques seem to produce different impact upon the broader range of cognitive abilities. They also mentioned that the amount of information remembered on measures of working memory can be increased by teaching strategies like rehearsing out loud, telling a story with a stimuli, using imagery to make stimuli salient. “Core training studies typically involve repetition of demanding working memory tasks that are designed to target domain-general working memory mechanisms” (Morrison and Chein, 2010). Thus tasks for core training programs usually involve sequential processing and frequent memory updating and are designed to decrease the use of domain-specific strategies, limit automization, include stimuli that span multiple modalities, enforce fast working memory encoding and retrieval, and demand high cognitive workload. Morrison and Chein (2010) identified that it produced more far-reaching transfer effects, probably because they targeted domain-general mechanisms of working memory. 7.6 Fitness/Physical activities Aside from many negative reviews on brain training techniques, there are some studies that suggest that people can improve their cognitive functions with some physical activities and training. Unfortunately, with age, older adults show decline in cognitive abilities (Salthouse, 2004). Research shows a decline in abilities of working memory, long-term memory, dual-tasking, task switching, and processing speed (Park et al., 2002; Verhaeghen and Cerella, 2002; Salthouse, 2004). Research claims that “aerobic fitness training enhances the cognitive vitality of healthy but sedentary adults” (Colcombe and Kramer, 2003). Studies of the relationship between cognition and physical training go back several decades; one of the first researches in this area was Spirduso and her colleagues. It was observed that the performance of the older athletes was better than the performance of the older sedentary adults, but for younger sedentary adults the benefit of fitness was not so significant (Spirduso and Clifford, 1978). Aerobic physical activity interventions (like swimming or power-walking) have been associated with improved attention (Colcombe et al., 2004) and executive control processes, like switching (Colcombe and Kramer, 2003). 7.6.1 A Meta-Analysis Study In “Fitness effect on the cognitive function of older adults: A Meta-analysis study,” Stanley Colcombe and Arthur F. Kramer (2003) talked about several studies that reported a positive effect on cognitive vitality of older adults who were engaged in physical activities. They examined four theoretical hypotheses (speed hypothesis, visuospatial hypothesis, controlled-procesing hypothesis, and executive-control hypothesis) that could affect the extent to which enhancements in aerobic fitness results in improvement in cognition (Rosenthal, 1998). Colcombe and Kramer were interested in the effect of exercise on cognitive functions identified by these four theoretical positions: speed, visuospatial, controlled processing, and executive control. They divided participants by age in three groups: young-old (56-65), middle-old (66-70), and old-old (71+). The training interventions included a large variety of activities from walking and dancing to circuit training, but were divided into two groups: aerobics and combination. Aerobics included exercises that emphasized cardiovascular fitness in isolation, and combination included exercises that combined cardiovascular fitness and strength training. Duration of the sessions also varied: short (15-30 min), moderate (31-45 min), and long (46-60 min), as well as the length if the exercise intervention: short (1-3 months), medium (4-6 months), and long (6+ months). Authors reported that on average fitness training did improve participants’ performance by 0.5 SD (standard deviation) in various cognitive processes in the four theoretical positions mentioned above. Colcombe and Kramer also stated that performing combined strength and aerobic training was more effective than aerobic training alone. However, it is also mentioned that more clinical studies are required to make sure that these results were not influenced by such factors as general health or education, but rather these training programs are indeed as efficient as they are claimed to be. 7.7 Combining Cognitive and Aerobic Training In “Does combined cognitive training and physical activity training enhance cognitive abilities more than either one alone? A four-condition randomized controlled trial among healthy older adults,” Evelyn Shatil (2013) examined the separate and combined effects of cognitive and aerobic training on four groups of healthy older adults. Four groups of older adults participated in four months cognitive and/or mild aerobic training. Based on the results it was concluded that older adults who engaged in cognitive training (separately or combined) showed a significant improvement in cognitive performance when compared to older adults who didn’t engage in cognitive training. The improvement was shown in cognitive performance on Hand-Eye Coordination, working memory and long-term memory, Seed of Information Processing, Visual Scanning, and Naming. Shatil’s hypothesis was that combining physical activity with cognitive training would yield significantly larger cognitive benefits than physical activity or cognitive training separately, which, indeed, was the result of the study. The differences and improvements held true not only between the groups but also within the groups. 7.7.1 Problems with the research One important point to keep in mind is that all of these studies were done with healthy older adults. Even though these studies show improvement in cognitive abilities in older adults, whether fitness training has the same effect on cognition in younger adults or young people is to be determined. More scientific studies are needed to examine if active fitness regimen is as beneficial for young people as it is for older adults and what are the benefits of performing regular physical activities from early on in life. In addition, there are no studies with older adults that have any kind of diseases, like Alzheimer’s diseases, for example (Shatil, 2013). Will physical activities help those people that are not as healthy as the participants in all presented studies? A few more points to mention, while it is evident that fitness does improve cognitive abilities in older adults, it is important to develop a range of aerobic exercises that could be performed while sitting in order to accommodate those participants who are the oldest or have a high risk of falling (Shatil, 2013). Also, not many studies examine or observe how long the fitness training should last if people want to see any significant results in improving their cognitive functions. Shatil’s study, for example, lasted only four months, but there is an indication that aerobic training must be practiced at least one whole year to produce any cognitive benefits in sedentary adults (Voss et al., 2010). It is also not clear whether the benefits of physical training have a long-term effect or for how long the improvement lasts if one stops training. 7.8 Limitations and Future Work Results in resent research on ways to improve cognitive functions seem very promising. It is evident that there brain training techniques that indeed work and help people with their cognitive functions. For example, physical activities help older adults to maintain or improve cognitive processing that inevitably decline with age: speed, visuospatial, controlled processing, and executive control (Shatil, 2013). So do some of the brain training games (Nouchi et al., 2012). Knowing more than one language also seems to help with our executive functions (Stocco et al., 2014). And some studies encourage optimism regarding working memory training as a tool for cognitive enhancement (Morrison and Chein, 2010). However, people should investigate these results closely. While they seem promising and optimistic, there are still a lot of questions for these studies and their results. These are the four main concerns researchers should address when conducting new experiments with brain training programs: examining long-term effects of the training, applying training to people of various age, trying to identify whether these programs work on people who are not healthy and have either physical or mental disorders; identifying whether performing activities for cognitive enhancement individually or in a group setting affects the final results. 7.8.1 Long-Term Effects These studies didn’t examine a long-term effect of any of these brain training programs. Most of the evidence regarding improved cognitive functions was reported right after the end of the appropriate experiment, which resulted in the immediate effect of the training, but there was no follow-up experiment to measure if the results of the training held over a certain amount of time. It would be important to measure if the brain training program has a long-term effect because if it does not, then can this training program be considered as useful? Or would it be not useful without long-term effect? 7.8.2 Various Age Groups Most of the studies that were reviewed in this paper were focused on participants that are older in age. Even though some brain training games and physical activities do help to enhance cognitive functions in older adults, the question is, would these games and activities be more effective and more beneficial if people start using them at earlier age? If that is the case, why wait until your cognitive functions start to decline and then try to improve them if it can be prevented or delayed at earlier stage? In addition, some of these programs and especially physical activities would be much easier to perfume for those who are younger in age and there will be less risk factors involved in doing such activities. 7.8.3 Participants with Health Problems One more important limitation in all of the studies mentioned above is that all of them were performed with the participation of healthy individuals. Such things as personal health can have a great effect on the participant’s performance and on the final results of the study. Even though some programs might work for individuals with a good health, those same programs might have little to no effect on individual with health problems or who has an Alzheimer’s disease, for example (Colcombe and Kramer, 2003). It is important to consider not only mental health of a person, but their physical condition as well. Some active exercise programs may be suitable for some and not suitable for other, therefore scientists need to develop a program that could be performed by people in different physical conditions or a range of programs that would provide the same cognitive benefits to people but would be suitable for people in various physical conditions. 7.8.4 Individual vs. Group Setting One more interesting aspect that can influence performance and the outcome of the training is individual vs. group setting. This is especially true for physical training because physical activities can be performed individually or in groups. Since aerobic training and other fitness activities are claimed to improve participants’ cognitive functions, it would be interesting to see whether a greater effect can be achieved if participants have support and feedback from those who participates in the same fitness program. Positive feedback from peers in a group setting may increase one’s desire to continue with the raining or to try to work harder and better, while no such feedback is available during individual training, therefore there is a high possibility for the lack of motivation. Addressing these issues in future studies could help make brain training less controversial and more beneficial for people. First of all, addressing issues such as age of the participants and participants who have any mental or physical diseases would account for a wider range of users. And studying long-term effect and benefits of various programs in different settings (individual vs. group) would help identify which brain training programs indeed work and which ones work the best. 7.9 Conclusion In this paper we took a look at different ways to improve one’s cognitive abilities: chess and music, physical training, and various cognitive training programs, including brain training games, bilingual training, and working memory training. Many people will be greatly disappointed, but being good at chess or music doesn’t mean that you’ll be good at everything else. There is not enough scientific evidence of far transfer from the domain on music and chess to other domains, not related to the two above. Near transfer, on the other hand, is known to take place. However, there are training programs that can help people improve our cognitive abilities. Such programs would be fitness training and exercises, brain training games, bilingual training and working memory training. Results of multiple studies show improvement in cognitive abilities in adults after participating in these brain training programs. But despite how promising and optimistic these results might sound, there are still a lot of grey areas and many unanswered questions. More research studies are required to develop better programs that would help improve one’s cognitive abilities despite their age, health or any other factors that might influence the final effect of the programs that are currently promoted on the market. But this is a right step towards improving our cognitive abilities. 7.10 References Ball, K., Berch, D. B., Helmers, K. F., Jobe, J. B., Leveck, M. D., &amp; Marsiske, M. (2002). Effects of cognitive training interventions with older adults: a randomized controlled trial. JAMA, 288, 2271–2281. Ball, K., Edwards, J. D., &amp; Ross, A. L. (2007). Cognitive interventions and aging: the impact of speed of processing training on cognitive and everyday functions J. Gerontol. Ser. B, 62B, 19-31. Basak, C., Boot, W. R., Voss, M. W., &amp; Kramer, A. F. (2008). Can training in a real-time strategy video game attenuate cognitive decline in older adults? Psychol. Aging, 23, 765-777. Bialystok, E. (2001). Bilingualism in development: Language, literacy and cognition. New York: Cambridge University Press. Bialystok, E. (2009). Bilingualism: The good, the bad, and the indifferent. Bilingualism: Language and Cognition, 12, 3-11. Burgoyne, A. P., Sala, G., Gobet, F., Macnamara, B. N., Campitelli, G., &amp; Hambrick, D. Z. (2016). The relationship between cognitive ability and chess skill: A comprehensive meta-analysis. Intelligence, 59, 72-83. Colcombe, S. &amp; Kramer, A. F. (2003). Fitness effect on the cognitive function of older adults: A Meta-analysis study. Psychological Science, 14(2), 125-30. doi:[10.1111/1467-9280.t01-1-01430](https://doi.org/10.1111/1467-9280.t01-1-01430) Festman, J., Rodriguez-Fornells, A., &amp; Münte, T. F. (2010). Individual differences in control of language interference in late bilinguals are mainly related to general executive abilities. Behavioral and Brain Functions, 6, 1-12. Kane, M., Hambrick, D., Tuholski, S., Wilhelm, O., Payne, T., &amp; Engle, R. (2004). The generality of working memory capacity: A latent-variable approach to verbal and visuospatial memory span and reasoning. Journal of Experimental Psychology: General, 133(2), 189-217. doi:10.1037/0096-3445.133.2.189 Klingberg, T., Fernell, E., Olesen, P. J., Johnson, M., Gustafsson, P., Dahlstrom, K. (2005). Computerized training of working memory in children with ADHD: A randomized, controlled trial. Journal of the American Academy of Child and Adolescent Psychiatry, 44(2), 177-186. doi:10.1097/00004583-200502000-00010 Kueider, A., Bichay, K., &amp; Rebok, G. (2014). Cognitive training for older Adults: What is it and does it work? Issue Brief, 10, 1-8. Lee, Y., Lu, M., &amp; Ko, H. (2007). Effect of skill training on working memory capacity. Learning and Instruction, 17, 336-344. Mahncke, H. W., Connor, B. B., Appelman, J., Ahsanuddin, O. N., Hardy, J. L., &amp; Wood, R. A. (2006). Memory enhancement in healthy older adults using a brain plasticity-based training program: a randomized, controlled study. Proc. Natl. Acad. U.S.A, 103, 12523-12528. Miyake, A., Friedman, N. P., Emerson, M. J., Witzki, A. H., Howerter, A., &amp; Wager, T. D. (2000). The unity and diversity of executive functions and their contributions to complex “frontal lobe” tasks: A latent variable analysis. Cognitive Psychology, 41, 49-100. Morrison, A. B. &amp; Chein, J. M. (2010). Does working memory training work? The promise and challenges of enhancing cognition by training working memory. Springer, 18, 46-60. doi:10.3758/s13423-010-0034-0 Mozolic, J.L., Long, A.B., Morgan, A.R, Rawley-Payne, M., Laurienti, P. J. (2011). A cognitive training intervention improves modality-specific attention in a randomized controlled trial of healthy older adults. Neurobiol Aging, 32, 655-668. Nouchi, R., Taki, Y., Takeuchi, H., Hashizume, H., Akitsuki, Y. (2012). Brain training game improves executive functions and processing speed in the elderly: A randomized controlled trial. PLoS ONE, 7(1), e29676. doi:10.1371/journal.pone.0029676 Oei, A. C. &amp; Patterson, M. D. (2015). Enhancing perceptual and attentional skills requires common demands between the action video games and transfer tasks. Frontiers in Psychology, 6, 113. doi:10.3389/fpsyg.2015.00113 Park, D. C., Lautenschlager, G., Hedden, T., Davidson, N. S., &amp; Smith, A. D. (2002). Models of visuospatial and verbal memory across the adult life span. Psychol. Aging, 17, 299-320. Parsons,B., Magill, T., Boucher, A., Zhang, M., Zogbo, K., Bérubé, S., Scheffer, O., Beauregard, M., &amp; Faubert, J. (2016). Enhancing cognitive function using perceptual-cognitive training. Clinical EEG and Neuroscience, 47(1), 37-47. doi:10.1177/1550059414563746 Rabipour, S. &amp; Raz, A. (2012). Training the brain: Fact and fad in cognitive and behavioral remediation. Brain and Cognition, 79, 159-179. doi:10.1016/j.bandc.2012.02.006 Rosenthal, R. (1998). Meta-analysis: Concepts, corollaries and controversies. Advances in psychological science, 1, 371-384. Sala, G. &amp; Gobet, F. (2017). Does far transfer exist? Negative evidence from chess, music, and working memory training. Current Directions in Psychological Science, 26(6), 515–520. doi:10.1177/0963721417712760 Salthouse, T. A. (2004). What and when of cognitive aging. Curr. Dir. Psychol. Sci. 13, 140-144. Schellenberg, E. G. (2006). Long-term positive associations between music lessons and IQ. Journal of Educational Psychology, 98, 457-468. Shatil, E. (2013). Does combined cognitive training and physical activity training enhance cognitive abilities more than either one alone? A four-condition randomized controlled trial among healthy older adults. Frontiers in Aging Neuroscience, 5, 1-12. doi:10.3389/fnagi.2013.00008 Simons, D. J., Boot, W. R., Charness, N., Gathercole, S. E., Chabris, C. F., Hambrick, D. Z., &amp; Stine-Morrow, E. A. L. (2016). Do “brain-training” programs work? Psychological Science in the Public Interest, 17, 103-186. Smith, G. E., Housen, P., Yaffe, K., Ruff, R., Kennison, R. F., Mahncke, H. W., &amp; Zelinski, E. M. (2009). A cognitive training program based on principles of brain plasticity: Results for the improvement in memory with plasticity-based adaptive cognitive training (IMPACT) study. Journal of the American Geriatrics Society, 57, 594-603. Stine-Morrow, E. A. L., Hussey, E. K., &amp; Ng, S. (2015). The potential for literacy to shape lifelong cognitive health. Policy Insights From the Behavioral and Brain Sciences, 2, 92-100. doi:10.1177/2372732215600889 Stocco, A., Yamasaki, B., Natalenko, R., &amp; Prat, C. S. (2014). Bilingual brain training: A neurobiological framework of how bilingual experience improves executive function. International Journal of Bilingualism, 18(1), 67-92. Thorndike, E. L. &amp; Woodworth, R. S. (1901). The influence of improvement in one mental function upon the efficiency of other functions (I). Psychological Review, 8, 247-261. Uchida, S., &amp; Kawashima, R. (2008). Reading and solving arithmetic problems improves cognitive functions of normal aged people: a randomized controlled study. Age (Dordr), 30, 21-29. van Heugten, C. M., Ponds, R. W. H. M., &amp; Kessels, R. P.C. (2016). Brain training: Hype or hope? Neuropsychological Rehabilitation, 26, 639-644. doi:10.1080/09602011.2016.1186101 Verhaeghen, P., &amp; Cerella, J. (2002). Aging, executive control, and attention: A review of meta- analyses. Neurosci. Biobehav. Rev. 26, 849-857. Voss, M. W., Prakash, R.S., Erickson, K. I.,Basak,C.,Chaddock,L., &amp; Kim, J.S. (2010). Plasticity of brain networks in a randomized intervention trial of exercise training in older adults. Front. Aging Neurosci, 2, 32. doi:10.3389/fnagi.2010.00032 Wilson, B. A. (1997). Cognitive rehabilitation: How it is and how it might be. Journal of the International Neuropsychological Society, 3, 487-496. "],
["human-object-recognition-and-computational-models.html", "Chapter 8 Human Object Recognition and Computational Models 8.1 Introduction 8.2 Human Object Recognition System 8.3 The behavioral phenomena of interest in object recognition 8.4 The behavioral phenomenon: Other-race effect 8.5 The behavioral phenomenon: Unfamiliar face 8.6 How we deal with the difficulties of computational models? 8.7 5. Conclusion 8.8 References", " Chapter 8 Human Object Recognition and Computational Models Seoung, Yeji The City University of New York – Hunter College 8.1 Introduction The ability to identify visual information is important in humans and animals for their survival. When you walk around downtown, you might identify buildings, traffic signs, a car that is approaching to you or faces of people on the street. We effortlessly recognize and classify visually presented objects and faces of people with high-accuracy (Biderman, 1987), even though each object produces tremendous variations in appearance (Logothetis, &amp; Sheingerg, 1996). Such automatic brain process in visual recognition system enables us to build conceptual representation through generalizations of a novel object into an existing category, but also through identifications of similar characteristics from different kinds of things (Grill-Spector et al., 2001). For example, when you see a golden retriever on the street, you can categorize it as a dog and distinguish the differences between a poodle and it and their shared features such as having four legs or a tail. Although there are various functions of our vision (DiCarlo, &amp; Cox, 2007), in the present review, recognition will be referred to a task including both identification and categorization: identification in which one can recognize a specific object or face among others, and categorization in which one can recognize a dog among other object classes (Poggio, &amp; Ullman, 2013). Although computerized recognition systems not completely duplicate individuals’ recognition performances, the studying of such artificial models contribute to understanding in process on human visual recognition systems (Pinto et al., 2008). A large body of literature has been interested in determining whether or not the computational approaches reproduce a realistic theory of human/animal object recognition. Since visual performance in the brain is attributed by more than 50 percent of the neocortex (Felleman, &amp; Van Essen, 1991), it is not surprising to be difficult to emulate this ability in computational methods. Early computational approaches focused primarily on recognizing three-dimensional (3D) objects, including artifacts (e.g., buildings, tables, and automobiles), animals and human faces. The main problem of such computational methods is that representations of objects are two-dimensionally produced on the retina at first, even if we recognize them as 3D images with different visual variations depending on its pose and lighting (Ullman, 1996). More recently developed computational models, especially including inspired by brain-based approaches, enable to recognize meaningful patterns on object (e.g., Lazebnik, Schmid, &amp; Ponce, 2006; Mutch, &amp; Lowe, 2006; Wang, Zhang, &amp; Fei-Fei, 2006; Zhang, Berg, &amp; Malik, 2006). A natural way to understand this general theme is to first try to review the basic capacities of the primate recognition system. After a brief description of some general principles of object recognition, this paper explores specific findings of effects and phenomena in the object recognition literatures. Then, this article will discuss whether or not each computational pattern classification theory can explain the phenomena. To that end, the current paper will investigate a possible solution motivated by the ventral visual stream in the brain to deal with the challenges of object recognition in modern computational models. 8.2 Human Object Recognition System We first need to explore specialized regions in the brain where are activated or not when recognizing objects or faces (Johnson, 1980) in order to adapt human object recognition theory into computational pattern models. This section will review how we perform object recognition in the brain. 8.2.1 The homology of human and macaque’s visual systems Object recognition task seems easy to perform for human and primates. When representing visual stimuli, the common features of the brain activations in the lateral occipital complex (LOC) (Orban, Van Essen, &amp; Vanduffel, 2004) and in the inferotemporal cortex (IT) (Kriegeskorte et al., 2008) have been observed in the studies on a comparison of macaques to humans. Compared to macaques’ brain, we have little figured out how neurons in the human brain are associated with each other or how neuronal chemical reactions are responded when performing object recognition (Clarke et al., 1999). However, Orban et al. (2004) found that there were similar brain activities of both the humans and the macaques in retinotopic visual regions, including early visual cortex (V1, V2, V3) and several mid-level visual areas (V4, MT, and V3A). Thus, each area transmits a population-based visual information to other brain areas (Felleman, &amp; Van Essen, 1991). Beyond retinotopic cortex, several visual fields work on object recognition differently: the regions of MT/MST act as identifying object motion (Watson et al., 1993; Tootell &amp; Taylor, 1995); the fields of TEO, V4, and V8 function as color detector (Engel, Zhang, &amp; Wandell, 1997; Hadjikhani, Liu, Dale, Cavanagh, &amp; Tootell, 1998; Bartels &amp; Zeki, 2000); the area of KO is activated by the kinetic motion recognition (Van Oostende, Sunaert, Van Hecke, Marchal, &amp; Orban, 1997). The lateral occipital complex (the LOC) known as non-retinotopic areas is a crucial region in performing the recognition task as well (Grill-Spector et al., 1998; Tootell, Mendola, Hanjikhani, Liu &amp;, Dale, 1998). The LOC includes several brain fields like the lateral bank of the fusiform gyrus (Grill-Spector et al., 1998; Tootell, Mendola, Hanjikhani, Liu &amp;, Dale, 1998). The LOC is sensitive to identify pieces of objects as well as objects as a whole (Grill-Spector et al., 1998). In addition to the functions of the LOC, such capability to recognize visual items is also observed in the inferotemporal cortex (IT) (Gross, Rocha, &amp; Bender, 1972; Ito, Tamura, Fujita, &amp; Tanaka, 1995). Specifically, IT neuronal activities are shown in at least more than six areas (Taso et al., 2003; Tsao et al., 2008a; Ku et al., 2011), suggesting that the IT might establish face recognition processing as well as non-human visual stimuli (Tsao et al., 2008b). Overall, studies on the homology of humans and macaques in visual mechanisms emphasizes the crucial role of the LOC and the IT in object recognition. 8.2.2 Object-selective visual areas in the human brain The advent of brain image techniques such as positron emission tomography (PET) and functional magnetic resonance imaging (fMRI) makes it possible to explore the neurobiological basis of object recognition in humans. A large body of literature has been revealed that working on object recognition is localized in specific areas, which are called the ventral visual processing stream including the occipital and temporal lobes (Miyashita, 1993; Orban, 2008; Rolls, 2000). For example, several studies using PET have provided evidence that the ventral and temporal areas were strongly activated when subjects were visually presented to individuals’ faces and objects (Haxby, Grady, Ungerleider, &amp; Horwitz, 1991; Kosslyn et al., 1994; Nobre, Allison, &amp; McCarthy, 1994; Woldorff, et al., 1997). In addition, those fields are even stimulated when subjects are asked to see shapes of objects passively (Corbetta, Miezin, Dobmeyer, Shulman, &amp; Petersen, 1991; Haxby et al., 1994). Furthermore, the study using fMRI found that the extent of activation in the LOC depends on the qualities of visual stimuli and whether they provide apparent shape or not (Malach et al., 1995). A variety of recognition deficits have been revealed when patients have damages in the fusiform and occipito-temporal junction (Farah, Hammond, Mehta, &amp; Ratcliff, 1989; Damasio, Tranel, &amp; Damasio, 1990; Goodale, Milner, Jakobson, &amp; Carey, 1991; Feinberg, Schindler, Ochoa, Kwan, &amp; Farah, 1994; Farah, Klein, &amp; Levinson, 1995; Moscovitch, Winocur, &amp; Behrmann, 1999). The studies used by Event-related potentials (ERPs) found that compared to when presenting jumbled control images, stronger activities in the LOC were shown for a vast array of artifacts (e.g., furniture, buildings, and tools) (McCarthy, Puce, Belger, &amp; Allison, 1999; Allison, Puce, Spencer, &amp; McCarthy, 1999). These studies also reported that when presenting individuals’ faces, the brain activities are specialized in the areas of the middle and anterior fusiform gyrus (McCarthy, Puce, Belger, &amp; Allison, 1999; Allison, Puce, Spencer, &amp; McCarthy, 1999). In conclusion, the development of brain image techniques has led to understand the significant role of the ventral visual stream where the brain regions are associated with recognition in object items. 8.2.3 Facial visual areas in the human brain Evidence from a large body of studies suggests that the brain regions working on face recognition are different from the areas involved in object recognition, though partially overlapped with each other (Behrmann et al., 1992; Caldara et al., 2003; Desimone, 1991; Tanaka, &amp; Farah, 1993; Turk, &amp; Pentland, 1991; Perrett et al., 1992). For example, it is hard for patients with prosopagnosia to recognize human faces since they have damages in specific brain areas, particularly of bilateral (Damasio et al., 1982; Gauthier et al., 1999) or unilateral right occipito-temporal lesions (De Renzi, 1986; Landis et al., 1986). On the other hand, it has been reported that while preserving face recognition, patients suffering from agnosia cannot identify object stimuli (Moscovitch et al., 1997). These findings suggest that the brain works independently for object and face recognition. In the same vein, neuroimaging studies using fMRI report the significant role of the occipito-temporal regions in face recognition (Kanwisher et al., 1991; McCarthy et al., 1997). Specifically, the human fusiform gyrus, the fusiform face area (FFA) is exclusively dedicated to face processing (Kanwisher, McDermott, &amp; Chun, 1997; Grill-Spector, Knouf, &amp; Kanwisher, 2004). Neuronal evidence revealed that neuronal activities in the FFA were strongly responded when presented face images rather than when presented non-face stimuli (Tsao et al., 2006). Taken together, FFA is a crucial area which acts as face recognition, thus suggesting there are the distinct brain areas between object and face recognition. 8.3 The behavioral phenomena of interest in object recognition Understanding in object recognition would be required to investigate how phenomena link to recognition systems (DiCarlo, Zoccolan, &amp; Rust, 2012). The current section will discuss several phenomena that are observed in object recognition literature, and whether or not each computational model can account for the effect. 8.4 The behavioral phenomenon: Other-race effect Although we encounter thousands of people in our lifetime, we can easily recognize a face among different individuals. Identifying or classifying people into several categories including race can have an effect on such automatic brain mechanism. According to Feingold (1914), our face recognition capabilities have more to do with same race (SR) than faces of another race (i.e., other-race faces (OR)), thus this effect is called “other-race” effect (ORE). For many years, a number of studies have supported this recognition effect (Caldara, &amp; Abdi, 2006; Furl et al., 2002; Goldstein, &amp; Chance, 1985; O’Toole, &amp; Peterson, 1996; O’Toole et al., 1994; Valentine, 1991). This phenomenon suggests that it might be hard to perceive the uniqueness or individuality of other-race faces (Furl et al., 2002). Although ORE is robustly and reliably observed in the psychological literature, it is still controversial whether it can account for the other-race phenomenon. Several hypotheses have been suggested to explain the other-race phenomenon (O’Toole et al., 1994), but there is little support for some accounts (Brigham, 1986): we inherently have more difficulty identifying faces of some races than others; prejudicial attitudes impede recognition of OR faces; and face recognition is processed more superficially in viewing OR faces than SR faces. A fourth possibility, which has been suggested by most studies, emphasizes that the extent of having an experience about particular races can influence on ORE (O’Toole et al., 1991; Furl et al., 2002). Imagine, we have had a great experience with SR faces rather than OR faces, and then we would tend to easily recognize for SR faces than for OR faces (Caldara, &amp; Abdi, 2006). In other words, if we have a bunch of experience with other race faces, we would better recognize them. While other studies (e.g., Brigham, &amp; Barkowitz, 1978; Lavarkas, Buri, &amp; Mayzner, 1976; Malpass, &amp; Kravitz, 1969; Ng, &amp; Lindsay, 1994) fail to find convincing results for this hypothesis, it is important to note that at least one study (brigham et al., 1982) found a small but significant effect of contact experience on ORE. Thus, it is an obscure field on the underlying explanations for ORE effect (Meissner, &amp; Brigham, 2001) and the further study would be necessary. 8.4.1 Face space model ORE has an advantage in classifying faces, even if it leads us to have the difficulty of recognizing OR faces. When subjects are asked to categorize individuals’ faces into an identical race, for example, they classify the distinct race of faces more quickly rather than their own race of faces (Caldara et al., 2004; Valentine, &amp; Endo, 1992). According to Valentine (1991), such other race advantage can be explained by an exemplar model. In the pattern computational systems, the face-stimuli inputs are placed in a multidimensional space, usually Euclidean (Valentine, 1991). The directions and distances of each input from the average face are calculated and this information determines the locations where each stimulus is placed in the space (Valentine, 1991), and psychophysical data support this view (Leopold et al., 2001). Empirical evidence showed that the distances of typical faces from the origin were shorter than those of other faces (Burton, &amp; Vokey, 1998). Indeed, a set of face stimuli is presented as a dot on the multidimension of the space, and thus OR faces are densely clustered while SR faces are broadly distributed in the space (Caldara et al., 2004). Due to this high-density pattern for OR faces, we can quickly classify faces of the distinct race rather than SR faces (Caldara et al., 2004). More interestingly, these particular patterns lead to increase in the difficulty of discrimination of different exemplars, and thus suggests other-race effects (Caldara, &amp; Abdi, 2006). Although the face space model is useful to explain the ORE, a lack of explanation for encoding is a significant drawback in this model (Caldara, &amp; Abdi, 2006). To deal with such problem, Burton and Vokey (1998) extracted the statistical properties from real faces to clarify the dimensions. Such way will also fix the weights of dimensions by learning inputs of faces (Caldara, &amp; Abdi, 2006). Moreover, perceptual learning can play an important role in obtaining these dimension (Caldara, &amp; Abdi, 2006). 8.4.2 Perceptual learning theory O’Toole et al. (1995) proposed that perceptual learning can play a significant role in understanding the mechanism for ORE. This so-called perceptual learning theory suggests that as face recognition ability develops, individuals will obtain the discriminating skills among individual human faces by learning to use the perceptual dimensions. O’Toole et al. (1996) found the benefits of perceptual learning on recognition on SR faces. Neuronal evidence also showed that individuals’ neural networks were strongly stimulated by new faces from the reference group (Caucasian) rather than faces from the other-race group (Asia), when subjects trained a set of Caucasian face-stimuli as a reference group, (O’Toole et al., 1996). This result is consistent with the finding in computational recognition pattern that it did more accurately recognize Caucasian faces than other-race faces, when Caucasian faces were trained and set as a reference group (Furl et al., 2002). There are at least two major similarities between the theoretical face-space model and perceptual learning theory (Caldara, &amp; Abdi, 2006). In order to explain ORE, both face-space model and perceptual learning theory emphasis on the significance of variance experience and the degrees of inner representations (Caldara, &amp; Abdi, 2006). Since both theories above have advantages and disadvantages to explain ORE, Caldara and Abdi (2006) suggest a complemented approach by using neural networks which are associated with conceptual representations. 8.4.3 Neural networks evidence Given both the limitation of face-space model and perceptual learning theory, Caldara and Abdi (2006) improved an algorithm, motivated by neuronal network associations, aimed to construct conceptual representations of face recognition in a multidimension space and to clarity whether the models can account for the ORE. Their simulation results revealed that when the SR faces were learnt as a target group, the face representations were broadly spread in the face-space while the OR faces were densely clustered (Caldara, &amp; Abdi, 2006). Neuronal network patterns provided that face-space model is optimal to respond to OR faces, suggesting that when individuals have more experience with SR faces, they would take advantage of perceptual learning, and thus they will be skillful to recognize SR faces rather than OR faces (Caldara, &amp; Abdi, 2006). Their findings are consistent with scientific evidence that perceptual learning is a crucial factor to explain the ORE (Furl et al., 2002; O’Toole et al., 1994; O’Toole et al., 1996). Thus, although perceptual learning can improve to encode distinctions relevant for SR faces, it makes be hard to recognize OR face representations (Caldara, &amp; Abdi, 2006). Overall, neuronal networks evidence supports the explanations of the face-space model and perceptual learning theory on the ORE. 8.5 The behavioral phenomenon: Unfamiliar face We effortlessly recognize faces of different people, but this ability is significantly different from familiar faces, which belong to our personal acquaintances, and unfamiliar faces (Bindemann, Avetisyan, &amp; Rakow, 2012; Bruce et al., 2001; Hancock et al., 2000; Jenkins, &amp; Burton, 2011; Johnston, &amp; Edmonds, 2009). Although recognizing familiar faces is strikingly stable and reliable performance regardless of poor visual conditions (e.g., poor illumination, low-quality images, and variable viewpoints), recognition of unfamiliar faces appears remarkably poor, even without any poor viewing conditions (Bindemann et al., 2012; Bruce et al., 2001; Hancock et al., 2000). Behavioral (e.g., Bindemann, &amp; Sandford, 2011) and psychophysical evidence (e.g., Haxby et al., 2001) have been supported this phenomenon. 8.5.1 Face-space model The face-space model also reviewed in 3.1.2, but here focus on face-space model accounting for unfamiliar face. This well-known model pursues to reproduce human’s conceptual representations of faces. One way of the underlying dimensions is multi-dimensional scaling (MDS) in terms of similarity inspired by exemplar models (Busey, 1998). According to Busey (1998), for example, he created six identifiable dimensions (e.g., age, facial hair, and hair color) in order to replicate human face recognition performance by using a bald man image set. When target faces are not bald, the important dimension would be hair color and style (Hancock et al., 2000). In addition, a statistical analyzing on a face set like principal component analysis (PCA) is a commonly used method in computational recognition task (Hancock et al., 2000). This approach represents a set of faces as a small number of global eigenvectors, which encode the major variations in the input set (Grudin, 2000). However, one serious drawback of PCA is the limitation when there is large within-class variance in the image sets (Kalocsai et al., 1998). Thus, it is likely that efficient information would be neglected because there are several possible views to recognize each face in the dataset (Hancock et al., 2000). Although PCA might provide the dimensionality of the space, not all dimensions are labeled and interpreted (Hancock et al., 2000). According to Dailey et al (1999), Compared to a model using PCA, MDS data by particularly using a kernel density estimation model is more predictable in human face recognition. Although there are efforts to apply the process of human face recognition to computational models and they have become to perform face recognition, it is hard to achieve to reproduce it completely resemble to human perception (Hancock et al., 2000). 8.6 How we deal with the difficulties of computational models? 8.6.1 Core Recognition Human and animals have abilities to extremely accurately and quickly recognize objects in their visual systems, which are supported by empirical evidence. For example, humans are able to recognize a briefly presented image in as short as 350ms (Rousselet, Fabre-Thorpe, &amp; Thorpe, 2002; Thorpe, Fize, &amp; Marlot, 1996), and monkeys can do it in 250ms (Fabre-Thorpe., Richard, &amp; Thorpe, 1998). Event-related potential (ERP) experiments found that complex visual processing of object recognition is achieved in 150 ms (Thorpe et al., 1996). Such ability is referred to “core recognition” that the primates are able to perceive and classify visually-presented objects quickly and accurately (DiCarlo, &amp; Cox, 2007). 8.6.2 Invariance problem Due to the fact that transformed images with tremendous variants are preserved as an identity (DiCarlo, Zoccolan, &amp; Rust, 2012), one can recognize two-dimensionally presented items on the retina (DiCarlo, &amp; Cox, 2007). The perceptual constancy is a significant mechanism for working on object recognition performance without any trouble which is provided by the changes in lighting, size, and backgrounds (Grill-Spector et al., 2001). That is, the variability of the world and the recognizer would lead to enormous images of each object that must be categorized into the identical category (e.g., “dog”) (DiCarlo et al., 2012; Grill-Spector et al., 2001). Thus, human capabilities to perceive and classify objects are not impeded by enormous variabilities of positions, scales, poses, illumination, and clutter (DiCarlo et al., 2012; Grill-Spector et al., 2001). Besides, one can recognize each part of object (e.g., eyes and legs of a dog) as well as the object as a whole (e.g., a dog), and one can categorize conceptual representations into an existing category like “cats,” “apartments,” “bicycles,” which is called intraclass variability (Grill-Spector et al., 2001). Although each object is presented in visually infinite variants, visual systems achieve the equivalence of all of these different patterns of each object without any confusion with images of all other possible objects. Such human recognition ability that is less sensitive to different visual appearances is referred to ‘cue-invariance’ (Grill-Spector et al., 2001). Although this invariance problem can be an impediment for computational models to reproduce human’s recognition completely, especially when items with infinite variants are implemented, both empirical (Thorpe, Fize, &amp; Marlot, 1996) and physiological (Hung, Kreiman, Poggio, &amp; DiCarlo, 2005) findings suggest that we would obtain a clue from visual stream to solve this invariance problem rapidly (DiCarlo, &amp; Cox, 2007; DiCarlo et al., 2012; Grill-Spectore, &amp; Malach, 2001; Grill-Spector et al., 2001). For example, Grill-Spector et al. (1998) reported that when subjects were presented to visually-variance objects, the object-selective brain fields, particularly the LOC, are actively stimulated. This finding implies that cue-invariance is observed in our visual recognition system. Kourtzi and Kanwisher (2000) investigated the levels of the brain activities in the LOC. Their results revealed that when subjects are presented to grayscale objects as a whole, the responses of the LOC were stronger compared to when presented to line drawings. In addition, their findings showed that when presented to pairs of same images, both levels of brain activities in LOC were similar (Kourtzi and Kanwisher, 2000). The similar brain responses were shown even when subjects passively saw pairs of stimuli which they were the identical objects but had different morphs (e.g., two different kinds of golden retrievers) (Kourtzi and Kanwisher, 2000). Moreover, Grill-Spector and Malach (2001) conducted a studying for invariant properties of the LOC by using functional magnetic resonance-adaptation (fMR-A). They reported that this area can work on object recognition regardless of the object’s variabilities in size and position (Grill-Spector, &amp; Malach, 2001). These results above demonstrate that there is the cue-invariance in visual object system and emphasize the crucial role of the LOC in object recognition. In the same vein, studies of fMRI revealed that IT sub-populations show the cue-invariance problem as well (Majaj et al., 2012) and this problem is not limited to a performance of object (i.e., non-face stimuli) recognition (Freiwald, &amp; Tsao, 2010). Thus, when individuals recognize faces of other people, the similar recognition processing has been observed (Freiwald, &amp; Tsao, 2010). Strikingly, it is important to note that IT neuronal populations can strongly support for human pattern recognition theory compared to neuronal populations of the earlier visual systems (Freiwald, &amp; Tsao, 2010; Hung et al., 2005; Rust, &amp; DiCarlo, 2010). Even when subjects perceive intricate visual morphs, IT neuronal populations are readily activated (Brincat, &amp; connor, 2004; Desimone et al., 1984; Perrett et al., 1982; Rust, &amp; DiCarlo, 2010; Tanaka, 1996). Moreover, viewing relatively trivial changes in object items can stimulate IT neurons such as variabilities of object position and size (Brincat, &amp; Connor, 2004; Ito et al., 1995; Li et al., 2009; Rust, &amp; DiCarlo, 2010; Tovee et al., 1994), various poses (Logothesis et al., 1994), variabilities of lighting (Vogels, &amp; Biederman, 2002), and changes of cluster (Li et al., 2009; Missal et al., 1999; Zoccolan et al., 2005). Thus, visual object representations are constructed with invariance problem in the IT neuronal populations (DiCarlo et al., 2012). 8.6.3 The explanation of IT neuronal populations on object recognition The transmission of visual object information in the brain is a hierarchical processing: visual information is sent first to the retina; from there, this information is transmitted to the lateral geniculate nucleus of the thalamus (LGN), and then to the occipital lobe, specifically area V1 to V2 to V4 to IT (Felleman, &amp; Van Essen, 1991). Traditionally, biologically inspired computational models have tried to duplicate 2D images, and this endeavor implies that 2D visual information is transmitted from early visual systems (areas V2 and V4) to final systems (IT) in the ventral visual stream (Anzai, Peng, &amp; Van Essen, 2007; Gallant, Braun, &amp; Van Essen, 1993; Pasupathy, &amp; Connor, 2001). At each stage, although neurons are tuned for component-level shape, IT can be involved in holistic shape tuning through learning (Baker, Behrmann, &amp; Olson, 2002). Although a large body of literature have figured out the mechanisms of the early visual systems like the area V1 (Lennie, &amp; Movshon, 2005), we do not clearly understand the mechanisms of the final stage such as the IT (Hung et al., 2005; Rust, &amp; DiCarlo, 2010). However, relatively recent several studies have revealed that the activities of the IT populations are clear and stable to perform recognizing objects as well as faces representations that have a variety of variabilities ranging from position to background component (Hung et al., 2005; Rust, &amp; DiCarlo, 2010). Moreover, neuronal analyses suggested that the IT neuronal populations were activated when subjects performed face recognition tasks (Freiwald, &amp; Tsao, 2010). Such neuronal activities could confirm the cue-invariance problem in our visual system (Freiwald, &amp; Tsao, 2010). Thus, the mechanisms of the IT neuronal activities can explain for human invariant object recognition behavior (Majaj et al., 2012). These studies also demonstrate that the explanations for object recognition based on the analysis of the IT populations are more clearly accounted for our visual functions than those motivated by the early visual stream (Freiwald, &amp; Tsao, 2010; Hung et al., 2005; Rust, &amp; DiCarlo, 2010). DiCarlo et al. (2012) summarized the neurophysiological evidence for IT neuronal populations as follows. First, the IT populations decode and transfer visual representations within 50 ms. Furthermore, after presented images, decoding visual information is accessible beginning under 100 ms. Additionally, the IT populations decode visual representations into neuronal formats with preserving cue-invariance of the objects (DiCarlo et al., 2012). Finally, these simple weighted summation codes are observed when subjects are presented objects without any training for a set of images (Hung et al., 2005). Taken together, by decoding visual representations, IT neuronal populations in the final stage of the ventral visual stream can be applied to computational pattern models (Pinto et al., 2010), but also can account for human object recognition behavior (Hung et al., 2005; Rust, &amp; DiCarlo, 2010). 8.6.4 Shape similarity vs. semantic category information in IT neuronal populations The efforts of understanding human object recognition behavior have led to develop several computational models. Particularly, the artificial systems based on IT neuronal population representation suggest better explanations for the processing of object recognition performance. However, it is still debatable how visual information is represented and placed in the visual areas. There are two main hypotheses in visual representations: shape similarity vs. semantic category (Baldassi et al., 2013; Huth et al., 2012; Khaligh-Razavi, &amp; Kriegeskorte, 2014). In the shape similarity view, we might consider the IT as a visual representation, because objects are segmented and clustered into visually similar groups. Thus, visual features of objects can be a crucial factor for visual representations in the brain. On the other hand, in the semantic category view, semantic information is significant criteria for representations of visual information. In this view, we might think of the IT as a visuo-semantic representation (Khaligh-Razavi, &amp; Kriegeskorte, 2014). Several literature claims that simple or intricate visual components are coded into IT neurons which serve as visual representations based on shape similarity (Brincat, &amp; Connor, 2004; Kayaert, Biederman, &amp; Vogels, 2003; Kayaert, Biederman, Beeck, &amp; Vogels, 2005; Yamane et al., 2008; Zoccolan, et al., 2007; Zoccolan et al., 2005). For example, Yamane et al. (2008) report that the representations of IT neuronal populations provide evidence for the important role of shape similarity components in constructing visual neural signals. A study of the IT of monkey used fMRI showed that the visual representations of animate objects were overlapped by inanimate objects in the IT (Freedman et al., 2006). Importantly, compared to the prefrontal cortex, in the IT neuronal populations, the levels of the activities for visually liked objects were not significantly different from those for objects which were clustered by semantic category (e.g., between cat-like and dog-like stimuli) (Freedman et al., 2006). Overall, these studies support the shape similarity theory for visual representations that IT neurons play a significant role in reproducing object identity (Kourtzi, &amp; Connor, 2011). Although biological evidence has revealed that IT neurons can be considered as a visual representation, recent several studies argue that visual objects are coded into the IT populations in terms of semantic category information (Huth et al., 2012). For example, compared to clusters based on their visual feature similarity, the visual representations are more clustered into several semantic categories such as animals, non-animate objects, and faces (Huth et al., 2012). Although a general semantic area for visual representations in the brain has not been observed, single fields provide the evidence that visual representations are organized by semantically related categories (Connolly et al., 2012; Just et al., 2010; Konkle and Oliva, 2012; Kriegeskorte et al., 2008; Naselaris et al., 2009; O’Toole et al., 2005). In the IT of monkey’s studies, the groups of visual representations in the brain were divided by semantic categories and the similar patterns showed in human’s brain as well. Particularly, the groups for inanimate objects were clearly segregated from those for animate objects (Connolly et al., 2012; Just et al., 2010; Konkle and Oliva, 2012; Kriegeskorte et al., 2008; Naselaris et al., 2009; O’Toole et al., 2005). Moreover, fMRI studies found that semantic-based metrics can explain for visual representations in the monkey’s IT populations patterns (Bell et al., 2009), which is consistent to the results from several studies that semantically segregated visual representations can meaningfully support for human object recognition patterns (Downing, Jiang, Shuman, &amp; Kanwisher, 2001; Kanwisher, 2010; Kanwisher, McDermott, &amp; Chun, 1997; Mahon et al., 2007; Mahon, &amp; Caramazza, 2009; Naselaris et al., 2009). This semantic category theory could be distinguished by studies that produce object-defining visual features and contrast their explanatory power. However, semantic category-based model cannot explain the functions of the IT populations without shape similarity-based model. Thus, visual representations in the IT are segmented by visual similarity as well as semantic category (Kriegeskorte et al., 2008; Connolly et al., 2012; Huth et al., 2012; Carlson et al., 2013). In order to reproduce visual representational metrics that are similar to those of IT, even unintended property variation with explicit images requires semantic information (Cadieu et al., 2014; Yamins et al., 2014). In fact, an efficient way to account for the visual representations in the IT is that visual similarity appearances does not impede semantic features of objects, and thus suggesting a correlation with each other (Khaligh-Razavi, &amp; Kriegeskorte, 2014). 8.6.5 Computational models accounting for the IT representation Computational frameworks have been developed to partly resemble the similarity patterns observed in IT cortex of the primates (Khaligh-Razavi, 2014). Sensible as individuals do, however, artificial models cannot fully perform object recognition performance. The development of pattern computational models has led to test realistic theories and to provide an effective measure accounting for primate visual object recognition (Pinto et al., 2008). The question raises whether the current computational recognition models are completely able to support the explanations for the IT neuronal populations and for recognition behaviors. Here the current paper will compare several computational approaches motivated by a biological process to other artificial approaches, and discuss whether those models can suggest the visual object representations in the primate’s IT. Khaligh-Razavi and Kriegeskorte (2014) categorized the models in mainly two ways with subordinate categories: (1) Unsupervised with category labels: (a) Biologically-inspired object-vision models (e.g., HMAX, VisNet, Stable model, Sparse localized features (SLF), Biological transform (BT), and convolutional network) (Ghodrati et al., 2012; Ghodrati et al., 2014; Hinton, 2012; Jarrett et al., (2009); LeCun, &amp; Bengio, 1995; Riesenhuber, &amp; Poggio, 1999; Serre, Oliva, &amp; Poggio, 2007; Sountsov, Santucci, &amp; Lisman, 2011; Wallis, &amp; Rolls, 1997); (b) Computer-vision models (e.g., GIST, SIFT, PHOG, PHOW, self-similarity features, geometric blur) (Bosch, Zisserman, &amp; Munoz, 2007; Deselaers, &amp; Ferrari, 2010; Lazebnik, Schmid, &amp; Ponce, 2006; Lowe, 1999; Ojala, Pietikainen, &amp; Maenpaa, 2001; Oliva, &amp; Torralba, 2001); (2) Supervised with category labels: (a) Biologically-inspired object-vision models: GMAX and supervised HMAX (Ghodrati et al., 2012), which these approaches can discriminate animate-objects from inanimate-objects due to the training from 884 images set; deep supervised convolutional neural network (DNN) (Krizhevsky et al., 2012), which can perform object recognition by learning from a bunch of semantically-categorized images used by ImageNet (Deng et al., 2009). While computer vision models perform several local image descriptors, biologically-inspired computational models are a hierarchical model consisting of a set of transforms that make an invariant representation of the input image in a neutrally plausible way (Khaligh-Razavi, &amp; Kriegeskorte, 2014). According to Khaligh-Razavi and Kriegeskorte (2014), they investigated 37 computational approaches whether they can provide evidence for the explanations of the human’s IT about the visual representations. A set of objects physically nonoverlapped with each other was used for the artificial systems to reweight and remix (Khaligh-Razavi, &amp; Kriegeskorte, 2014). They found that the HMAX model and several computer-vision models predicted well early visual cortex responses. Furthermore, most of the models work to discriminate representation patterns of the IT from other visual areas (Khaligh-Razavi, &amp; Kriegeskorte, 2014). Several models produce categorical divisions between animal and human faces, and this finding is consistent with the results of the IT populations of human and monkey that the group for human faces were differently placed in the IT compared to the group for animal faces (Khaligh-Razavi, &amp; Kriegeskorte, 2014). While several supervised models well performed recognition tasks, all unsupervised models could not succeed to distinguish between human and non-human faces. Besides, the unsupervised models failed to emulate animate/inanimate division of IT populations (Khaligh-Razavi, &amp; Kriegeskorte, 2014). There are still limitations for computational models to reproduce semantic categorizations which are commonly found in the human IT. However, these results provide a powerful suggestion that pattern computational models trained with categorically labeled image sets could be efficient to account for the visual object representations of the IT (Khaligh-Razavi, &amp; Kriegeskorte, 2014). 8.6.6 4.6. Deep Neural Networks While deep neural networks have been developed with progress in useful learning algorithms (Hinton, Osindero, &amp; Teh, 2006; Krizhevsky, Sutskever, &amp; Hinton, 2012; LeCun, &amp; Bengio, 1995), learning process from enormous dataset enables the computational models to classify and recognize visually presented objects. More recent studies report that compared to other computational models, the responses liked human IT populations can be better predicted by the new deep computational models. Furthermore, these new models better produce categorical visual divisions in the vision fields in both human and monkey (Cadieu et al., 2014; Khaligh-Razavi, &amp; Kriegeskorte, 2014). The new deep neural computational approaches have similar components that are inspired by the primate visual systems (Khaligh-Razavi, &amp; Kriegeskorte, 2014). First of all, feedforward hierarchical structure is the common feature in the new deep neural models. In fact, these models convert to visual information from each prior stage to following stage. Next, each stage has abilities that can linearly filter the former stage which is represented as a nonlinear structure by reducing a single linear transformation (Khaligh-Razavi, &amp; Kriegeskorte, 2014). Besides, after decoding linear visual information of each stage, they are constructed convolutedly. This computed information allows to produce efficient parameters. At the same time, the decoded visual inputs transmit visual information with the cue-invariance (LeCun, &amp; Bengio, 1995). Furthermore, with increasing from stage to stage, the visual representations are placed at a space based on image-visual information and are clustered by shape similarity or semantic category information. Moreover, the neural networks models include four or more layers of representation (Gengio, 2009). Although fewer units or complex patterns are necessary, the deep networks are able to confirm accurate visual information. Finally, the new deep neural networks models can be learned by supervision with a large number of pictures which are categorically labeled (e.g., more than a million image sets) (Krizhevsky, Sutskever, &amp; Hinton, 2012). Thus, it might be possible that the more similar to IT the computational models perform, the better they process object recognition. 8.6.7 4.7. The advantages of hierarchical features in computational models Unlike computer-vision models, biologically inspired object visual models show a hierarchical structure which features of visual representations increase in the intricacy of information from lower stage to upper stage (Poggio, &amp; Ullman, 2013). Such hierarchical visual models are powerful to replicate the visual object recognition in the IT populations. There are several possible advantages for hierarchical structure of visual representations. First, hierarchical computational approaches can take advantage of the response of IT neurons, which achieve an efficient and robust recognition performance, though objects produce infinite appearances which are influenced by illumination, position, and recognizers (Logothetis et al., 1994; Logothetis, &amp; Sheinberg, 1996). Although computer vision systems can quite readily achieve scale and position invariance by simply matching target objects with dataset which contains images with different scales and positions (Valentin, &amp; Abdi, 1996), this methodology is inadequate to apply realistic recognition theory (Poggio, &amp; Ullman, 2013). Second, hierarchical approaches can offer a benefit in efficiency in quickness and in useful resources (Poggio, &amp; Ullman, 2013). Hierarchical models allow to perform even complex objects recognition by training with over a million of images. Thus, these approaches can achieve a successful recognition performance with learning process of visual images (Poggio, &amp; Ullman, 2013). Finally, the possible advantage of hierarchies is that these models can identify and classify parts of objects (e.g., ears and a tail of a dog) as well as objects as a whole (e.g., a dog and a cat) (Epshtein, Lifshitz, &amp; Ullman, 2008). 8.7 5. Conclusion Object recognition is a remarkable ability in everyday life. The present paper attempted to review the abilities to recognize visually presented-objects and faces, then review several phenomena and effects which are observed in object recognition literature and discussed whether or not computerized artificial systems can explain processing in object recognition. While the current literature reviewed the significant role of ventral stream systems in object recognition and a potential solution of the problems that are observed in computational model, their functional relevance remains to be established. It might be hard to fully understand how the brain solves object recognition as yet. However, artificial models have become far more computationally sophisticated. New theories suggest great promise for explaining object recognition process by understanding from all of domains. 8.8 References Allison, T., McCarthy, G., Nobre, A., Puce, A., &amp; Belger, A. (1994). Human extrastriate visual cortex and the perception of faces, words, numbers, and colors. Cerebral cortex, 4(5), 544-554. Allison, T., Puce, A., Spencer, D. D., &amp; McCarthy, G. (1999). Electrophysiological studies of human face perception. I: Potentials generated in occipitotemporal cortex by face and non-face stimuli. Cerebral cortex, 9(5), 415-430. Anzai, A., Peng, X., &amp; Van Essen, D. C. (2007). Neurons in monkey visual area V2 encode combinations of orientations.Nature neuroscience,10(10), 1313. Baker, C. I., Behrmann, M., &amp; Olson, C. R. (2002). Impact of learning on representation of parts and wholes in monkey inferotemporal cortex.Nature neuroscience,5(11), 1210. Baldassi, C., Alemi-Neissi, A., Pagan, M., DiCarlo, J. J., Zecchina, R., &amp; Zoccolan, D. (2013). Shape similarity, better than semantic membership, accounts for the structure of visual object representations in a population of monkey inferotemporal neurons.PLoS computational biology,9(8), e1003167. Bartels, A., &amp; Zeki, S. (2000). The architecture of the colour centre in the human visual brain: new results and a reviw. European Journal of Neuroscience, 12, 172-193. Behrmann, M., Moscovitch, M., &amp; Winocur, G. (1999). Vision and visual mental imagery.Case studies in the neuropsychology of vision. Psychology Press, UK, 81-110. Behrmann, M., Winocur, G., &amp; Moscovitch, M. (1992). Dissociation between mental imagery and object recognition in a brain-damaged patient.Nature,359(6396), 636. Bell, A. H., Hadj-Bouziane, F., Frihauf, J. B., Tootell, R. B., &amp; Ungerleider, L. G. (2009). Object representations in the temporal cortex of monkeys and humans as revealed by functional magnetic resonance imaging.Journal of neurophysiology,101(2), 688-700. Bengio, Y. (2009). Learning deep architectures for AI.Foundations and trends in Machine Learning,2(1), 1-127. Biederman, I. (1987). Recognition-by-components: a theory of human image understanding. Psychological review, 94(2), 115-147. Bindemann, M., Avetisyan, M., &amp; Rakow, T. (2012). Who can recognize unfamiliar faces? Individual differences and observer consistency in person identification.Journal of Experimental Psychology: Applied,18(3), 277. Bindemann, M., &amp; Sandford, A. (2011). Me, myself, and I: Different recognition rates for three photo-IDs of the same person.Perception,40(5), 625-627. Bosch, A., Zisserman, A., &amp; Munoz, X. (2007, July). Representing shape with a spatial pyramid kernel. InProceedings of the 6th ACM international conference on Image and video retrieval(pp. 401-408). ACM. Brigham, J. C. (1986). The influence of race on face recognition. InAspects of face processing(pp. 170-177). Springer, Dordrecht. Brigham, J. C., &amp; Barkowitz, P. (1978). Do “they all look alike?” The effect of race, sex, experience, and attitudes on the ability to recognize faces.Journal of Applied Social Psychology,8(4), 306-318. Brincat, S. L., &amp; Connor, C. E. (2004). Underlying principles of visual shape selectivity in posterior inferotemporal cortex.Nature neuroscience,7(8), 880. Bruce, V., Henderson, Z., Newman, C., &amp; Burton, A. M. (2001). Matching identities of familiar and unfamiliar faces caught on CCTV images.Journal of Experimental Psychology: Applied,7(3), 207. Burton, A. M., &amp; Vokey, J. R. (1998). The face-space typicality paradox: Understanding the face-space metaphor.The Quarterly Journal of Experimental Psychology: Section A,51(3), 475-483. Busey, T. A. (1998). Physical and psychological representations of faces: Evidence from morphing.Psychological Science,9(6), 476-483. Cadieu, C. F., Hong, H., Yamins, D. L., Pinto, N., Ardila, D., Solomon, E. A., … &amp; DiCarlo, J. J. (2014). Deep neural networks rival the representation of primate IT cortex for core visual object recognition.PLoS computational biology,10(12), e1003963. Caldara, R., &amp; Abdi, H. (2006). Simulating the ‘other-race’effect with autoassociative neural networks: further evidence in favor of the face-space model.Perception,35(5), 659-670. Caldara, R., Rossion, B., Bovet, P., &amp; Hauert, C. A. (2004). Event-related potentials and time course of the ‘other-race’face classification advantage.Neuroreport,15(5), 905-910. Caldara, R., Thut, G., Servoir, P., Michel, C. M., Bovet, P., &amp; Renault, B. (2003). Face versus non-face object perception and the ‘other-race’effect: a spatio-temporal event-related potential study.Clinical Neurophysiology,114(3), 515-528. Clarke, S., Riahi-Arya, S., Tardif, E., Eskenasy, C., &amp; Probst, A. (1999). Thalamic projections of the fusiform gyrus in man. European Journal of Neuroscience, 11, 1835-1838. Carlson, J. M., Cha, J., &amp; Mujica-Parodi, L. R. (2013). Functional and structural amygdala–anterior cingulate connectivity correlates with attentional bias to masked fearful faces.Cortex,49(9), 2595-2600. Connolly, A. C., Guntupalli, J. S., Gors, J., Hanke, M., Halchenko, Y. O., Wu, Y. C., … &amp; Haxby, J. V. (2012). The representation of biological classes in the human brain.Journal of Neuroscience,32(8), 2608-2618. Corbetta, M., Miezin, F. M., Dobmeyer, S., Shulman, G. L., &amp; Petersen, S. E. (1991). Selective and divided attention during visual discriminations of shape, color, and speed: functional anatomy by positron emission tomography. Journal of neuroscience, 11(8), 2383-2402. Dailey, M. N., Cottrell, G. W., &amp; Busey, T. A. (1999). Facial memory is kernel density estimation (almost). InAdvances in neural information processing systems(pp. 24-30). Damasio, A. R., Damasio, H., &amp; Van Hoesen, G. W. (1982). Prosopagnosia Anatomic basis and behavioral mechanisms.Neurology,32(4), 331-331. Damasio, A. R., Tranel, D., &amp; Damasio, H. (1990). Face agnosia and the neural substrates of memory. Annual review of neuroscience, 13(1), 89-109. Deng, J., Dong, W., Socher, R., Li, L. J., Li, K., &amp; Fei-Fei, L. (2009, June). Imagenet: A large-scale hierarchical image database. InComputer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on(pp. 248-255). IEEE. Deselaers, T., &amp; Ferrari, V. (2010, June). Global and efficient self-similarity for object classification and detection. InComputer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on(pp. 1633-1640). IEEE. Desimone, R., Albright, T. D., Gross, C. G., &amp; Bruce, C. (1984). Stimulus-selective properties of inferior temporal neurons in the macaque.Journal of Neuroscience,4(8), 2051-2062. Desimone, R. (1991). Face-selective cells in the temporal cortex of monkeys.Journal of cognitive neuroscience,3(1), 1-8. De Renzi, E. (1986). Current issues on prosopagnosia. InAspects of face processing(pp. 243-252). Springer, Dordrecht. DiCarlo, J. J., &amp; Cox, D. D. (2007). Untangling invariant object recognition. Trends in cognitive sciences, 11(8), 333-341. DiCarlo, J. J., Zoccolan, D., &amp; Rust, N. C. (2012). How does the brain solve visual object recognition?. Neuron, 73(3), 415-434. Downing, P. E., Jiang, Y., Shuman, M., &amp; Kanwisher, N. (2001). A cortical area selective for visual processing of the human body.Science,293(5539), 2470-2473. Engel, S., Zhang, X., Wandell, B. (1997). Colour tuning in human visual cortex measured with functional magnetic resonance imaging. Nature, 388, 68-71. Epshtein, B., Lifshitz, I., &amp; Ullman, S. (2008). Image interpretation by a single bottom-up top-down cycle.Proceedings of the National Academy of Sciences,105(38), 14298-14303. Fabre-Thorpe, M., Richard, G., &amp; Thorpe, S. J. (1998). Rapid categorization of natural images by rhesus monkeys. Neuroreport, 9(2), 303-308. Farah, M. J., Hammond, K. M., Mehta, Z., &amp; Ratcliff, G. (1989). Category-specificity and modality-specificity in semantic memory. Neuropsychologia, 27(2), 193-200. Feinberg, T. E., Schindler, R. J., Ochoa, E., Kwan, P. C., &amp; Farah, M. J. (1994). Associative visual agnosia and alexia without prosopagnosia.Cortex,30(3), 395-411. Feingold, G. A. (1914). Influence of environment on identification of persons and things.J. Am. Inst. Crim. L. &amp; Criminology,5, 39. Felleman, D. J., &amp; Van, D. E. (1991). Distributed hierarchical processing in the primate cerebral cortex. Cerebral cortex (New York, NY:1991), 1(1), 1-47. Freiwald, W. A., &amp; Tsao, D. Y. (2010). Functional compartmentalization and viewpoint generalization within the macaque face-processing system.Science,330(6005), 845-851. Freedman, D. J., Riesenhuber, M., Poggio, T., &amp; Miller, E. K. (2005). Experience-dependent sharpening of visual shape selectivity in inferior temporal cortex.Cerebral Cortex,16(11), 1631-1644. Furl, N., Phillips, P. J., &amp; O’Toole, A. J. (2002). Face recognition algorithms and the other-race effect: computational mechanisms for a developmental contact hypothesis.Cognitive Science,26(6), 797-815. Gallant, J. L., Braun, J., &amp; Van Essen, D. C. (1993). Selectivity for polar, hyperbolic, and Cartesian gratings in macaque visual cortex.Science,259(5091), 100-103. Gauthier, I., Tarr, M. J., Anderson, A. W., Skudlarski, P., &amp; Gore, J. C. (1999). Activation of the middle fusiform’face area’increases with expertise in recognizing novel objects.Nature neuroscience,2(6), 568. Ghodrati, M., Khaligh-Razavi, S. M., Ebrahimpour, R., Rajaei, K., &amp; Pooyan, M. (2012). How can selection of biologically inspired features improve the performance of a robust object recognition model?.PloS one,7(2), e32357. Ghodrati, M., Farzmahdi, A., Rajaei, K., Ebrahimpour, R., &amp; Khaligh-Razavi, S. M. (2014). Feedforward object-vision models only tolerate small image variations compared to human.Frontiers in computational neuroscience,8, 74. Goldstein, A. G., &amp; Chance, J. E. (1985). Effects of training on Japanese face recognition: Reduction of the other-race effect.Bulletin of the Psychonomic Society,23(3), 211-214. Goodale, M. A., Milner, A. D., Jakobson, L. S., &amp; Carey, D. P. (1991). A neurological dissociation between perceiving objects and grasping them. Nature, 349(6305), 154-155. Grill-Spector, K., Kourtzi, Z., &amp; Kanwisher, N. (2001). The lateral occipital complex and its role in object recognition. Vision research, 41(10-11), 1409-1422. Grill-Spector, K., Knouf, N., &amp; Kanwisher, N. (2004). The fusiform face area subserves face perception, not generic within-category identification.Nature neuroscience,7(5), 555. Grill-Spector, K., Kushnir, T., Hendler, T., Edelman, S., Itzchak, Y., Malach, R. (1998). A sequence of object processing stages revealed by fMRI in the human occipital lobe. Human Brain Mapping, 316-328. Gross, C., Rocha, M., Bender, D. (1972). Visual properties of neurons in inferotemporal cortex of the Macaque. Journal of Neurophysiology, 35, 96-111. Grudin, M. A. (2000). On internal representations in face recognition systems.Pattern recognition,33(7), 1161-1177. Hadjikhani, N., Liu, A., Dale, A., Cavanagh, P., Tootell, R. (1998). Retinotopy and color sensitivity in human visual cortical area V8. Nature Neuroscience, 1, 235-241. Hancock, P. J., Bruce, V., &amp; Burton, A. M. (2000). Recognition of unfamiliar faces.Trends in cognitive sciences,4(9), 330-337. Haxby, J. V., Grady, C. L., Ungerleider, L. G., &amp; Horwitz, B. (1991). Mapping the functional neuroanatomy of the intact human brain with brain work imaging. Neuropsychologia, 29(6), 539-555. Haxby, J. V., Gobbini, M. I., Furey, M. L., Ishai, A., Schouten, J. L., &amp; Pietrini, P. (2001). Distributed and overlapping representations of faces and objects in ventral temporal cortex.Science,293(5539), 2425-2430. Haxby, J. V., Hoffman, E. A., &amp; Gobbini, M. I. (2002). Human neural systems for face recognition and social communication.Biological psychiatry,51(1), 59-67. Hung, C. P., Kreiman, G., Poggio, T., &amp; DiCarlo, J. J. (2005). Fast readout of object identity from macaque inferior temporal cortex.Science,310(5749), 863-866. Hinton, G., Deng, L., Yu, D., Dahl, G. E., Mohamed, A. R., Jaitly, N., … &amp; Kingsbury, B. (2012). Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups.IEEE Signal Processing Magazine,29(6), 82-97. Hinton, G. E., Osindero, S., &amp; Teh, Y. W. (2006). A fast learning algorithm for deep belief nets.Neural computation,18(7), 1527-1554. Huth, A. G., Nishimoto, S., Vu, A. T., &amp; Gallant, J. L. (2012). A continuous semantic space describes the representation of thousands of object and action categories across the human brain.Neuron,76(6), 1210-1224. Ito, M., Tamura, H., Fujita, I., Tanaka, K. (1995). Size and position invariance of neuronal responses in monkey inferotemporal cortex. Journal of Neurophysiology, 73, 218-226. Jenkins, R., &amp; Burton, A. M. (2011). Stable face representations.Philosophical Transactions of the Royal Society of London B: Biological Sciences,366(1571), 1671-1683. Jerabek, P. (1997). Retinotopic organization of early visual spatial attention effects as revealed by PET and ERPs. Human brain mapping, 5(4), 280-286. Jarrett, K., Kavukcuoglu, K., &amp; LeCun, Y. (2009, September). What is the best multi-stage architecture for object recognition?. InComputer Vision, 2009 IEEE 12th International Conference on(pp. 2146-2153). IEEE. Johnson, K. O., (1980). Sensory discrimination: Decision process. Journal of Neurophysiology, 43(6), 1771-1792. Johnston, R. A., &amp; Edmonds, A. J. (2009). Familiar and unfamiliar face recognition: A review.Memory,17(5), 577-596. Just, M. A., Cherkassky, V. L., Aryal, S., &amp; Mitchell, T. M. (2010). A neurosemantic theory of concrete noun representation based on the underlying brain codes.PloS one,5(1), e8622. Kalocsai, P., Zhao, W., &amp; Elagin, E. (1998, April). Face similarity space as perceived by humans and artificial systems. InAutomatic Face and Gesture Recognition, 1998. Proceedings. Third IEEE International Conference on(pp. 177-180). IEEE. Kanwisher, N., McDermott, J., &amp; Chun, M. M. (1997). The fusiform face area: a module in human extrastriate cortex specialized for face perception.Journal of neuroscience,17(11), 4302-4311. Kanwisher, N. (2010). Functional specificity in the human brain: a window into the functional architecture of the mind.Proceedings of the National Academy of Sciences,107(25), 11163-11170. Kanwisher, N. (1991). Repetition blindness and illusory conjunctions: Errors in binding visual types with visual tokens.Journal of Experimental Psychology: Human Perception and Performance,17(2), 404. Kanwisher, N., McDermott, J., &amp; Chun, M. M. (1997). The fusiform face area: a module in human extrastriate cortex specialized for face perception.Journal of neuroscience,17(11), 4302-4311. Kayaert, G., Biederman, I., &amp; Vogels, R. (2003). Shape tuning in macaque inferior temporal cortex.Journal of Neuroscience,23(7), 3016-3027. Kayaert, G., Biederman, I., Op de Beeck, H. P., &amp; Vogels, R. (2005). Tuning for shape dimensions in macaque inferior temporal cortex.European Journal of Neuroscience,22(1), 212-224. Khaligh-Razavi, S. M., &amp; Kriegeskorte, N. (2014). Deep supervised, but not unsupervised, models may explain IT cortical representation.PLoS computational biology,10(11), e1003915. Konkle, T., &amp; Oliva, A. (2012). A real-world size organization of object responses in occipitotemporal cortex.Neuron,74(6), 1114-1124. Kosslyn, S. M., Alpert, N. M., Thompson, W. L., Chabris, C. F., Rauch, S. L., &amp; Anderson, A. K. (1994). Identifying objects seen from different viewpoints A PET investigation. Brain, 117(5), 1055-1071. Kourtzi, Z., &amp; Connor, C. E. (2011). Neural representations for object perception: structure, category, and adaptive coding.Annual review of neuroscience,34, 45-67. Kriegeskorte, N., Mur, M., Ruff, D. A., Kiani, R., Bodurka, J., Esteky, H., … &amp; Bandettini, P. A. (2008). Matching categorical object representations in inferior temporal cortex of man and monkey.Neuron,60(6), 1126-1141. Krizhevsky, A., Sutskever, I., &amp; Hinton, G. E. (2012). Imagenet classification with deep convolutional neural networks. InAdvances in neural information processing systems (pp. 1097-1105). Kriegeskorte, N., Mur, M., Ruff, D. A., Kiani, R., Bodurka, J., Esteky, H., … &amp; Bandettini, P. A. (2008). Matching categorical object representations in inferior temporal cortex of man and monkey.Neuron,60(6), 1126-1141. Krizhevsky, A., Sutskever, I., &amp; Hinton, G. E. (2012). Imagenet classification with deep convolutional neural networks. InAdvances in neural information processing systems (pp. 1097-1105). Ku, S. P., Tolias, A. S., Logothetis, N. K., &amp; Goense, J. (2011). fMRI of the face-processing network in the ventral temporal lobe of awake and anesthetized macaques.Neuron,70(2), 352-362. Lazebnik, S., Schmid, C., &amp; Ponce, J. (2006). A discriminative framework for texture and object recognition using local image features. InToward Category-Level Object Recognition (pp. 423-442). Springer, Berlin, Heidelberg. Landis, T., Cummings, J. L., Benson, D. F., &amp; Palmer, E. P. (1986). Loss of topographic familiarity: An environmental agnosia.Archives of neurology,43(2), 132-136. Lavrakas, P. J., Buri, J. R., &amp; Mayzner, M. S. (1976). A perspective on the recognition of other-race faces.Perception &amp; Psychophysics,20(6), 475-481. Lazebnik, S., Schmid, C., &amp; Ponce, J. (2006). Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories. In Computer vision and pattern recognition, 2006 IEEE computer society conference on (Vol.2, pp. 2169-2178). IEEE. LeCun, Y., &amp; Bengio, Y. (1995). Convolutional networks for images, speech, and time series.The handbook of brain theory and neural networks,3361(10), 1995. Lennie, P., &amp; Movshon, J. A. (2005). Coding of color and form in the geniculostriate visual pathway (invited review).JOSA A,22(10), 2013-2033. Leopold, D. A., Rhodes, G., Müller, K. M., &amp; Jeffery, L. (2005). The dynamics of visual adaptation to faces.Proceedings of the Royal Society of London B: Biological Sciences,272(1566), 897-904. Li, N., Cox, D. D., Zoccolan, D., &amp; DiCarlo, J. J. (2009). What response properties do individual neurons need to underlie position and clutter “invariant” object recognition?.Journal of Neurophysiology,102(1), 360-376. Logothetis, N. K., Pauls, J., Bülthoff, H. H., &amp; Poggio, T. (1994). View-dependent object recognition by monkeys.Current biology,4(5), 401-414. Logothetis N. K., &amp; Sheinberge D. L. (1996). Visual object recognition. Annual review of neuroscience, 19(1), 577-621. Lowe, D. G. (1999). Object recognition from local scale-invariant features. InComputer vision, 1999. The proceedings of the seventh IEEE international conference on(Vol. 2, pp. 1150-1157). Ieee. McCarthy, G., Puce, A., Gore, J. C., &amp; Allison, T. (1997). Face-specific processing in the human fusiform gyrus.Journal of cognitive neuroscience,9(5), 605-610. Majaj, N., Hong, H., Solomon, E., &amp; DiCarlo, J. J. (2012). A unified neuronal population code fully explains human object recognition.Cosyne Abstracts. Mahon, B. Z., Milleville, S. C., Negri, G. A., Rumiati, R. I., Caramazza, A., &amp; Martin, A. (2007). Action-related properties shape object representations in the ventral stream.Neuron,55(3), 507-520. Mahon, B. Z., &amp; Caramazza, A. (2009). Concepts and categories: A cognitive neuropsychological perspective.Annual review of psychology,60, 27-51. Malach, R., Reppas, J. B., Benson, R. R., Kwong, K. K., Jiang, H., Kennedy, W. A., … &amp; Tootell, R. B. (1995). Object-related activity revealed by functional magnetic resonance imaging in human occipital cortex. Proceedings of the National Academy of Sciences, 92(18), 8135-8139. Malpass, R. S., &amp; Kravitz, J. (1969). Recognition for faces of own and other race.Journal of personality and social psychology,13(4), 330. McCarthy, G., Puce, A., Belger, A., &amp; Allison, T. (1999). Electrophysiological studies of human face perception. II: Response properties of face-specific potentials generated in occipitotemporal cortex. Cerebral cortex, 9(5), 431-444. Meissner, C. A., &amp; Brigham, J. C. (2001). Thirty years of investigating the own-race bias in memory for faces: A meta-analytic review.Psychology, Public Policy, and Law,7(1), 3. Missal, M., Vogels, R., Li, C. Y., &amp; Orban, G. A. (1999). Shape interactions in macaque inferior temporal neurons.Journal of Neurophysiology,82(1), 131-142. Miyashita, Y. (1993). Inferior temporal cortex: where visual perception meets memory. Annual review of neuroscience, 16(1), 245-263. Moscovitch, M., Winocur, G., &amp; Behrmann, M. (1997). What is special about face recognition? Nineteen experiments on a person with visual object agnosia and dyslexia but normal face recognition.Journal of cognitive neuroscience,9(5), 555-604. Mutch, J., &amp; Lowe, D. G. (2006). Multiclass object recognition with sparse, localized features. In Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on (Vol. 1, pp. 11-18). IEEE. Naselaris, T., Prenger, R. J., Kay, K. N., Oliver, M., &amp; Gallant, J. L. (2009). Bayesian reconstruction of natural images from human brain activity.Neuron,63(6), 902-915. Naselaris, T., Prenger, R. J., Kay, K. N., Oliver, M., &amp; Gallant, J. L. (2009). Bayesian reconstruction of natural images from human brain activity.Neuron,63(6), 902-915. Ng, W. J., &amp; Lindsay, R. C. (1994). Cross-race facial recognition: Failure of the contact hypothesis.Journal of Cross-Cultural Psychology,25(2), 217-232. Ojala, T., Pietikäinen, M., &amp; Mäenpää, T. (2001, March). A generalized local binary pattern operator for multiresolution gray scale and rotation invariant texture classification. InInternational Conference on Advances in Pattern Recognition(pp. 399-408). Springer, Berlin, Heidelberg. Oliva, A., &amp; Torralba, A. (2001). Modeling the shape of the scene: A holistic representation of the spatial envelope.International journal of computer vision,42(3), 145-175. Orban, G. A. (2008). Higher order visual processing in macaque extrastriate cortex. Physiological reviews, 88(1), 59-89. Orban, G. A., Van Essen, D., &amp; Vanduffel, W. (2004). Comparative mapping of higher visual areas in monkeys and humans.Trends in cognitive sciences,8(7), 315-324. O’toole, A. J., Deffenbacher, K. A., Valentin, D., &amp; Abdi, H. (1994). Structural aspects of face recognition and the other-race effect.Memory &amp; Cognition,22(2), 208-224. O’Toole, A. J., Peterson, J., &amp; Deffenbacher, K. A. (1996). An ‘other-race effect’ for categorizing faces by sex.Perception,25(6), 669-676. O’toole, A. J., Vetter, T., Bülthoff, H. H., &amp; Troje, N. F. (1995). The role of shape and texture information in sex classification. O’toole, A. J., Jiang, F., Abdi, H., &amp; Haxby, J. V. (2005). Partially distributed representations of objects and faces in ventral temporal cortex.Journal of cognitive neuroscience,17(4), 580-590. Pasupathy, A., &amp; Connor, C. E. (2001). Shape representation in area V4: position-specific tuning for boundary conformation.Journal of neurophysiology,86(5), 2505-2519. Pinto, N., Cox, D. D., &amp; DiCarlo, J. J. (2008). Why is real-world visual object recognition hard?. PLoS computational biology, 4(1), 151-156. Perrett, D. I., Hietanen, J. K., Oram, M. W., &amp; Benson, P. J. (1992). Organization and functions of cells responsive to faces in the temporal cortex.Phil. Trans. R. Soc. Lond. B,335(1273), 23-30. Poggio, T., &amp; Ullman, S. (2013). Vision: are models of object recognition catching up with the brain?. Annals of the New York Academy of Sciences, 1305(1), 72-82. Perrett, D. I., Rolls, E. T., &amp; Caan, W. (1982). Visual neurones responsive to faces in the monkey temporal cortex.Experimental brain research,47(3), 329-342. Pinto, N., Cox, D. D., &amp; DiCarlo, J. J. (2008). Why is real-world visual object recognition hard?.PLoS computational biology,4(1), e27. Pinto, N., Majaj, N., Barhomi, Y., Solomon, E., &amp; DiCarlo, J. J. (2010). Human versus machine: comparing visual object recognition systems on a level playing field.Cosyne Abstracts. Riesenhuber, M., &amp; Poggio, T. (1999). Hierarchical models of object recognition in cortex.Nature neuroscience,2(11), 1019. Rousselet, G. A., Fabre-Thorpe, M., &amp; Thorpe, S. J. (2002). Parallel processing in high-level categorization of natural images. Nature neuroscience, 5(7), 629-630. Rolls, E. T. (2000). The orbitofrontal cortex and reward. Cerebral cortex, 10(3), 284-294. Rust, N. C., &amp; DiCarlo, J. J. (2010). Selectivity and tolerance (“invariance”) both increase as visual information propagates from cortical area V4 to IT.Journal of Neuroscience,30(39), 12978-12995. Serre, T., Oliva, A., &amp; Poggio, T. (2007). A feedforward architecture accounts for rapid categorization.Proceedings of the national academy of sciences,104(15), 6424-6429. Sountsov, P., Santucci, D. M., &amp; Lisman, J. E. (2011). A biologically plausible transform for visual recognition that is invariant to translation, scale, and rotation.Frontiers in computational neuroscience,5, 53. Tanaka, K. (1996). Inferotemporal cortex and object vision.Annual review of neuroscience,19(1), 109-139. Tanaka, J. W., &amp; Farah, M. J. (1993). Parts and wholes in face recognition.The Quarterly journal of experimental psychology,46(2), 225-245. Tsao, D., Freiwald, W., Knutsen, T., Mandeville, J., Tootell, R. (2003). Faces and objects in macaque cerebral cortex. Nature Neruoscience, 6, 989-995. Tsao, D. Y., Freiwald, W. A., Tootell, R. B., &amp; Livingstone, M. S. (2006). A cortical region consisting entirely of face-selective cells.Science,311(5761), 670-674. Tsao, D., Moeller, S., Freiwald, W. (2008a). Comparing face patch systems in macaques and humans. Proceedings of the National Academy of Sciences,105(49), 19514-19519. Tsao, D. Y., Schweers, N., Moeller, S., &amp; Freiwald, W. A. (2008b). Patches of face-selective cortex in the macaque frontal lobe.Nature neuroscience,11(8), 877. Tootell, R., Taylor, J. (1995). Anatomical evidence for MT and additional cortical visual areas in humans. Cerebral Cortex, 5, 39-55. Tovee, M. J., Rolls, E. T., &amp; Azzopardi, P. (1994). Translation invariance in the responses to faces of single neurons in the temporal visual cortical areas of the alert macaque.Journal of neurophysiology. Turk, M., &amp; Pentland, A. (1991). Eigenfaces for recognition.Journal of cognitive neuroscience,3(1), 71-86. Thorpe, S., Fize, D., &amp; Marlot, C. (1996). Speed of processing in the human visual system. Nature, 381(6582), 520-522. Tootell, R., Mendola, J., Hadjikhani, N., Liu, A., Dale, A. (1998). The representation of the ipsilateral visual field in human cerebral cortex. Proceedings of the Natural Academy of Science USA, 95, 818-824. Ullman, S. (1996). High-level vision: Object recognition and visual cognition (Vol.2). Cambridge, MA: MIT press. Valentine, T. (1991). A unified account of the effects of distinctiveness, inversion, and race in face recognition.The Quarterly Journal of Experimental Psychology Section A,43(2), 161-204. Valentin, D., &amp; Abdi, H. (1996). Can a linear autoassociator recognize faces from new orientations?.JOSA A,13(4), 717-724. Valentine, T., &amp; Endo, M. (1992). Towards an exemplar model of face processing: The effects of race and distinctiveness.The Quarterly Journal of Experimental Psychology Section A,44(4), 671-703. Van Oostende, S., Sunaert, S., Van Hecke, P., Marchal, G., &amp; Orban, G. (1997). The kinetic occipital (KO) region in man: an fMRI study. Cerebral Cortex, 7, 690-701. Vogels, R., &amp; Biederman, I. (2002). Effects of illumination intensity and direction on object coding in macaque inferior temporal cortex.Cerebral Cortex,12(7), 756-766. Wang, G., Zhang, Y., &amp; Fei-Fei, L. (2006). Using dependent regions for object categorization in a generative framework. In Computer Vision and Pattern Recognition, 20006 IEEE Computer Society Conference on (Vol. 2, pp. 1597-1604). IEEE. Wallis, G., &amp; Rolls, E. T. (1997). Invariant face and object recognition in the visual system.Progress in neurobiology,51(2), 167-194. Watson, D., Myers, R., Frackowiak., R., Hajnal, J., Woods, R., Mazziotta, J., Shipp, S., Zeki, S. (1993). Area V5 of the human brain: evidence from a combined study using positron emission tomography and magnetic resonance imaging. Cerebral Cortex, 3, 79-94. Woldorff, M. G., Fox, P. T., Matzke, M., Lancaster, J. L., Veeraswamy, S., Zamarripa, F., … &amp; Ullman, S. (1996). High-level vision: Object recognition and visual cognition (Vol.2). Cambridge, MA: MIT press. Yamane, Y., Carlson, E. T., Bowman, K. C., Wang, Z., &amp; Connor, C. E. (2008). A neural code for three-dimensional object shape in macaque inferotemporal cortex.Nature neuroscience,11(11), 1352. Yamins, D. L., Hong, H., Cadieu, C. F., Solomon, E. A., Seibert, D., &amp; DiCarlo, J. J. (2014). Performance-optimized hierarchical models predict neural responses in higher visual cortex.Proceedings of the National Academy of Sciences,111(23), 8619-8624. Zhang, H., Berg, A. C., Maire, M., &amp; Malik, J. (2006). SVM-KNN: Discriminative nearest neighbor classification for visual category recognition. In Computer Vision and Pattern Recognition, 2006 IEEE computer Society Conference on (Vol. 2, pp. 2126-2136). IEEE. Zoccolan, D., Cox, D. D., &amp; DiCarlo, J. J. (2005). Multiple object response normalization in monkey inferotemporal cortex.Journal of Neuroscience,25(36), 8150-8164. Zoccolan, D., Kouh, M., Poggio, T., &amp; DiCarlo, J. J. (2007). Trade-off between object selectivity and tolerance in monkey inferotemporal cortex.Journal of Neuroscience,27(45), 12292-12307. "],
["references-7.html", "References", " References "]
]
